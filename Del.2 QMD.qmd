---
title: "2. Del Analyse, ML Model + Shiny"
author: "Jan Maurycy Pedersen, Jolene Kaye Jensen, Lukas Beslic Christiansen"

format:
  pdf:
    toc: true
    toc-title: "Indholdsfortegnelse"
    toc-depth: 4
    number-sections: true
    geometry:
      - left=1.0cm
      - right=1.0cm
      - top=1.5cm
      - bottom=1.5cm
    include-before-body:
      - text: |
          \begin{center}
          \vspace{1cm}
          \includegraphics[width=0.9\textwidth]{forside.png}
          \end{center}
          \newpage

editor: visual
---

# Stam-baseline som analytisk referencepunkt

Dette QMD udg√∏r projektets centrale stampunkt og etablerer den f√¶lles baseline, som al efterf√∏lgende analyse bygger videre p√•. Baseline fungerer ikke som en f√¶rdig eller l√•st model, men som et metodisk referencepunkt, der l√∏bende udvides og nuanceres i analysen. Ved at starte fra et enkelt, l√¶kagefrit grundsetup kan nye variable og antagelser tilf√∏jes trinvis, s√• √¶ndringer i modeladf√¶rd og forklaringskraft kan forst√•s, dokumenteres og sammenlignes systematisk p√• tv√¶rs af prognosehorisonter. Desuden anvender vi de f√∏rste to baselines til manuel validering og tjek og konsolidering af kode

## Pakker og globale indstillinger

I dette indledende trin indl√¶ses de n√∏dvendige pakker p√• en m√•de, der sikrer et ensartet og reproducerbart setup p√• tv√¶rs af maskiner. Startup-beskeder undertrykkes for at holde output roligt og egnet til rapportering, mens globale indstillinger justeres, s√• numeriske v√¶rdier pr√¶senteres uden videnskabelig notation. Dette skaber et stabilt og l√¶sbart fundament for det videre analysearbejde.

```{r}

# Vi undertrykker startup-messages for at holde output roligt og l√¶sbart i en
# rapportkontekst. pacman::p_load sikrer ens setup p√• tv√¶rs af maskiner.
suppressPackageStartupMessages({
  if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
  pacman::p_load(DBI, odbc, dplyr, lubridate, rstudioapi, hms)
})

# scipen = 999 fjerner videnskabelig notation, s√• tal fremst√•r mere intuitive.
options(scipen = 999)

cat("Pakker er nu klar ‚Äì god arbejdslyst!\n\n")
```

## Sikker og reproducerbar databaseops√¶tning

Dette trin sikrer en reproducerbar og sikker ops√¶tning af forbindelsen til Azure SQL ved at anvende milj√∏variabler til h√•ndtering af credentials. Scriptet kontrollerer tidligt, om alle n√∏dvendige variabler er til stede, og guider brugeren til korrekt ops√¶tning, hvis noget mangler. Ved at fejle tidligt og tydeligt undg√•s skjulte forbindelsesfejl senere i analysen, og koden kan k√∏res konsistent p√• tv√¶rs af maskiner uden hardcodede adgangsoplysninger.

```{r}
# Vi bruger milj√∏variabler til credentials fra renviron, s√• scriptet kan k√∏res p√• tv√¶rs af
# maskiner uden hardcodede n√∏gler. Hvis noget mangler, fejler vi tidligt og tydeligt.

ensure_renviron <- function() {
  required_vars <- c("AZURE_SQL_SERVER", "AZURE_SQL_DB", "AZURE_SQL_UID", "AZURE_SQL_PWD")
  values <- Sys.getenv(required_vars)
  missing_vars <- required_vars[values == ""]
  
  if (length(missing_vars) > 0) {
    cat("‚ö†Ô∏è F√∏lgende milj√∏variabler mangler i .Renviron:\n")
    print(missing_vars)
    cat("\n√Öbner ~/.Renviron ‚Äì udfyld v√¶rdierne, gem, og genstart R.\n")
    file.edit("~/.Renviron")
    
    if (rstudioapi::isAvailable()) {
      rstudioapi::restartSession()
    } else {
      stop("rstudioapi er ikke tilg√¶ngelig ‚Äì genstart R manuelt og k√∏r igen.")
    }
  } else {
    cat("‚úî Alle n√∏dvendige .Renviron-variabler er sat.\n\n")
  }
}
```

## Robust oprettelse af Azure SQL-forbindelse

I dette trin etableres forbindelsen til Azure SQL ved hj√¶lp af en bevidst robust retry-strategi. Da Azure-forbindelser i praksis kan fejle sporadisk p√• grund af timeouts, netv√¶rksforhold eller cold starts, fors√∏ges forbindelsen oprettet flere gange med gradvist stigende timeouts. Tilgangen reducerer risikoen for tilf√¶ldige afbrydelser under rapportk√∏rsler og sikrer, at analysen enten opn√•r en stabil databaseforbindelse eller stopper kontrolleret med en klar fejlmeddelelse.

```{r, eval=FALSE}
DBI::dbDisconnect(con)


# Vi bruger en retry-funktion, fordi Azure-forbindelser i praksis kan fejle
# sporadisk (timeout, netv√¶rk, cold start). Metoden √∏ger robusthed og minimerer
# ‚Äútilf√¶ldige fejl‚Äù under rapportk√∏rsler.
connect_azure_retry <- function(
    fors√∏g_max = 6,
    timeouts  = c(60, 180, 200, 260, 360, 600),
    delay_sec = 10
) {
  fors√∏g <- 1
  con <- NULL
  
  while (fors√∏g <= fors√∏g_max && is.null(con)) {
    timeout_brug <- timeouts[min(fors√∏g, length(timeouts))]
    cat("Fors√∏g", fors√∏g, "p√• at forbinde (ConnectionTimeout =", timeout_brug, "sekunder)...\n")
    
    con_try <- try(
      DBI::dbConnect(
        odbc::odbc(),
        driver   = "ODBC Driver 18 for SQL Server",
        server   = Sys.getenv("AZURE_SQL_SERVER"),
        database = Sys.getenv("AZURE_SQL_DB"),
        uid      = Sys.getenv("AZURE_SQL_UID"),
        pwd      = Sys.getenv("AZURE_SQL_PWD"),
        port     = 1433,
        Encrypt  = "yes",
        TrustServerCertificate = "no",
        ConnectionTimeout      = timeout_brug
      ),
      silent = TRUE
    )
    
    if (!inherits(con_try, "try-error")) {
      con <- con_try
      cat("‚úÖ Forbundet til:", Sys.getenv("AZURE_SQL_DB"), "p√• fors√∏g", fors√∏g, "\n\n")
      return(con)
    }
    
    cat("‚ùå Forbindelsen fejlede p√• fors√∏g", fors√∏g, "\n")
    if (fors√∏g == fors√∏g_max) stop("Kunne ikke forbinde til Azure SQL efter ", fors√∏g_max, " fors√∏g.\n")
    
    cat("Venter", delay_sec, "sekunder f√∏r n√¶ste fors√∏g...\n\n")
    Sys.sleep(delay_sec)
    fors√∏g <- fors√∏g + 1
  }
  
  stop("Uventet: forlod retry-loop uden forbindelse.")
}

ensure_renviron()
con <- connect_azure_retry()
on.exit(try(DBI::dbDisconnect(con), silent = TRUE), add = TRUE)

```

## Indl√¶sning af data fra Azure

I dette trin indl√¶ses de n√∏dvendige datas√¶t direkte fra Azure SQL ved hj√¶lp af dbReadTable uden brug af SQL-queries. Hele Superliga-programmet anvendes som strukturelt grundlag, mens Viborg FF‚Äôs hjemmekampe med tilskuertal udg√∏r m√•lvariablen i analysen. Ved at tr√¶kke data fra join-ready-laget sikres det, at datas√¶ttene allerede er konsistente og klar til videre modellering, samtidig med at antallet af r√¶kker udskrives som et simpelt kontrolpunkt for korrekt indl√¶sning.

```{r}

# ====================================================================
# Hent data fra Azure (ingen SQL-queries, kun dbReadTable)
# ====================================================================
# program1 indeholder hele Superliga-programmet (mange klubber).
# VFF1 indeholder Viborg FF hjemmekampe med tilskuere/billetsalg (vores target).
con <- DBI::dbConnect(
  odbc::odbc(),
  Driver   = "ODBC Driver 18 for SQL Server",
  Server   = Sys.getenv("AZURE_SQL_SERVER"),
  Database = Sys.getenv("AZURE_SQL_DB"),
  UID      = Sys.getenv("AZURE_SQL_UID"),
  PWD      = Sys.getenv("AZURE_SQL_PWD"),
  Encrypt  = "yes"
)


schema_program <- "PBA03_JoinReady"
schema_vff     <- "PBA03_JoinReady"
tbl_program    <- "fact_superliga_program_join_ready"
tbl_vff        <- "fact_VFF_Billetsalg_join_ready"

program1 <- DBI::dbReadTable(con, DBI::Id(schema = schema_program, table = tbl_program)) |> as_tibble()

VFF1     <- DBI::dbReadTable(con, DBI::Id(schema = schema_vff,     table = tbl_vff))     |> as_tibble()

cat("program1 r√¶kker:", nrow(program1), " | VFF1 r√¶kker:", nrow(VFF1), "\n\n")
str(program1)
str(VFF1)


```

![](images/2026-01-04_10h47_02.png)

![](images/2026-01-04_10h48_58.png)

## Afgr√¶nsning til Viborg FF‚Äôs hjemmebanekampe

I dette trin afgr√¶nses Superliga-programmet til udelukkende at omfatte Viborg FF‚Äôs hjemmebanekampe. Da datas√¶ttet med billetsalg allerede kun indeholder VFF‚Äôs hjemmekampe, anvendes dette filter for at sikre strukturel konsistens mellem kampprogram og m√•lvariabel. Transformationen holdes bevidst minimal for at undg√• utilsigtet tab af r√¶kker, som tidligere er observeret ved mere aggressive deduplikeringer, og antallet af tilbagev√¶rende kampe anvendes som et simpelt kontrolpunkt.

```{r}
# ====================================================================
# Afgr√¶nsning: VFF hjemmebanekampe i programmet
# ====================================================================
# VFF1 indeholder kun VFF hjemmekampe. Programmet indeholder alt. Derfor
# filtrerer vi programmet til de r√¶kker, hvor hjemme_klubID er Viborg FF.
#
# Vigtigt: I vores tidligere fejls√∏gning viste det sig, at aggressive distinct() kunne ‚Äúspise‚Äù r√¶kker i praksis, afh√¶ngigt af hvordan data er blevet skrevet.
# Her holder vi derfor transformationen minimal og kontrollerer match senere.
VFF_HOME_ID <- "KLUB046"

program2 <- program1 |>
  filter(hjemme_klubID == VFF_HOME_ID) |>
  transmute(
    kamp_id,
    dato,
    ugedag,
    tid
  )

cat("program2 (VFF hjemme) r√¶kker:", nrow(program2), "\n")

tibble(program2)

```

![](images/2026-01-04_10h51_06.png)

## Sammenk√¶dning af kampprogram og VFF-data

I dette trin kobles kampprogrammets oplysninger p√• datas√¶ttet med Viborg FF‚Äôs hjemmekampe ved hj√¶lp af kamp_id som f√¶lles n√∏gle. VFF-datas√¶ttet behandles som master, s√• alle VFF-kampe bevares, mens dato, ugedag og kickoff-tid kun tilf√∏jes, hvor der findes et gyldigt match i programmet. Datatyper h√•ndteres eksplicit for at sikre, at kampdato og kampstartstid kan anvendes robust i den videre analyse og modellering.

```{r}
# ====================================================================
# Join: tilf√∏j programoplysninger til VFF1 (kamp_id som n√∏gle)
# ====================================================================
# Vi anvender left_join, fordi VFF1 er vores master: Vi vil bevare alle VFF-kampe
# og kun tilf√∏je dato/ugedag/tid fra programmet hvor der findes match.
#
# Datatyper:
# - dato kommer fra Azure som Date og kan derfor beholdes som Date.
# - tid kommer som character og konverteres til hms, s√• den kan bruges til
#   at udlede kickoff-time robust.
VFF1_med_program <- VFF1 |>
  mutate(kamp_id = as.character(kamp_id)) |>
  left_join(
    program2 |> mutate(kamp_id = as.character(kamp_id)),
    by = "kamp_id"
  ) |>
  mutate(
    kamp_dato = as.Date(dato),
    kamp_tid  = hms::as_hms(tid),
    kamp_time = as.integer(lubridate::hour(kamp_tid))
  )
View(VFF1_med_program);str(VFF1_med_program)


```

![](images/2026-01-04_10h53_16.png)

## Sanity check af join og tidskonvertering

Dette trin fungerer som et afg√∏rende sanity check efter joinet mellem kampprogram og VFF-data. Her kontrolleres det, om der opst√•r manglende v√¶rdier i kampdato, kampstartstid eller afledt kamp-time, hvilket typisk indikerer manglende match p√• kamp_id eller uventede datatyper. I baseline-kontekst er fuld d√¶kning afg√∏rende, da manglende programoplysninger ellers kan f√∏re til modellering p√• ufuldst√¶ndige eller misvisende data.

```{r}
# Sanity check:
# Hvis join/konvertering giver NA p√• kamp_dato/kamp_tid, betyder det typisk
# manglende match p√• kamp_id eller uventet format. I baseline-kontekst √∏nsker vi
# fuld d√¶kning, fordi vi ellers modellerer p√• ‚Äúhalv data‚Äù.
join_diag <- VFF1_med_program |>
  summarise(
    r√¶kker_total   = n(),
    uden_kamp_dato = sum(is.na(kamp_dato)),
    uden_kamp_tid  = sum(is.na(kamp_tid)),
    uden_kamp_time = sum(is.na(kamp_time))
  )

print(join_diag)
```

## Validering af fuld join-d√¶kning f√∏r baseline-modellering

Dette afsluttende trin dokumenterer og h√•ndh√¶ver, at joinet mellem billetsalgsdata og kampprogram er fuldst√¶ndigt. Konklusionen baseres p√• join-diagnostikken og viser, at alle VFF-kampe har gyldige v√¶rdier for kampdato og kampstartstid. Dermed er de centrale kalenderoplysninger fuldt tilg√¶ngelige, og baseline-modellen kan bygges uden risiko for at inkludere r√¶kker med manglende programdata. Skulle der mod forventning opst√• manglende match, stoppes processen eksplicit for at forhindre modellering p√• ufuldst√¶ndige data.

```{r}

# Join-diagnostikken viser fuld d√¶kning: 0 uden_kamp_dato, 0 uden_kamp_tid og
# 0 uden_kamp_time. Det betyder, at alle VFF-kampe i billetsalgsdatas√¶ttet har
# fundet et match i kampprogrammet p√• kamp_id, og at de centrale kalenderfelter
# derfor er komplet tilg√¶ngelige for baseline-modellering. Dermed undg√•r vi at
# bygge modellen p√• r√¶kker med manglende programoplysninger.

if (join_diag$uden_kamp_dato > 0 || join_diag$uden_kamp_tid > 0) {
  cat("\n‚ö†Ô∏è Manglende match efter join. Udsnit af problemr√¶kker:\n\n")
  print(
    VFF1_med_program |>
      filter(is.na(kamp_dato) | is.na(kamp_tid)) |>
      select(kamp_id, s√¶son, runde, hjemme_klubID, ude_klubID, dato, tid, ugedag) |>
      head(20)
  )
  stop("Stopper: join-d√¶kning fejlede. Baseline m√• ikke bygges p√• NA-join.")
}

```

## Opbygning af f√¶lles baseline-datas√¶t

I dette trin konstrueres det f√¶lles baseline-datas√¶t, som fungerer som det analytiske referencepunkt for den videre modellering. Datas√¶ttet indeholder udelukkende variable, der er kendt f√∏r kampafvikling, og dermed undg√•s informationsl√¶kage allerede i udgangspunktet. Ved at kombinere s√¶son, runde, kampstartstid og ugedag med tilskuertallet skabes et enkelt, men informativt grundlag, der kan indfange strukturelle og kalenderrelaterede forskelle mellem kampene. Baseline1 giver samtidig et klart overblik over variationen i tilskuertal og dokumenterer, at der er tilstr√¶kkelig spredning i data til, at meningsfuld modellering kan gennemf√∏res.

```{r}
# =============================================================================
# 5) Baseline-datas√¶t (baseline1)
# =============================================================================
# Baseline konstrueres med variable, der er kendt f√∏r kampafvikling:
# - s√¶son: strukturelle forskelle mellem √•r (sportslig status, stadion, √∏konomi)
# - runde: position i s√¶sonforl√∏b (momentum, vigtighed, vejr s√¶sonm√¶ssigt)
# - kamp_time: kickoff-slot (tilg√¶ngelighed, tv-slot, transport)
# - ugedag: testes som kalender-effekt, men forventes ikke n√∏dvendigvis st√¶rk
#
# Vi filtrerer til r√¶kker med responsvariabel (tilskuere) samt valid kamp_dato.
baseline1 <- VFF1_med_program |>
  filter(!is.na(kamp_dato), !is.na(tilskuere)) |>
  transmute(
    kamp_id   = as.character(kamp_id),  # <-- TILF√òJET: kamp_id fra VFF1 (n√∏gle, ikke feature)
    kamp_dato,
    s√¶son     = as.factor(s√¶son),
    runde     = as.integer(runde),
    ugedag    = as.factor(ugedag),
    kamp_time = as.integer(kamp_time),
    tilskuere = as.numeric(tilskuere)
  )

cat("\nbaseline1 r√¶kker:", nrow(baseline1), "\n")
print(str(baseline1))
print(summary(baseline1$tilskuere))

View(baseline1)

# Baseline1 best√•r af 259 observationer (VFF-hjemmekampe). Tilskuertallet varierer
# fra 1074 til 9523, med median 4545 og gennemsnit 4778,7. Spredningen er tydelig,
# hvilket g√∏r det relevant at etablere en baseline-model, der kan forklare en del
# af variationen ved hj√¶lp af simple, tidligt kendte variable.


```

![](images/2026-01-04_10h43_08.png)

## Gemning og fastl√¶ggelse af baseline

I dette trin gemmes baseline-datas√¶ttet lokalt som et f√¶lles udgangspunkt for alle prognosemodeller, s√• senere scripts kan genbruge det samme grundlag uden at gentage datatrin.

```{r}
baseline_dir <- "C:/Users/janpe/OneDrive/Skrivebord/PBA Dataanlyse/01_F√∏rste semester/1 Semester projekt/Baseline"

# Opret mappen hvis den ikke findes (reproducerbarhed)
dir.create(baseline_dir, recursive = TRUE, showWarnings = FALSE)

baseline_file <- file.path(baseline_dir, "baseline_azure.rds")

saveRDS(baseline1, baseline_file)

cat("üíæ Gemte baseline til:", baseline_file, "\n")
cat("üìå Working directory:", normalizePath(getwd()), "\n")
```

# Stam-baseline med kamptid

Dette afsnit etablerer et f√¶lles metodisk mere detaljeret stampunkt, som fungerer som afs√¶t for den videre analyse. Baseline anvendes ikke som en endelig model, men som et referencegrundlag, der l√∏bende udvides og justeres, s√• effekten af nye variable og antagelser kan vurderes systematisk p√• tv√¶rs af prognosehorisonter.

## Pakker og globale indstillinger

Her etableres et stabilt og reproducerbart analyse-setup ved at indl√¶se de n√∏dvendige pakker p√• tv√¶rs af maskiner. Startup-beskeder undertrykkes for at holde output roligt i console og globale indstillinger justeres, s√• numeriske v√¶rdier pr√¶senteres klart og uden videnskabelig notation.

```{r}
# Vi undertrykker startup-messages for at holde output roligt og l√¶sbart i en
# rapportkontekst. pacman::p_load sikrer ens setup p√• tv√¶rs af maskiner.
suppressPackageStartupMessages({
  if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
  pacman::p_load(DBI, odbc, dplyr, lubridate, rstudioapi, hms, stringr)
})

# scipen = 999 fjerner videnskabelig notation, s√• tal fremst√•r mere intuitive.
options(scipen = 999)

cat("Pakker er nu klar ‚Äì god arbejdslyst!\n\n")

```

## Sikker og reproducerbar Azure-forbindelse

Dette trin sikrer b√•de korrekt konfiguration af milj√∏variabler og en stabil forbindelse til Azure SQL. Credentials h√•ndteres via .Renviron for at undg√• hardcoding og sikre reproducerbarhed p√• tv√¶rs af maskiner, mens en eksplicit retry-mekanisme reducerer risikoen for sporadiske forbindelsesfejl under analyse- og rapportk√∏rsler.

```{r, eval=FALSE}
DBI::dbDisconnect(con)

# ====================================================================
# Safeguard: .Renviron + Azure forbindelse (reproducerbarhed)
# ====================================================================
# Vi bruger milj√∏variabler til credentials, s√• scriptet kan k√∏res p√• tv√¶rs af
# maskiner uden hardcodede n√∏gler. Hvis noget mangler, fejler vi tidligt og
# tydeligt.
ensure_renviron <- function() {
  required_vars <- c("AZURE_SQL_SERVER", "AZURE_SQL_DB", "AZURE_SQL_UID", "AZURE_SQL_PWD")
  values <- Sys.getenv(required_vars)
  missing_vars <- required_vars[values == ""]
  
  if (length(missing_vars) > 0) {
    cat("‚ö†Ô∏è F√∏lgende milj√∏variabler mangler i .Renviron:\n")
    print(missing_vars)
    cat("\n√Öbner ~/.Renviron ‚Äì udfyld v√¶rdierne, gem, og genstart R.\n")
    file.edit("~/.Renviron")
    
    if (rstudioapi::isAvailable()) {
      rstudioapi::restartSession()
    } else {
      stop("rstudioapi er ikke tilg√¶ngelig ‚Äì genstart R manuelt og k√∏r igen.")
    }
  } else {
    cat("‚úî Alle n√∏dvendige .Renviron-variabler er sat.\n\n")
  }
}

# Vi bruger en retry-funktion, fordi Azure-forbindelser i praksis kan fejle
# sporadisk (timeout, netv√¶rk, cold start). Metoden √∏ger robusthed og minimerer
# ‚Äútilf√¶ldige fejl‚Äù under rapportk√∏rsler.
connect_azure_retry <- function(
    fors√∏g_max = 6,
    timeouts  = c(60, 180, 200, 260, 360, 600),
    delay_sec = 10
) {
  fors√∏g <- 1
  con <- NULL
  
  while (fors√∏g <= fors√∏g_max && is.null(con)) {
    timeout_brug <- timeouts[min(fors√∏g, length(timeouts))]
    cat("Fors√∏g", fors√∏g, "p√• at forbinde (ConnectionTimeout =", timeout_brug, "sekunder)...\n")
    
    con_try <- try(
      DBI::dbConnect(
        odbc::odbc(),
        driver   = "ODBC Driver 18 for SQL Server",
        server   = Sys.getenv("AZURE_SQL_SERVER"),
        database = Sys.getenv("AZURE_SQL_DB"),
        uid      = Sys.getenv("AZURE_SQL_UID"),
        pwd      = Sys.getenv("AZURE_SQL_PWD"),
        port     = 1433,
        Encrypt  = "yes",
        TrustServerCertificate = "no",
        ConnectionTimeout      = timeout_brug
      ),
      silent = TRUE
    )
    
    if (!inherits(con_try, "try-error")) {
      con <- con_try
      cat("‚úÖ Forbundet til:", Sys.getenv("AZURE_SQL_DB"), "p√• fors√∏g", fors√∏g, "\n\n")
      return(con)
    }
    
    cat("‚ùå Forbindelsen fejlede p√• fors√∏g", fors√∏g, "\n")
    if (fors√∏g == fors√∏g_max) stop("Kunne ikke forbinde til Azure SQL efter ", fors√∏g_max, " fors√∏g.\n")
    
    cat("Venter", delay_sec, "sekunder f√∏r n√¶ste fors√∏g...\n\n")
    Sys.sleep(delay_sec)
    fors√∏g <- fors√∏g + 1
  }
  
  stop("Uventet: forlod retry-loop uden forbindelse.")
}

ensure_renviron()
con <- connect_azure_retry()
on.exit(try(DBI::dbDisconnect(con), silent = TRUE), add = TRUE)


```

## Indl√¶sning af join-ready data fra Azure

I dette trin indl√¶ses de n√∏dvendige datas√¶t direkte fra Azure SQL ved hj√¶lp af dbReadTable uden brug af SQL-queries. Superliga-programmet anvendes som strukturelt grundlag, mens Viborg FF‚Äôs hjemmekampe med tilskuertal udg√∏r m√•lvariablen i analysen. Data hentes fra join-ready-laget for at sikre konsistens og klarhed i det videre analysearbejde.

```{r}

# =============================================================================
# Hent data fra Azure (ingen SQL-queries, kun dbReadTable)
# =============================================================================
con <- DBI::dbConnect(
  odbc::odbc(),
  Driver   = "ODBC Driver 18 for SQL Server",
  Server   = Sys.getenv("AZURE_SQL_SERVER"),
  Database = Sys.getenv("AZURE_SQL_DB"),
  UID      = Sys.getenv("AZURE_SQL_UID"),
  PWD      = Sys.getenv("AZURE_SQL_PWD"),
  Encrypt  = "yes"
)

# program1 indeholder hele Superliga-programmet (mange klubber).
# VFF1 indeholder Viborg FF hjemmekampe med tilskuere/billetsalg (vores target).
schema_program <- "PBA03_JoinReady"
schema_vff     <- "PBA03_JoinReady"
tbl_program    <- "fact_superliga_program_join_ready"
tbl_vff        <- "fact_VFF_Billetsalg_join_ready"

program1 <- DBI::dbReadTable(con, DBI::Id(schema = schema_program, table = tbl_program)) |> as_tibble()
VFF1     <- DBI::dbReadTable(con, DBI::Id(schema = schema_vff,     table = tbl_vff))     |> as_tibble()

cat("program1 r√¶kker:", nrow(program1), " | VFF1 r√¶kker:", nrow(VFF1), "\n\n")


```

## Afgr√¶nsning til Viborg FF‚Äôs hjemmebanekampe

Her afgr√¶nses kampprogrammet til udelukkende at omfatte Viborg FF‚Äôs hjemmebanekampe, s√• det matcher billetsalgsdatas√¶ttet. Transformationen holdes bevidst minimal for at undg√• utilsigtet tab af r√¶kker, hvilket tidligere har vist sig at kunne opst√• ved mere aggressive deduplikeringer.

```{r}

# ====================================================================
# Afgr√¶nsning: VFF hjemmebanekampe i programmet
# ====================================================================
# VFF1 indeholder kun VFF hjemmekampe. Programmet indeholder alt. Derfor
# filtrerer vi programmet til de r√¶kker, hvor hjemme_klubID er Viborg FF.
#
# Vigtigt: I vores tidligere fejls√∏gning viste det sig, at aggressive distinct()
# kunne ‚Äúspise‚Äù r√¶kker i praksis, afh√¶ngigt af hvordan data er blevet skrevet.
# Her holder vi derfor transformationen minimal og kontrollerer match senere.
VFF_HOME_ID <- "KLUB046"

program2 <- program1 |>
  filter(hjemme_klubID == VFF_HOME_ID) |>
  transmute(
    kamp_id,
    dato,
    ugedag,
    tid
  )

cat("program2 (VFF hjemme) r√¶kker:", nrow(program2), "\n")


```

## Sammenk√¶dning af kampprogram og VFF-data

I dette trin sammenk√¶des kampprogrammets oplysninger med VFF‚Äôs billetsalgsdata ved hj√¶lp af kamp_id som f√¶lles n√∏gle. VFF-datas√¶ttet behandles som master, s√• alle hjemmekampe bevares, mens dato og kickoff-tid tilf√∏jes, hvor der findes et match. Tidsfeltet parses robust for at h√•ndtere forskellige formater og sikre korrekt afledning af kampstartstid, som senere anvendes i b√•de baseline og feature-joins.

```{r}

# ====================================================================
# Join: tilf√∏j programoplysninger til VFF1 (kamp_id som n√∏gle)
# ====================================================================
# Vi anvender left_join, fordi VFF1 er vores master: Vi vil bevare alle VFF-kampe
# og kun tilf√∏je dato/ugedag/tid fra programmet hvor der findes match.
#
# Datatyper:
# - dato kommer fra Azure som Date og kan derfor beholdes som Date.
# - tid kommer som character (eller nogle gange ‚Äúgrimt‚Äù format) og konverteres til hms,
#   s√• den kan bruges til at udlede kickoff-time robust.
#

parse_tid_robust <- function(x) {
  # h√•ndter NA
  if (all(is.na(x))) return(hms::as_hms(NA))
  
  # hvis det er numeric (Excel-tid), s√• er det typisk fraktion af d√∏gn
  if (is.numeric(x)) {
    secs <- round(x * 86400)
    return(hms::as_hms(secs))
  }
  
  x_chr <- stringr::str_trim(as.character(x))
  x_chr <- ifelse(grepl("^[0-9]{1,2}$", x_chr), paste0(x_chr, ":00:00"), x_chr)
  x_chr <- ifelse(grepl("^[0-9]{1,2}:[0-9]{2}$", x_chr), paste0(x_chr, ":00"), x_chr)
  
  t <- suppressWarnings(hms::as_hms(x_chr))
  
  # fallback: pr√∏v lubridate::hm hvis as_hms ikke kan
  if (all(is.na(t))) {
    hm_try <- suppressWarnings(lubridate::hm(x_chr))
    if (!all(is.na(hm_try))) t <- hms::as_hms(format(hm_try, "%H:%M:%S"))
  }
  
  return(t)
}

VFF1_med_program <- VFF1 |>
  mutate(kamp_id = as.character(kamp_id)) |>
  left_join(
    program2 |> mutate(kamp_id = as.character(kamp_id)),
    by = "kamp_id"
  ) |>
  mutate(
    kamp_dato = as.Date(dato),
    kamp_tid  = parse_tid_robust(tid),
    kamp_time = as.integer(lubridate::hour(kamp_tid)),
    # kamp_dt_local er n√∏glen du skal bruge til vejr senere
    kamp_dt_local = as.POSIXct(
      paste(kamp_dato, format(kamp_tid, "%H:%M:%S")),
      tz = "Europe/Copenhagen"
    )
  )

str(VFF1_med_program)

```

![](images/2026-01-04_11h29_45.png)

## Sanity check af join og tidsfelter

Dette trin kontrollerer, at joinet mellem kampprogram og VFF-data er fuldst√¶ndigt, og at alle centrale tidsfelter er korrekt dannet. Eventuelle NA-v√¶rdier i kampdato, kampstartstid eller afledte tidsvariable indikerer typisk manglende match eller formatproblemer og er uacceptable i baseline-kontekst, hvor fuld datad√¶kning er et krav.

```{r}

# Sanity check:
# Hvis join/konvertering giver NA p√• kamp_dato/kamp_tid, betyder det typisk
# manglende match p√• kamp_id eller uventet format. I baseline-kontekst √∏nsker vi
# fuld d√¶kning, fordi vi ellers modellerer p√• ‚Äúhalv data‚Äù.
join_diag <- VFF1_med_program |>
  summarise(
    r√¶kker_total     = n(),
    uden_kamp_dato   = sum(is.na(kamp_dato)),
    uden_kamp_tid    = sum(is.na(kamp_tid)),
    uden_kamp_time   = sum(is.na(kamp_time)),
    uden_kamp_dt_loc = sum(is.na(kamp_dt_local))
  )

View(join_diag)

```

![](images/2026-01-04_11h31_30.png)

## Bekr√¶ftelse af fuld join-d√¶kning

Join-diagnostikken viser fuld d√¶kning uden manglende v√¶rdier i kampdato, kickoff-tid eller lokal kamp-datetime. Det betyder, at alle VFF-hjemmekampe har et entydigt match i kampprogrammet, og at de centrale kalender- og tidsfelter er komplet tilg√¶ngelige. Dermed kan baseline bygges p√• et fuldt og konsistent datagrundlag uden risiko for modellering p√• ufuldst√¶ndige r√¶kker.

```{r}
# Join-diagnostikken viser fuld d√¶kning: 0 uden_kamp_dato, 0 uden_kamp_tid og
# 0 uden_kamp_time. Det betyder, at alle VFF-kampe i billetsalgsdatas√¶ttet har
# fundet et match i kampprogrammet p√• kamp_id, og at de centrale kalenderfelter derfor er komplet tilg√¶ngelige for baseline-modellering Dermed undg√•r vi at bygge modellen p√• r√¶kker med manglende programoplysninger.

if (join_diag$uden_kamp_dato > 0 || join_diag$uden_kamp_tid > 0 || join_diag$uden_kamp_dt_loc > 0) {
  cat("\n‚ö†Ô∏è Manglende match efter join. Udsnit af problemr√¶kker:\n\n")
  print(
    VFF1_med_program |>
      filter(is.na(kamp_dato) | is.na(kamp_tid) | is.na(kamp_dt_local)) |>
      select(kamp_id, s√¶son, runde, hjemme_klubID, ude_klubID, dato, tid, ugedag) |>
      head(20)
  )
  stop("Stopper: join-d√¶kning fejlede. Baseline m√• ikke bygges p√• NA-join.")
}

```

## Konstruktion af stam-baseline (baseline1)

I dette trin opbygges baseline1 som et f√¶lles stam-datas√¶t baseret udelukkende p√• information, der er kendt f√∏r kampafvikling. Datas√¶ttet er bevidst konstrueret som et datagrundlag ‚Äì ikke som en f√¶rdig model ‚Äì og indeholder b√•de n√∏glefelter og centrale kalender- og tidsvariable, s√• efterf√∏lgende feature-scripts kan arbejde videre uden at gentage joins. Baseline1 fungerer dermed som det stabile referencepunkt for al videre analyse og modellering.

```{r}

# ====================================================================
# Baseline-datas√¶t (baseline1)
# ====================================================================
#
# VIGTIGT:
# - Baseline er et dataset. Ikke en model.
# - Derfor gemmer vi ogs√• stamdatafelter (kamp_dato, kamp_tid, kamp_dt_local)
#   s√• alle feature-scripts kan arbejde videre uden at gen-joine programmet igen.
#
# Vi filtrerer til r√¶kker med responsvariabel (tilskuere) samt valid kamp_dato.
baseline1 <- VFF1_med_program |>
  filter(!is.na(kamp_dato), !is.na(tilskuere)) |>
  transmute(
    kamp_id       = as.character(kamp_id),  # n√∏gle
    kamp_dato     = kamp_dato,              # dato (Date)
    kamp_tid      = kamp_tid,               # tid (hms)
    kamp_dt_local = kamp_dt_local,          # fuld datetime (POSIXct, Europe/Copenhagen)
    kamp_time     = as.integer(kamp_time),  # time som tal
    
    s√¶son     = as.factor(s√¶son),
    runde     = as.integer(runde),
    ugedag    = as.factor(ugedag),
    tilskuere = as.numeric(tilskuere)
  )

cat("\nbaseline1 r√¶kker:", nrow(baseline1), "\n")
print(str(baseline1))
print(summary(baseline1$tilskuere))

```

![](images/2026-01-04_11h32_27.png)

## Gemning af baseline som f√¶lles input til videre analyse

I dette trin gemmes stam-baseline lokalt som RDS-filer, s√• alle prognose- og feature-scripts kan tage udgangspunkt i det samme datas√¶t uden at gentage joins og typekonverteringer. Ved at gemme b√•de en klassisk baseline og en eksplicit navngivet ‚Äúfuture baseline feature‚Äù sikres et klart og ensartet udgangspunkt for videre modellering p√• tv√¶rs af prognosehorisonter.

```{r}
# ====================================================================
# Gem baseline lokalt (genbrug i D10/D7/D3 og lang horisont)
# =============================================================================
# Vi gemmer baseline1 som RDS i projektets Baseline-mappe, s√• alle prognose-scripts
# kan starte fra samme datas√¶t uden at gentage joins og typekonvertering.
# Der bruges en absolut sti, s√• output placeres entydigt uafh√¶ngigt af working directory.

baseline_dir <- "C:/Users/janpe/OneDrive/Skrivebord/PBA Dataanlyse/01_F√∏rste semester/1 Semester projekt/Baseline"

# Opret mappen hvis den ikke findes (reproducerbarhed)
dir.create(baseline_dir, recursive = TRUE, showWarnings = FALSE)

#  Gem den ‚Äúklassiske‚Äù baseline (som f√∏r)
baseline_file <- file.path(baseline_dir, "baseline_azure.rds")
saveRDS(baseline1, baseline_file)
cat("üíæ Gemte baseline til:", baseline_file, "\n")
cat("üìå Working directory:", normalizePath(getwd()), "\n")

#  Gem en ‚Äúfuture baseline feature‚Äù (samme baseline, men tydeligt navngivet til feature-scripts)
# NOTE:
# - Den her fil er din nye standard input til feature scripts (vejr, mm.)
future_baseline_file <- file.path(baseline_dir, "future_baseline_feature_azure.rds")
saveRDS(baseline1, future_baseline_file)
cat("üíæ Gemte FUTURE baseline feature til:", future_baseline_file, "\n")
```

# ML model D3

Denne analyse implementerer en reproducerbar pipeline til at forudsige tilskuertal (D3) for VFF-kampe baseret p√• et samlet kampdatas√¶t. Data hentes fra Azure SQL og en lokal baseline (RDS), hvorefter centrale felter valideres, dubletter fjernes, og kampstartstid standardiseres til en numerisk timevariabel. Herefter konstrueres et feature-s√¶t ved at join‚Äôe helligdage, SAH-h√•ndboldaktivitet, befolkningstal (matchet som n√¶rmeste tidligere dato), vejr (n√¶rmeste faste observationstid) og temperatur (seneste observation f√∏r kickoff). Yderligere inkluderes sportslige og kontekstuelle variable, herunder placering f√∏r kamp og modstander, med robust h√•ndtering af faktorniveauer mellem tr√¶ning og test. Det endelige analysedatas√¶t sorteres kronologisk og opdeles i et tidsbaseret 80/20 train-test split for at minimere risikoen for fremtidskig. Modeller estimeres og sammenlignes p√• samme split via (1) stepwise OLS med AIC, (2) best subset selection med BIC og (3) ridge/lasso (glmnet) med krydsvalidering. For glmnet anvendes tidsblok-folds i CV for at bevare den tidslige struktur under tuning. Modelperformance evalueres konsekvent p√• testdata med RMSE, MAE, MSE og R¬≤, og resultater organiseres i strukturerede output-objekter til videre rapportering. Der indg√•r desuden en valgfri ‚Äúfair‚Äù sammenligning, hvor modeller med og uden befolkning estimeres p√• samme N for en retvisende effektvurdering. Afslutningsvist genereres figurer (Predicted vs Actual) med modeltekst, og der etableres en Shiny-prototype til interaktivt modelvalg og pr√¶diktion.

## Setup: pakker og globale indstillinger

Kort sagt initialiseres analyse-milj√∏et ved f√∏rst at sikre, at alle n√∏dvendige R-pakker er tilg√¶ngelige, hvorefter de indl√¶ses uden st√∏jende opstartsbeskeder. Afslutningsvist justeres numerisk visning (s√• store tal ikke vises i videnskabelig notation), og der printes en kort statusmeddelelse, som bekr√¶fter at milj√∏et er klar til resten af pipeline‚Äôen.

```{r}
# Form√•l: sikre at alle afh√¶ngigheder findes, og at milj√∏et er ens hver gang scriptet k√∏res.
needed_pkgs <- c("DBI","odbc","dplyr","lubridate","stringr","tibble","tidyr","ggplot2","leaps","glmnet")
# Find pakker der mangler (tjekker uden at loade dem)
missing_pkgs <- needed_pkgs[
  !vapply(needed_pkgs, requireNamespace, logical(1), quietly = TRUE)]
# Stop tidligt hvis noget mangler (fail fast), s√• resten af pipeline‚Äôen ikke k√∏rer halvt
if (length(missing_pkgs) > 0) 
  stop("‚ùå Manglende pakker: ", paste(missing_pkgs, collapse = ", "))
# Indl√¶s pakker (undertryk startup-messages for mere l√¶sbart output)
suppressPackageStartupMessages({
  library(DBI); library(odbc)
  library(dplyr); library(tidyr)
  library(lubridate); library(stringr)
  library(tibble); library(ggplot2)
  library(leaps); library(glmnet)
})
# Global indstilling: undg√• scientific notation i print (mere l√¶sbart i rapport/log)
options(scipen = 999)
# Log: bekr√¶ft at setup er gennemf√∏rt
cat("Pakker er klar ‚úÖ\n\n")

```

## Hj√¶lpefunktioner: milj√∏tjek og robust Azure SQL-forbindelse

F√∏r den egentlige dataindsamling defineres to centrale hj√¶lpefunktioner. F√∏rst valideres, at n√∏dvendige login-oplysninger til databasen findes som milj√∏variabler i .Renviron, s√• forbindelsen kan etableres sikkert og reproducerbart. Dern√¶st etableres en robust forbindelsesfunktion til Azure SQL, som fors√∏ger flere gange med stigende timeouts og korte pauser mellem fors√∏g, hvilket reducerer risikoen for, at midlertidige netv√¶rks- eller serverproblemer stopper hele pipeline‚Äôen.

```{r}
# ====================================================================
# Hj√¶lpefunktioner (√âN gang)
# ====================================================================
ensure_renviron <- function() {
  # Defin√©r hvilke milj√∏variabler der skal v√¶re sat i .Renviron
  required_vars <- c("AZURE_SQL_SERVER","AZURE_SQL_DB","AZURE_SQL_UID","AZURE_SQL_PWD")
  # Hent v√¶rdierne fra milj√∏et
  values <- Sys.getenv(required_vars)
  # Find hvilke der mangler (tom streng)
  missing_vars <- required_vars[values == ""]
  # Stop tidligt hvis noget mangler (s√• vi ikke fors√∏ger at forbinde    med tomme credentials)
  if (length(missing_vars) > 0) {
    stop("‚ùå Manglende milj√∏variabler i .Renviron: ", paste(missing_vars, collapse = ", "))
  } # Log: alt OK
  cat("‚úî .Renviron OK\n\n")
}

connect_azure_retry <- function(
  	# Maks antal forbindelsesfors√∏g
    fors√∏g_max = 6,
    # Timeouts pr. fors√∏g (stigende, s√• vi giver mere tid ved senere      fors√∏g)
    timeouts  = c(60, 180, 200, 260, 360, 600),
    # Pause mellem fors√∏g (sekunder)
    delay_sec = 10
) {
  # S√∏rg for at milj√∏variabler findes f√∏r vi fors√∏ger at forbinde
  ensure_renviron()
  # T√¶ller for antal fors√∏g
  fors√∏g <- 1
  # Loop indtil connection lykkes eller vi rammer max fors√∏g
  while (fors√∏g <= fors√∏g_max) {
    # V√¶lg timeout til dette fors√∏g (brug sidste v√¶rdi hvis fors√∏g >      l√¶ngde(timeouts))
    timeout_brug <- timeouts[min(fors√∏g, length(timeouts))]
    # Log hvilket fors√∏g og timeout vi bruger
    cat("Fors√∏g", fors√∏g, "- ConnectionTimeout =", timeout_brug, "sekunder\n")
    # Fors√∏g at oprette connection (try s√• scriptet ikke stopper ved      f√∏rste fejl)
    con_try <- try(
      DBI::dbConnect(
        odbc::odbc(),
        driver   = "ODBC Driver 18 for SQL Server",
        server   = Sys.getenv("AZURE_SQL_SERVER"),
        database = Sys.getenv("AZURE_SQL_DB"),
        uid      = Sys.getenv("AZURE_SQL_UID"),
        pwd      = Sys.getenv("AZURE_SQL_PWD"),
        Encrypt  = "yes",
        TrustServerCertificate = "no",
        ConnectionTimeout = timeout_brug
      ),
      silent = TRUE
    )
    # Hvis connection lykkes: return√©r connection-objektet
    if (!inherits(con_try, "try-error")) {
      cat("‚úÖ Forbundet til Azure SQL\n\n")
      return(con_try)
    } 
    #Hvis sidste fors√∏g ogs√• fejler: stop med tydelig fejlbesked
    if (fors√∏g == fors√∏g_max) stop("‚ùå Kunne ikke forbinde til Azure       SQL efter ", fors√∏g_max, " fors√∏g.")
    # Vent og pr√∏v igen
    Sys.sleep(delay_sec)
    fors√∏g <- fors√∏g + 1
  }
}
```

### Hj√¶lpefunktion: sikker tabelindl√¶sning (retry + logging)

Funktionen indkapsler indl√¶sning af tabeller fra databasen i en robust ‚Äúretry‚Äù-mekanisme. Den fors√∏ger at l√¶se den √∏nskede tabel et fast antal gange, logger en kort fejlbesked ved hvert mislykket fors√∏g og venter kort mellem fors√∏gene. Hvis alle fors√∏g fejler, stoppes scriptet med en tydelig fejl, s√• pipeline‚Äôen ikke forts√¶tter p√• et ufuldst√¶ndigt datagrundlag.

```{r}

# L√¶s en tabel robust med retry + fejllogning (stopper kun efter sidste fors√∏g)
   safe_dbReadTable <- function(con, schema, table, fors√∏g_max = 4,      delay_sec = 3) {
  	# Fors√∏g at l√¶se tabellen op til fors√∏g_max gange
  for (i in seq_len(fors√∏g_max)) {
    	# Fors√∏g at l√¶se schema.table (try = ingen hard stop ved fejl)
    out <- try(DBI::dbReadTable(con, DBI::Id(schema = schema, table =     table)), silent = TRUE)
    # Hvis det lykkes: return√©r data.frame med det samme
    if (!inherits(out, "try-error")) return(out)
    msg <- as.character(out)
    cat("‚ö†Ô∏è dbReadTable fejlede (fors√∏g", i, "af", fors√∏g_max, "):",      schema, ".", table, "\n")
    # Hvis det fejler: udtr√¶k fejltekst og log kort besked (f√∏rste 240     tegn)
    cat(substr(msg, 1, 240), "...\n\n")
    if (i < fors√∏g_max) Sys.sleep(delay_sec)
  }
     # Hvis alle fors√∏g fejler: stop med tydelig fejl
  stop("‚ùå Kunne ikke l√¶se tabel: ", schema, ".", table)
}


```

### Hj√¶lpefunktion: parse HH:MM(:SS) til time (0‚Äì23)

Denne funktion bruges til at udtr√¶kke timen fra tidsstrenge, s√• du kan lave robuste ‚Äún√¶r kickoff‚Äù-matches. Den normaliserer f√∏rst formatet (tilf√∏jer :00 hvis sekunder mangler), og returnerer derefter timen som integer. Hvis formatet ikke kan parses, returneres NA.

```{r}
# Hj√¶lpefunktion: udtr√¶k time fra tidsstreng (HH:MM eller HH:MM:SS)
time_chr_to_hour <- function(x) {

	# S√∏rg for at input er trimmed character
	x <- str_trim(as.character(x))

	# Hvis formatet er HH:MM, s√• g√∏r det til HH:MM:SS ved at tilf√∏je :00
	x <- if_else(str_detect(x, "^\\d{1,2}:\\d{2}$"), paste0(x, ":00"), x)

	# Tjek hvilke elementer der nu matcher HH:MM:SS
	ok <- str_detect(x, "^\\d{1,2}:\\d{2}:\\d{2}$")

	# Output: default NA, udfyld kun hvor parsing er mulig
	out <- rep(NA_integer_, length(x))
	out[ok] <- as.integer(str_extract(x[ok], "^\\d{1,2}"))

	out
}
```

### Hj√¶lpefunktioner: evalueringsm√•l til modelperformance

Her defineres en lille samling standardm√•l til at evaluere og sammenligne modeller. Funktionerne beregner henholdsvis RMSE, MAE og MSE som fejlm√•l samt R¬≤ som forklaringsgrad, hvor der indbygges robusthed over for manglende v√¶rdier (NA). I R¬≤-funktionen h√•ndteres specialtilf√¶ldet, hvor variationen i de observerede v√¶rdier er nul (sst = 0), s√• der ikke opst√•r division med nul.

```{r}

# RMSE: kvadratrod af gennemsnitlig kvadreret fejl (straffer store fejl relativt h√•rdt)
rmse_vec <- function(y, yhat) sqrt(mean((as.numeric(y) - as.numeric(yhat))^2, na.rm = TRUE))

# MAE: gennemsnitlig absolut fejl (mere robust end RMSE overfor outliers)
mae_vec  <- function(y, yhat) mean(abs(as.numeric(y) - as.numeric(yhat)), na.rm = TRUE)

# MSE: gennemsnitlig kvadreret fejl (samme som RMSE men uden kvadratrod)
mse_vec  <- function(y, yhat) mean((as.numeric(y) - as.numeric(yhat))^2, na.rm = TRUE)

# R¬≤: 1 - (SSE/SST), dvs. hvor stor del af variationen i y modellen forklarer
# H√•ndterer specialtilf√¶lde hvor SST = 0 (ingen variation i y) for at undg√• division med 0
r2_vec <- function(y, yhat) {
  y <- as.numeric(y); yhat <- as.numeric(yhat)
  sse <- sum((y - yhat)^2, na.rm = TRUE)
  sst <- sum((y - mean(y, na.rm = TRUE))^2, na.rm = TRUE)
  if (isTRUE(all.equal(sst, 0))) return(NA_real_)
  1 - (sse / sst)
}

```

### Hj√¶lpefunktioner: afgr√¶nsning af output og robust kolonnevalg

Disse to funktioner bruges som sm√•, praktiske byggesten i pipeline‚Äôen. Den f√∏rste sikrer, at numeriske outputs (fx predictioner) holdes inden for et realistisk interval ved at klippe v√¶rdier under 0 og over en valgt maksimumgr√¶nse. Den anden finder den f√∏rste kolonne i et datas√¶t, der matcher en liste af mulige kolonnenavne, hvilket g√∏r koden robust over for variationer i navngivning p√• tv√¶rs af tabeller og versioner.

```{r}
# Hj√¶lpefunktion: klip v√¶rdier til et realistisk interval [0, cap]
# Form√•l: undg√• negative predictioner og urealistisk h√∏je v√¶rdier i output
clip_0_cap <- function(x, cap = 10000) pmax(pmin(as.numeric(x), as.numeric(cap)), 0)

# Hj√¶lpefunktion: find f√∏rste eksisterende kolonne blandt flere mulige navne
# Form√•l: g√∏re koden robust hvis kolonnenavne varierer mellem tabeller/versioner
find_first_col <- function(df, candidates) {
  hit <- candidates[candidates %in% names(df)][1]
  if (is.na(hit)) return(NA_character_)
  hit
}

```

### Hj√¶lpefunktion: fjern kolonner uden variation (0-varians)

Funktionen bruges til at rense en designmatrix (fx fra model.matrix) ved at fjerne kolonner, som ikke varierer i data. Det er is√¶r relevant f√∏r variabelselektion eller regulariserede modeller, fordi 0-varians-kolonner ikke bidrager med information og kan skabe un√∏dvendig kompleksitet. Hvis input er tomt eller NULL, returneres objektet u√¶ndret.

```{r}
# Hj√¶lpefunktion: fjern kolonner uden variation (0-varians)
# Form√•l: droppe uinformative features (fx dummy-kolonner der altid er 0/1 konstant),
# s√• model-fitting bliver mere stabilt og mindre st√∏jfyldt.
drop_zero_variance_cols <- function(X) {
  # Hvis X er NULL eller tom (ingen kolonner), return√©r u√¶ndret
  if (is.null(X) || ncol(X) == 0) return(X)
  # Beregn varians pr. kolonne (NA ignoreres)
  v <- apply(X, 2, function(col) stats::var(as.numeric(col), na.rm = TRUE))
  # Behold kun kolonner hvor variansen er defineret og st√∏rre end 0
  keep <- !(is.na(v) | v == 0)
  # Return√©r den filtrerede matrix (drop=FALSE bevarer matrix-format
  X[, keep, drop = FALSE]
}
```

### Hj√¶lpefunktion: ens dummy-kodning i train/test (model.matrix)

Form√•let er at sikre, at train og test f√•r pr√¶cis de samme dummy-kolonner, s√• modeller ikke fejler eller bliver inkonsistente pga. forskellige faktorniveauer. Det l√∏ses ved at kombinere datas√¶ttene f√∏r model.matrix, fjerne intercept-kolonnen og derefter splitte designmatricen tilbage i train og test.

```{r}
# Hj√¶lpefunktion: ens model.matrix for train/test (samme dummy-kolonner)
# Form√•l: undg√• at train og test f√•r forskellige kolonner pga. forskellige faktor-niveauer.
# Metode: kombiner train+test, byg model.matrix √©n gang, split derefter tilbage.
make_mm_train_test <- function(train_df, test_df, mm_formula) {
  	# Tilf√∏j en split-mark√∏r, s√• vi kan splitte korrekt efter              bind_rows()
  train_df$.split <- "train"
  test_df$.split  <- "test"
  	# Kombin√©r data for at sikre identisk dummy-kodning p√• tv√¶rs af       train/test
  combo <- bind_rows(train_df, test_df)
  	# Byg designmatrix ud fra samme formel p√• hele datas√¶ttet
  X_combo <- stats::model.matrix(mm_formula, data = combo)
  	# Fjern intercept-kolonne hvis den er med (mange workflows             h√•ndterer intercept separat)
  if ("(Intercept)" %in% colnames(X_combo)) {
    X_combo <- X_combo[, colnames(X_combo) != "(Intercept)", drop = FALSE]
  }
  # Split designmatrix tilbage til train og test (samme kolonner i      begge)
  X_train <- X_combo[combo$.split == "train", , drop = FALSE]
  X_test  <- X_combo[combo$.split == "test",  , drop = FALSE]
  
  # Return√©r begge matricer samlet
  list(X_train = X_train, X_test = X_test)
}
```

### Hj√¶lpefunktioner: tidsblokke til CV, s√¶son-start og robust faktorh√•ndtering

Her defineres tre sm√• hj√¶lpefunktioner, som sikrer en mere realistisk validering og mere stabile modelk√∏rsler. F√∏rst oprettes et foldid som sammenh√¶ngende tidsblokke til krydsvalidering, s√• tr√¶ningen ikke blandes tilf√¶ldigt p√• tv√¶rs af tid. Dern√¶st udtr√¶kkes s√¶sonens start√•r som numerisk variabel til modeller, hvor faktorer kan give un√∏digt mange dummyer. Til sidst standardiseres faktorniveauer mellem tr√¶ning og test ved at mappe ukendte eller manglende niveauer til en f√¶lles ‚ÄúANDRE‚Äù-kategori, s√• predict() ikke fejler.

```{r}
# CV foldid som tidsblokke (undg√•r random fremtidskig i tr√¶ning)
# Form√•l: lave fold-inddeling til CV, hvor observationer holdes i sammenh√¶ngende tidsblokke.
# Dette reducerer leakage ift. tid (dvs. at ‚Äúfremtiden‚Äù ikke blandes ind i tr√¶ningen tilf√¶ldigt).
make_time_block_foldid <- function(n, k = 10) {
  	# Hvis datas√¶ttet er mindre end antal folds, s√• s√¶nk k (men mindst 2)
  if (n < k) k <- max(2, min(k, n))
  	# Block size s√• alle r√¶kker bliver fordelt p√• ~k blokke
  block_size <- ceiling(n / k)
  	# Byg foldid: 1,1,1,...,2,2,2,... (tidsblokke) og klip til l√¶ngde n
  rep(seq_len(k), each = block_size)[seq_len(n)]
}

# Udtr√¶k s√¶sonens start√•r (fx "2022/2023" -> 2022)
# Form√•l: konvertere s√¶son til en numerisk variabel (ofte for at undg√• mange dummy-kolonner).

season_start_year <- function(x) suppressWarnings(as.integer(substr(as.character(x), 1, 4)))

# Robust faktorh√•ndtering mellem train/test
# Form√•l: sikre at test ikke indeholder nye/ukendte niveauer som f√•r predict()/model.matrix til at fejle.
# Metode: niveauer defineres ud fra train; ukendte eller NA i test mappes til "ANDRE".
safe_factor_with_other <- function(train_vec, test_vec, other_level = "ANDRE") {
  train_chr <- as.character(train_vec)
  test_chr  <- as.character(test_vec)
  lvls <- sort(unique(train_chr))
  if (!(other_level %in% lvls)) lvls <- c(lvls, other_level)
  test_chr[is.na(test_chr) | !(test_chr %in% lvls)] <- other_level
  list(
    train = factor(train_chr, levels = lvls),
    test  = factor(test_chr,  levels = lvls)
  )
}
```

## Connection: valider milj√∏ og opret databaseforbindelse

Denne del af scriptet initialiserer forbindelsen til Azure SQL. F√∏rst verificeres, at n√∏dvendige milj√∏variabler er sat korrekt i `.Renviron`, s√• credentials ikke hardcodes i koden. Derefter oprettes forbindelsen med retry-logik, og der registreres en ‚Äúcleanup‚Äù-handling, s√• forbindelsen altid lukkes p√¶nt igen ved afslutning eller fejl, hvilket g√∏r pipeline‚Äôen mere stabil og reproducerbar.

```{r}


# Valid√©r at n√∏dvendige milj√∏variabler til Azure SQL findes (stopper hvis noget mangler)
ensure_renviron()
# Opret forbindelse til Azure SQL (med retry-logik i connect_azure_retry)
con <- connect_azure_retry()
# S√∏rg for at forbindelsen altid lukkes p√¶nt ved script-exit (ogs√• ved fejl)
# add = TRUE g√∏r, at denne on.exit ikke overskriver andre on.exit-calls


```

## Indl√¶sning af baseline: RDS, kvalitetstjek og konstruktion af kampstartstid

I dette afsnit indl√¶ses baseline-datas√¶ttet fra en lokal RDS-fil, og n√∏glevariable standardiseres til korrekte datatyper, s√• datas√¶ttet kan bruges konsistent i resten af pipeline‚Äôen. Herefter kontrolleres, at de n√∏dvendige kolonner findes, og der udskrives en kort status for antal r√¶kker og unikke kamp-id‚Äôer. Hvis kampstartstidspunktet (kamp_tid) mangler i baseline-filen, hentes det fra et sekund√¶rt baseline-feature-datas√¶t og joines ind p√• kamp_id, s√•ledes at kamp-tid altid er tilg√¶ngelig. Til sidst konverteres kamp-tid til en numerisk timevariabel (kamp_time_h), og datas√¶ttet kvalitetssikres ved at identificere og h√•ndtere dubletter, hvor der v√¶lges √©n r√¶kke pr. kamp_id (prioriteret efter f√¶rrest manglende v√¶rdier).

```{r}
# S√¶t mappe og filnavn til baseline-RDS (lokal fil)
baseline_dir  <- "C:/Users/janpe/OneDrive/Skrivebord/PBA Dataanlyse/01_F√∏rste semester/1 Semester projekt/Baseline"
baseline_file <- file.path(baseline_dir, "baseline_azure.rds")
# Stop hvis baseline-filen ikke findes (fail fast)
stopifnot(file.exists(baseline_file))

# Indl√¶s baseline og standardis√©r centrale datatyper
# - kamp_id: character (sikrer stabile joins)
# - kamp_dato: Date (sikrer stabile dato-joins)
baseline <- readRDS(baseline_file) %>%
  mutate(
    kamp_id   = as.character(kamp_id),
    kamp_dato = as.Date(kamp_dato)
  )
# Log: print st√∏rrelse og antal unikke kampe
stopifnot(all(c("kamp_id","kamp_dato","tilskuere") %in% names(baseline)))
# Log: print st√∏rrelse og antal unikke kampe
cat("Baseline loaded ‚úÖ  R√¶kker:", nrow(baseline),
    "Unikke kamp_id:", n_distinct(baseline$kamp_id), "\n\n")

# sikr kamp_tid
if (!("kamp_tid" %in% names(baseline))) {
  cat("‚ö†Ô∏è baseline_azure.rds har ikke 'kamp_tid'. Henter fra future_baseline_feature_azure.rds...\n")
  feature_baseline_file <- file.path(baseline_dir, "future_baseline_feature_azure.rds")
  stopifnot(file.exists(feature_baseline_file))
  
  fb <- readRDS(feature_baseline_file) %>%
    mutate(kamp_id = as.character(kamp_id), kamp_dato = as.Date(kamp_dato)) %>%
    arrange(kamp_id) %>%
    group_by(kamp_id) %>%
    slice(1) %>%
    ungroup() %>%
    select(kamp_id, kamp_tid)
  
  baseline <- baseline %>% left_join(fb, by = "kamp_id")
  rm(fb)
  cat("‚úî kamp_tid joinet ind\n\n")
}

baseline <- baseline %>%
  mutate(
    kamp_tid_chr = str_trim(as.character(kamp_tid)),
    kamp_tid_chr = if_else(str_detect(kamp_tid_chr, "^\\d{1,2}:\\d{2}$"), paste0(kamp_tid_chr, ":00"), kamp_tid_chr),
    kamp_time_h  = time_chr_to_hour(kamp_tid_chr)
  )

cat("Kamp-r√¶kker uden parsebar kamp_time_h:", sum(is.na(baseline$kamp_time_h)), "\n\n")

```

## Baseline QA: deduplikering af kamp_id (√©n r√¶kke pr. kamp)

Dette afsnit kvalitetssikrer baseline ved at finde kamp-id‚Äôer, der forekommer flere gange. Hvis der findes dubletter, v√¶lges den ‚Äúbedste‚Äù r√¶kke pr. kamp_id ved at prioritere observationen med f√¶rrest manglende v√¶rdier, s√• datatabet minimeres. Til sidst valideres det med et tjek, at baseline nu har pr√¶cis √©n r√¶kke pr. kamp.

```{r}
# dedup kamp_id
dup_ids <- baseline %>% count(kamp_id, sort = TRUE) %>% filter(n > 1)
cat("--- BASELINE QA: DUPLIKAT-TJEK ---\n")
cat("Antal kamp_id med dubletter:", nrow(dup_ids), "\n")
if (nrow(dup_ids) > 0) {
  baseline2 <- baseline
  baseline2$.na_count <- rowSums(is.na(baseline2))
  baseline <- baseline2 %>%
    arrange(kamp_id, .na_count) %>%
    group_by(kamp_id) %>%
    slice(1) %>%
    ungroup() %>%
    select(-.na_count)
  stopifnot(nrow(baseline) == n_distinct(baseline$kamp_id))
  cat("‚úÖ Baseline deduplikeret (1 r√¶kke pr kamp_id)\n\n")
} else {
  cat("‚úÖ Ingen dubletter fundet\n\n")
}
```

## Feature joins: berrig baseline med eksterne og kontekstuelle forklaringsvariabler

I dette afsnit udvides baseline-datas√¶ttet med et s√¶t forklaringsvariable, der forventes at p√•virke tilskuertallet. F√∏rst konstrueres en helligdagsindikator p√• datoniveau og joines ind p√• kampdato. Dern√¶st beregnes samtidige SAH-h√•ndboldkampe pr. dato (b√•de indikator og antal) og joines p√• kampdato. Herefter tilf√∏jes Viborgs befolkningstal ved at matche hver kampdato til n√¶rmeste tidligere registrering, s√• variablen er tidskonsistent. Endelig joines vejr og temperatur p√• kampniveau ved at v√¶lge den observation, der ligger t√¶ttest p√• kickoff inden for faste tidsgrid (vejr) samt den seneste temperaturm√•ling f√∏r kickoff samme dag (temperatur). Der etableres samtidig robuste ‚Äúmangler‚Äù-indikatorer og modelvenlige kodninger (fx vejrkode_model), s√• manglende/ikke-observerbare observationer h√•ndteres eksplicit i senere modellering.

### Helligdage: opbygning af helligdagsindikator og merge til baseline

Her hentes en helligdagskalender fra databasen og reduceres til √©t simpelt flag pr. dato (1 = helligdag). Flaget joines derefter ind i kampdata p√• kampdato, s√• hver kamp f√•r en entydig variabel. Manglende match efter join fortolkes som ‚Äúikke helligdag‚Äù og omkodes derfor til 0, s√• variablen er klar til modellering uden NA‚Äôer.

```{r}
hellig_raw <- safe_dbReadTable(con,"PBA01_Raw", "dim_helligdage_dkk_raw")
stopifnot(all(c("dato","helligdag_navn") %in% names(hellig_raw)))

hellig_min <- hellig_raw %>%
  mutate(hellig_dato = as.Date(dato)) %>%
  filter(!is.na(hellig_dato)) %>%
  group_by(hellig_dato) %>%
  summarise(er_helligdag = 1L, .groups = "drop")

baseline <- baseline %>%
  left_join(hellig_min, by = c("kamp_dato" = "hellig_dato")) %>%
  mutate(er_helligdag = if_else(is.na(er_helligdag), 0L, er_helligdag))

cat("Helligdage joinet ‚úÖ\n\n")
```

### SAH: indikator og antal h√•ndboldkampe pr. dato (join til baseline)

Her konstrueres et simpelt event-signal for SAH p√• dagsniveau. F√∏rst hentes h√•ndboldkampene, hvorefter der aggregeres pr. dato til (1) en bin√¶r indikator for om der afvikles mindst √©n kamp og (2) et antal kampe den p√•g√¶ldende dag. Disse features joines derefter ind i baseline p√• kampdato, og manglende v√¶rdier efter join omkodes til 0, s√• variablerne kan anvendes direkte i modellering.

```{r}
# 4B) SAH
sah_raw <- safe_dbReadTable(con, "PBA02_Clean", "fact_h√•ndboldkampe_SAH_clean")
stopifnot(all(c("kamp_dato","kamp_tid","Event") %in% names(sah_raw)))

sah_min <- sah_raw %>%
  mutate(sah_dato = as.Date(kamp_dato)) %>%
  filter(!is.na(sah_dato)) %>%
  group_by(sah_dato) %>%
  summarise(
    er_h√•ndboldkamp_SAH = 1L,
    antal_h√•ndboldkampe = n(),
    .groups = "drop"
  )

baseline <- baseline %>%
  left_join(sah_min, by = c("kamp_dato" = "sah_dato")) %>%
  mutate(
    er_h√•ndboldkamp_SAH = if_else(is.na(er_h√•ndboldkamp_SAH), 0L, er_h√•ndboldkamp_SAH),
    antal_h√•ndboldkampe = if_else(is.na(antal_h√•ndboldkampe), 0L, antal_h√•ndboldkampe)
  )

cat("H√•ndbold SAH joinet ‚úÖ\n\n")

```

### Befolkning: match til kampdato med ‚Äún√¶rmeste tidligere‚Äù observation

Her hentes Viborgs befolkningsdata og renses til √©n samlet tidsserie (kun totaler for k√∏n og civilstand). Derefter matches hver kamp til den seneste befolkningsobservation, der ligger p√• eller f√∏r kampdatoen, s√• vi undg√•r at bruge ‚Äúfremtidige‚Äù v√¶rdier. Til sidst joines befolkningstal ind p√• kampniveau via kamp_id, s√• baseline fortsat har √©n r√¶kke pr. kamp.

```{r}
# 4C) Befolkning (closest tidligere dato)
bef_raw <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_Viborg_befolkning_join_ready")
stopifnot(all(c("k√∏n","civilstand","dato","befolkningstal") %in% names(bef_raw)))

bef_all <- bef_raw %>%
  mutate(
    k√∏n = str_to_lower(trimws(as.character(k√∏n))),
    civilstand = str_to_lower(trimws(as.character(civilstand))),
    dato = as.Date(dato),
    befolkningstal = as.numeric(befolkningstal)
  ) %>%
  filter(
    !is.na(dato), !is.na(befolkningstal),
    k√∏n %in% c("i alt","alt"),
    civilstand %in% c("i alt","alt")
  ) %>%
  distinct(dato, .keep_all = TRUE) %>%
  arrange(dato) %>%
  transmute(bef_dato = dato, befolkningstal = befolkningstal)

baseline_bef <- baseline %>%
  transmute(kamp_id, kamp_dato) %>%
  left_join(bef_all, join_by(closest(kamp_dato >= bef_dato)))

baseline <- baseline %>%
  left_join(baseline_bef %>% select(kamp_id, befolkningstal), by = "kamp_id")

cat("Befolkning joinet ‚úÖ\n\n")

```

### Vejr: match n√¶rmeste observation til kickoff og konstru√©r model-venlige vejrvariable

Her hentes vejrdata og renses til et format, der kan matches stabilt til hver kamp. Matching sker ved f√∏rst at begr√¶nse til faste observationstidspunkter (08, 11, 14, 17) og derefter v√¶lge den observation, der ligger t√¶ttest p√• kampens kickoff-time. Hvis der ikke findes en grid-observation for kampdatoen, anvendes en fallback (f√∏rste observation p√• datoen). Til sidst joines vejr ind p√• kampniveau, og der oprettes eksplicitte ‚Äúmangler‚Äù-indikatorer samt kodninger (vejrkode_model og vejrbeskrivelse_model), s√• manglende/ikke-observerbare forhold h√•ndteres konsistent i modelleringen.

```{r}
# 4D) VEJR (n√¶rmeste blandt 8/11/14/17)
cat("\n--- FEATURE: VEJR ---\n")
vejr_sql <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_vejr_join_ready")
stopifnot(all(c("obs_dato","tid","vejrkode","vejrbeskrivelse") %in% names(vejr_sql)))

vejr_grid_tider_h <- c(8L, 11L, 14L, 17L)

vejr_pre <- vejr_sql %>%
  mutate(
    vejr_dato = if (inherits(obs_dato, "Date")) obs_dato else as.Date(obs_dato, format = "%d-%m-%Y"),
    vejr_tid_chr = str_trim(as.character(tid)),
    vejr_tid_chr = if_else(str_detect(vejr_tid_chr, "^\\d{1,2}:\\d{2}$"), paste0(vejr_tid_chr, ":00"), vejr_tid_chr),
    vejr_time_h = time_chr_to_hour(vejr_tid_chr),
    vejrkode = suppressWarnings(as.integer(vejrkode)),
    vejrbeskrivelse = as.character(vejrbeskrivelse)
  ) %>%
  filter(!is.na(vejr_dato), !is.na(vejr_time_h))

vejr_grid <- vejr_pre %>%
  filter(vejr_time_h %in% vejr_grid_tider_h) %>%
  group_by(vejr_dato, vejr_time_h) %>%
  slice(1) %>%
  ungroup()

vejr_fallback_1 <- vejr_pre %>%
  arrange(vejr_dato, vejr_time_h) %>%
  group_by(vejr_dato) %>%
  slice(1) %>%
  ungroup()

baseline_key <- baseline %>% transmute(kamp_id, kamp_dato, kamp_time_h)

kandidater_vejr <- baseline_key %>%
  filter(!is.na(kamp_dato), !is.na(kamp_time_h)) %>%
  inner_join(vejr_grid %>% select(vejr_dato, vejr_time_h, vejrkode, vejrbeskrivelse),
             by = c("kamp_dato" = "vejr_dato")) %>%
  mutate(dist_hours_to_kickoff = abs(kamp_time_h - vejr_time_h)) %>%
  group_by(kamp_id) %>%
  arrange(dist_hours_to_kickoff, .by_group = TRUE) %>%
  slice(1) %>%
  ungroup() %>%
  transmute(
    kamp_id,
    vejr_tid_h = vejr_time_h,
    vejrkode,
    vejrbeskrivelse,
    dist_hours_to_kickoff,
    vejr_match_type = "grid_nearest"
  )

mangler_vejr <- baseline_key %>%
  anti_join(kandidater_vejr %>% select(kamp_id), by = "kamp_id")

fallback_vejr <- mangler_vejr %>%
  left_join(vejr_fallback_1 %>% select(vejr_dato, vejr_time_h, vejrkode, vejrbeskrivelse),
            by = c("kamp_dato" = "vejr_dato")) %>%
  transmute(
    kamp_id,
    vejr_tid_h = vejr_time_h,
    vejrkode,
    vejrbeskrivelse,
    dist_hours_to_kickoff = NA_integer_,
    vejr_match_type = "fallback_dato"
  )

vejr_match <- bind_rows(kandidater_vejr, fallback_vejr)
stopifnot(sum(duplicated(vejr_match$kamp_id)) == 0)

baseline <- baseline %>%
  left_join(vejr_match, by = "kamp_id") %>%
  mutate(
    vejr_mangler_obs = if_else(is.na(vejrkode), 1L, 0L),
    vejr_ikke_observerbar = if_else(!is.na(vejrkode) & vejrkode == 0, 1L, 0L),
    vejr_mangler_info = if_else(vejr_mangler_obs == 1L | vejr_ikke_observerbar == 1L, 1L, 0L),
    vejrkode_model = if_else(vejr_mangler_info == 1L, -1L, as.integer(vejrkode)),
    vejrbeskrivelse_model = case_when(
      vejr_mangler_obs == 1L ~ "UKENDT",
      vejr_ikke_observerbar == 1L ~ "IKKE_OBSERVERBAR",
      TRUE ~ as.character(vejrbeskrivelse)
    )
  )

cat("Vejr joinet ‚úÖ  NA vejrkode:", sum(is.na(baseline$vejrkode)), "\n\n")

```

### Temperatur f√∏r kickoff (step-back samme dag)

Denne kode henter temperaturm√•linger og knytter dem til hver kamp ved at v√¶lge den seneste m√•ling samme dag f√∏r kickoff. Hvis der ikke findes en m√•ling f√∏r kickoff, markeres det med en match-type og NA-v√¶rdier. Til sidst joines temperaturen ind i baseline, og der laves model-klare kolonner.

```{r}

# 4E) Temperatur (step-back samme dag: 18‚Üí15‚Üí12‚Üí09 f√∏r kickoff)
cat("\n--- FEATURE: TEMPERATUR ---\n")
temp_sql <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_temperatur_join_ready")
stopifnot(all(c("obs_dato","tid","temperatur") %in% names(temp_sql)))

temp_tider_h <- c(9L, 12L, 15L, 18L)

temp_grid <- temp_sql %>%
  mutate(
    temp_dato = if (inherits(obs_dato, "Date")) obs_dato else as.Date(obs_dato, format = "%d-%m-%Y"),
    temp_tid_chr = str_trim(as.character(tid)),
    temp_tid_chr = if_else(str_detect(temp_tid_chr, "^\\d{1,2}:\\d{2}$"), paste0(temp_tid_chr, ":00"), temp_tid_chr),
    temp_time_h = time_chr_to_hour(temp_tid_chr),
    temperatur = suppressWarnings(as.numeric(temperatur))
  ) %>%
  filter(!is.na(temp_dato), !is.na(temp_time_h), temp_time_h %in% temp_tider_h) %>%
  group_by(temp_dato, temp_time_h) %>%
  slice(1) %>%
  ungroup()

temp_kandidater <- baseline_key %>%
  inner_join(temp_grid %>% select(temp_dato, temp_time_h, temperatur),
             by = c("kamp_dato" = "temp_dato")) %>%
  filter(!is.na(kamp_time_h), temp_time_h <= kamp_time_h) %>%
  mutate(temp_dist_hours_to_kickoff = kamp_time_h - temp_time_h)

temp_valgt <- temp_kandidater %>%
  group_by(kamp_id) %>%
  arrange(desc(temp_time_h), .by_group = TRUE) %>%
  slice(1) %>%
  ungroup() %>%
  transmute(
    kamp_id,
    temp_tid_h = temp_time_h,
    temperatur,
    temp_dist_hours_to_kickoff = as.integer(temp_dist_hours_to_kickoff),
    temp_match_type = "step_back_same_day"
  )

temp_mangler <- baseline_key %>%
  anti_join(temp_valgt %>% select(kamp_id), by = "kamp_id") %>%
  transmute(
    kamp_id,
    temp_tid_h = NA_integer_,
    temperatur = NA_real_,
    temp_dist_hours_to_kickoff = NA_integer_,
    temp_match_type = case_when(
      is.na(kamp_time_h) ~ "NO_KICKOFF_TIME",
      TRUE               ~ "NO_TEMP_BEFORE_KICKOFF"
    )
  )

temp_match <- bind_rows(temp_valgt, temp_mangler)
stopifnot(sum(duplicated(temp_match$kamp_id)) == 0)

baseline <- baseline %>%
  left_join(temp_match, by = "kamp_id") %>%
  mutate(
    temp_mangler_obs = if_else(is.na(temperatur), 1L, 0L),
    temperatur_model = as.numeric(temperatur),
    temp_match_type_model = if_else(is.na(temp_match_type), "NO_TEMP", as.character(temp_match_type))
  )

cat("Temperatur joinet ‚úÖ  NA temperatur:", sum(is.na(baseline$temperatur)), "\n\n")

```

### Placering f√∏r kamp (feature til baseline)

Denne del af pipeline henter holdets placering f√∏r kamp fra en renset tabel og g√∏r den klar til at blive joinet ind i baseline.Den reducerer data til √©n r√¶kke pr. kamp_id, s√• joinet ikke kan skabe dubletter i dit modelgrundlag. Til sidst udskrives en statuslinje, der viser hvor mange kampe der ender med manglende placering (NA).

```{r}

# 4F) Placering
plac_raw <- safe_dbReadTable(con, "PBA02_Clean", "fact_vff_rundeplaceringer_clean") %>%
  mutate(kamp_id = as.character(kamp_id))
stopifnot(all(c("kamp_id","placering_f√∏r_kamp") %in% names(plac_raw)))

plac_1row <- plac_raw %>%
  select(kamp_id, placering_f√∏r_kamp) %>%
  mutate(placering_f√∏r_kamp = suppressWarnings(as.integer(placering_f√∏r_kamp))) %>%
  arrange(kamp_id) %>%
  group_by(kamp_id) %>%
  slice(1) %>%
  ungroup()

stopifnot(sum(duplicated(plac_1row$kamp_id)) == 0)
baseline <- baseline %>% left_join(plac_1row, by = "kamp_id")
cat("Placering joinet ‚úÖ  NA placering_f√∏r_kamp:", sum(is.na(baseline$placering_f√∏r_kamp)), "\n")

```

### Modstander (feature til baseline)

Denne kode henter kamp-programdata og finder automatisk den kolonne, der indeholder modstanderens navn, selv hvis kolonnenavnet varierer. Modstander-navnet renses (fjern overfl√∏dige mellemrum og tomme v√¶rdier s√¶ttes til NA), og der sikres √©n r√¶kke pr. kamp_id f√∏r join.Til sidst joines modstander ind i baseline, konverteres til faktor, og der logges b√•de NA‚Äôer og antal unikke modstandere.

```{r}
# 4G) Modstander
mod_raw <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_superliga_program_join_ready") %>%
  mutate(kamp_id = as.character(kamp_id))
stopifnot("kamp_id" %in% names(mod_raw))

candidate_cols <- c("modstander","udehold","away_team","modstander_navn","udehold_navn","away_team_name")
found <- candidate_cols[candidate_cols %in% names(mod_raw)][1]
if (is.na(found)) {
  cat("‚ö†Ô∏è Kunne ikke finde en modstander-kolonne automatisk.\nKolonner:\n")
  print(names(mod_raw))
  stop("Ret candidate_cols eller v√¶lg korrekt kolonne.")
}

mod_1row <- mod_raw %>%
  select(kamp_id, modstander_raw = all_of(found)) %>%
  mutate(
    modstander = str_squish(as.character(modstander_raw)),
    modstander = if_else(is.na(modstander) | modstander == "", NA_character_, modstander)
  ) %>%
  select(kamp_id, modstander) %>%
  arrange(kamp_id) %>%
  group_by(kamp_id) %>%
  slice(1) %>%
  ungroup()

stopifnot(sum(duplicated(mod_1row$kamp_id)) == 0)

baseline <- baseline %>%
  left_join(mod_1row, by = "kamp_id") %>%
  mutate(modstander = as.factor(modstander))

cat("Modstander joinet ‚úÖ  NA modstander:", sum(is.na(baseline$modstander)), "\n")
cat("Antal unikke modstandere:", n_distinct(as.character(baseline$modstander)), "\n\n")

```

### Samlet QA af baseline (tjek af manglende v√¶rdier og entydighed)

Denne blok laver en hurtig kvalitetssikring af dit feature-s√¶t ved at t√¶lle r√¶kker, unikke kamp-id‚Äôer og antal manglende v√¶rdier pr. n√∏glefeature. Det hj√¶lper dig med at opdage datal√¶k, dubletter eller kolonner der ikke blev joinet korrekt, f√∏r du g√•r videre til modellering.Til sidst ‚Äúl√•ser‚Äù du datas√¶ttet som baseline_d3 og rydder op ved at fjerne baseline fra milj√∏et.

```{r}
# 4H) Samlet QA
qa_d3 <- baseline %>%
  summarise(
    r√¶kker_total = n(),
    unikke_kamp_id = n_distinct(kamp_id),
    uden_kamp_time_h = sum(is.na(kamp_time_h)),
    uden_helligdag = sum(is.na(er_helligdag)),
    uden_sah_flag = sum(is.na(er_h√•ndboldkamp_SAH)),
    uden_befolkning = sum(is.na(befolkningstal)),
    uden_vejrkode = sum(is.na(vejrkode)),
    uden_temp = sum(is.na(temperatur)),
    uden_placering = sum(is.na(placering_f√∏r_kamp)),
    uden_modstander = sum(is.na(modstander))
  )

print(qa_d3)
cat("\nbaseline_d3 (features) klar ‚úÖ\n\n")

baseline_d3 <- baseline
rm(baseline)

```

### Billetsalg (D3/D7/D10): robust udtr√¶k og ‚Äú1 r√¶kke pr. kamp‚Äù

Denne kode henter billetsalgsdata og finder automatisk de korrekte kolonner til D3, D7 og D10, selv hvis kolonnenavnene varierer. Derefter reduceres data til √©n r√¶kke pr. kamp_id ved at tage den h√∏jeste observerede v√¶rdi pr. kamp (praktisk hvis der ligger flere snapshots). Til sidst renses output, s√• umulige v√¶rdier som Inf bliver til NA, hvilket g√∏r datas√¶ttet stabilt til analyse og modellering.

```{r}

# ====================================================================
# 5) Billetsalg -> analysis_df_d3 + df_d3_all (ren, stabil)
# ====================================================================
tickets_raw <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_VFF_Billetsalg_join_ready") %>%
  mutate(kamp_id = as.character(kamp_id))

col_d3  <- find_first_col(tickets_raw, c("d3_tilskuere","d3","tilskuere_d3","billetter_d3"))
col_d7  <- find_first_col(tickets_raw, c("d7_tilskuere","d7","tilskuere_d7","billetter_d7"))
col_d10 <- find_first_col(tickets_raw, c("d10_tilskuere","d10","tilskuere_d10","billetter_d10"))
if (is.na(col_d3)) stop("‚ùå Kan ikke finde D3-kolonne i billetsalg-tabellen. Kig p√• names(tickets_raw).")

tickets_1row <- tickets_raw %>%
  group_by(kamp_id) %>%
  summarise(
    d3  = suppressWarnings(max(as.numeric(.data[[col_d3]]),  na.rm = TRUE)),
    d7  = if (!is.na(col_d7))  suppressWarnings(max(as.numeric(.data[[col_d7]]),  na.rm = TRUE)) else NA_real_,
    d10 = if (!is.na(col_d10)) suppressWarnings(max(as.numeric(.data[[col_d10]]), na.rm = TRUE)) else NA_real_,
    .groups = "drop"
  ) %>%
  mutate(
    d3  = if_else(is.infinite(d3),  NA_real_, d3),
    d7  = if_else(is.infinite(d7),  NA_real_, d7),
    d10 = if_else(is.infinite(d10), NA_real_, d10)
  )

```

### Step-v√¶kster + model-datas√¶t (D3): features, join og endelig klarg√∏ring

Denne kode laver billetsalgs-features baseret p√• step-v√¶kster mellem D10‚ÜíD7 og D7‚ÜíD3, hvor negative √¶ndringer klippes til 0. Herefter joines billetsalgs-features ind i dit feature-s√¶t (baseline_d3) og der bygges et stabilt ‚Äúf√¶lles‚Äù datas√¶t (df_d3_all) til modellering. Til sidst sikres korrekte datatyper, fjernes r√¶kker uden kampdato, og datas√¶ttet sorteres kronologisk.

```{r}
# -----------------------------
# RETTELSE: step-v√¶kster
#   - v√¶kst_d10_d7 = max(d7 - d10, 0)
#   - v√¶kst_d7_d3  = max(d3 - d7, 0)
#   - Ingen v√¶kst_d10_d3
# -----------------------------
tickets_feats_d3 <- tickets_1row %>%
  mutate(
    billetter_d3 = d3,
    v√¶kst_d10_d7 = if_else(!is.na(d10) & !is.na(d7), pmax(d7 - d10, 0), NA_real_),
    v√¶kst_d7_d3  = if_else(!is.na(d7),               pmax(d3 - d7,  0), NA_real_)
  ) %>%
  select(kamp_id, billetter_d3, v√¶kst_d10_d7, v√¶kst_d7_d3)

analysis_df_d3 <- baseline_d3 %>%
  mutate(kamp_id = as.character(kamp_id)) %>%
  left_join(tickets_feats_d3, by = "kamp_id")

cat("analysis_df_d3 klar ‚úÖ  R√¶kker:", nrow(analysis_df_d3),
    "Unikke kamp_id:", n_distinct(analysis_df_d3$kamp_id), "\n")
cat("NA billetter_d3:", sum(is.na(analysis_df_d3$billetter_d3)), "\n\n")

# df_d3_all: f√¶lles datas√¶t til modeller
df_d3_all <- analysis_df_d3 %>%
  transmute(
    kamp_id      = as.character(kamp_id),
    kamp_dato    = as.Date(kamp_dato),
    tilskuere    = as.numeric(tilskuere),
    
    s√¶son        = as.factor(s√¶son),
    runde        = as.integer(runde),
    kamp_time_h  = as.integer(kamp_time_h),
    
    billetter_d3 = as.numeric(billetter_d3),
    v√¶kst_d10_d7 = as.numeric(v√¶kst_d10_d7),
    v√¶kst_d7_d3  = as.numeric(v√¶kst_d7_d3),
    
    er_helligdag = as.integer(er_helligdag),
    er_h√•ndboldkamp_SAH = as.integer(er_h√•ndboldkamp_SAH),
    antal_h√•ndboldkampe = as.integer(antal_h√•ndboldkampe),
    
    temperatur_model = as.numeric(temperatur_model),
    vejrkode_model   = as.integer(vejrkode_model),
    vejr_mangler_info = as.integer(vejr_mangler_info),
    
    placering_f√∏r_kamp = as.integer(placering_f√∏r_kamp),
    befolkningstal     = as.numeric(befolkningstal),
    
    modstander = as.factor(modstander)
  ) %>%
  filter(!is.na(kamp_dato)) %>%
  arrange(kamp_dato)
  View(df_d3_all)

```

## Tidssplit: kronologisk 80/20 opdeling i tr√¶ning og test

Her opdeles det samlede analysedatas√¶t i et tr√¶ningss√¶t og et tests√¶t baseret p√• tid (kronologisk), s√• evalueringen efterligner en realistisk prognosesituation. F√∏rst fasts√¶ttes test-andelen (20%), hvorefter der beregnes et cut-point, og data splittes i de tidligste observationer (train) og de seneste (test). Til sidst udskrives en kort status med st√∏rrelserne samt startdatoen for testperioden, s√• du tydeligt kan dokumentere split‚Äôet i rapporten.

```{r}
# ====================================================================
# Tidssplit (80/20) kronologisk ‚Äî √âN gang
# ====================================================================
test_prop <- 0.20
n_total <- nrow(df_d3_all)
n_test  <- max(1, floor(n_total * test_prop))
cut_idx <- n_total - n_test

train_d3 <- df_d3_all[1:cut_idx, , drop = FALSE]
test_d3  <- df_d3_all[(cut_idx + 1):n_total, , drop = FALSE]

cat("Tidssplit klar ‚úÖ  Train:", nrow(train_d3), " Test:", nrow(test_d3), "\n")
cat("Test-periode starter:", as.character(min(test_d3$kamp_dato)), "\n\n")
```

## Predictor pool: dynamisk valg af forklaringsvariabler

Denne kode forbereder listen af forklaringsvariable, der skal indg√• i modelleringen. F√∏rst tjekkes om variablen modstander findes i tr√¶ningsdatas√¶ttet, s√• scriptet ikke fejler, hvis kolonnen mangler. Derefter samles en ‚Äúpredictor pool‚Äù, hvor modstander kun inkluderes, n√•r den faktisk er tilg√¶ngelig, og hvor befolkningstal bevidst udelades som standard (s√• det kan testes separat senere).

```{r}
#bruges i nedenst√•nde og fungere som et tjek
has_modstander <- "modstander" %in% names(train_d3)

# predictor pool (uden befolkning som default) sikring af modstander er i predictor_pool
predictor_pool <- c(
  "s√¶son","runde","kamp_time_h",
  "billetter_d3","v√¶kst_d10_d7","v√¶kst_d7_d3",
  if (has_modstander) "modstander" else NULL,
  "er_helligdag","er_h√•ndboldkamp_SAH","antal_h√•ndboldkampe",
  "temperatur_model","vejrkode_model","vejr_mangler_info",
  "placering_f√∏r_kamp"
)
```

Her sikrer, at din liste af forklaringsvariable faktisk kan bruges til modellering p√• tr√¶ningsdata. F√∏rst fjernes variable, der ikke findes i train_d3, og derefter fjernes variable, der er helt tomme (kun NA) i tr√¶ningss√¶ttet. Til sidst bygges en line√¶r model-formel dynamisk, s√• du automatisk f√•r tilskuere \~ x1 + x2 + ... baseret p√• den endelige predictor-liste.

```{r}
# Fjern predictors som ikke findes i tr√¶ningsdatas√¶ttet (robusthed)
predictor_pool <- predictor_pool[predictor_pool %in% names(train_d3)]
# Fjern predictors der kun best√•r af NA i tr√¶ningsdatas√¶ttet (ingen information)
predictor_pool <- predictor_pool[
  vapply(
    predictor_pool,
    function(v) !all(is.na(train_d3[[v]])), 
    logical(1)
    )
  ]

# Stop hvis der ikke er nogen brugbare predictors tilbage (ellers kan modellen ikke estimeres)
if (length(predictor_pool) == 0) stop("‚ùå predictor_pool endte tom. Tjek df_d3_all kolonner/NA.")

```

Denne linje bygger en model-formel automatisk ud fra predictor_pool, s√• du ikke skal skrive variablerne manuelt. Resultatet er en formula-variabel (full_formula), som kan bruges direkte i lm() og step() til at fitte modeller med pr√¶cis de predictors, du har valgt (ogs√• hvis listen √¶ndrer sig undervejs).

```{r}
# Byg model-formel dynamisk til lm/stepwise:
# fx "tilskuere ~ runde + kamp_time_h + billetter_d3 + ..."
full_formula <- as.formula(paste("tilskuere ~", paste(predictor_pool, collapse = " + ")))
```

Faktor-niveauer i testdata tilpasses tr√¶ningsdata, s√• ukendte kategorier samles i en f√¶lles reference og modellen kan anvendes stabilt uden at fejle ved prediction.

```{r}
# # robusthed: test modstander-levels til train levels (predict skal ikke kn√¶kke)
# if ("modstander" %in%
#     names(train_step)) {  tmp <- safe_factor_with_other(train_step$modstander, test_step$modstander, "ANDRE")
#   train_step$modstander <- tmp$train
#   test_step$modstander  <- tmp$test
#   rm(tmp)
# }

# # robusthed: test modstander-levels til train levels (predict skal ikke kn√¶kke)
# if ("modstander" %in% names(train_step)) {
#   tmp <- safe_factor_with_other(train_step$modstander, test_step$modstander, "ANDRE")
#   train_step$modstander <- tmp$train
#   test_step$modstander  <- tmp$test
#   rm(tmp)
# }


# 7B) complete cases til stepwise (samme logik som du gjorde)
train_step <- train_d3 %>% select(tilskuere, all_of(predictor_pool)) %>% drop_na()
test_step  <- test_d3  %>% select(tilskuere, all_of(predictor_pool)) %>% drop_na()

# robusthed: test modstander-levels til train levels (predict skal ikke kn√¶kke)
if ("modstander" %in% names(train_step)) {
  tmp <- safe_factor_with_other(train_step$modstander, test_step$modstander, "ANDRE")
  train_step$modstander <- tmp$train
  test_step$modstander  <- tmp$test
  rm(tmp)
}
```

Efter stepwise-udv√¶lgelse udskrives antallet af observationer i tr√¶nings- og testdatas√¶ttet. Samtidig dokumenteres hvor mange r√¶kker der er fjernet som f√∏lge af manglende v√¶rdier, s√• datatab og konsistens i modelgrundlaget kan vurderes eksplicit.

```{r}

cat("Stepwise datas√¶t ‚úÖ  Train:", nrow(train_step), " Test:", nrow(test_step), "\n")
cat("Drop NA (train):", nrow(train_d3) - nrow(train_step), "r√¶kker\n")
cat("Drop NA (test) :", nrow(test_d3)  - nrow(test_step),  "r√¶kker\n\n")

```

Der opstilles en nulmodel med kun konstantled som reference samt en fuld model med alle udvalgte forklarende variable, s√• den efterf√∏lgende modeludv√¶lgelse kan vurderes relativt til et simpelt baseline-niveau.

```{r}
m_null <- lm(tilskuere ~ 1, data = train_step)
m_full <- lm(full_formula, data = train_step)
```

Der anvendes forward, backward og both stepwise selection inden for samme model space for at sammenligne, hvordan forskellige selektionsstrategier p√•virker den endelige modelsammens√¶tning.

```{r}
m_step_fwd  <- step(m_null, scope = list(lower = formula(m_null), upper = formula(m_full)), direction = "forward", trace = 0)
m_step_bwd  <- step(m_full, direction = "backward", trace = 0)
m_step_both <- step(m_null, scope = list(lower = formula(m_null), upper = formula(m_full)), direction = "both", trace = 0)
```

Model performance samles i en f√¶lles struktur med RMSE, MAE og R¬≤, s√• den pr√¶diktive n√∏jagtighed og forklaringsgrad kan sammenlignes direkte p√• tv√¶rs af stepwise forward, backward og both selection baseret p√• AIC.

```{r}

pred_step_fwd  <- clip_0_cap(predict(m_step_fwd,  newdata = test_step))
pred_step_bwd  <- clip_0_cap(predict(m_step_bwd,  newdata = test_step))
pred_step_both <- clip_0_cap(predict(m_step_both, newdata = test_step))


perf_step <- tibble(
  model = c("Stepwise Forward (AIC)", "Stepwise Backward (AIC)", "Stepwise Both (AIC)"),
  RMSE  = c(rmse_vec(test_step$tilskuere, pred_step_fwd),
            rmse_vec(test_step$tilskuere, pred_step_bwd),
            rmse_vec(test_step$tilskuere, pred_step_both)),
  MAE   = c(mae_vec(test_step$tilskuere, pred_step_fwd),
            mae_vec(test_step$tilskuere, pred_step_bwd),
            mae_vec(test_step$tilskuere, pred_step_both)),
  R2    = c(r2_vec(test_step$tilskuere, pred_step_fwd),
            r2_vec(test_step$tilskuere, pred_step_bwd),
            r2_vec(test_step$tilskuere, pred_step_both))
)

cat("Stepwise f√¶rdig ‚úÖ\n")
print(perf_step)
cat("\nValgte features (Backward):\n"); print(names(coef(m_step_bwd))); cat("\n")


```

Resultaterne viser, at stepwise forward, backward og both (AIC) leverer identisk modelperformance, med RMSE p√• 214, MAE p√• 177 og R¬≤ p√• 0,97. Dette indikerer, at de tre selektionsstrategier konvergerer mod samme endelige model og variabels√¶t. Valg af stepwise-retning har derfor ingen praktisk betydning for modellens pr√¶diktionsevne i dette setup.

Stepwise backward (AIC) udv√¶lger en enkel model, hvor billetsalg t√¶t p√• kampdatoen udg√∏r den prim√¶re forklaringsfaktor, suppleret af kortsigtet salgsdynamik, temperatur og placering f√∏r kamp. Dette indikerer, at kampn√¶re eftersp√∏rgselsdata er afg√∏rende for modellens pr√¶diktionsevne.

Den estimerede null-model indeholder udelukkende et konstantled og fungerer som reference for modeludvidelse, mens den fulde model inkluderer samtlige potentielle forklaringsvariable. Disse to modeller danner yderpunkterne for den efterf√∏lgende stepwise-selektion baseret p√• AIC.

```{r}
m_null <- lm(tilskuere ~ 1, data = train_step)
m_full <- lm(full_formula, data = train_step)
```

Stepwise forward estimeres ved gradvist at udvide null-modellen mod den fulde model, mens stepwise backward reducerer den fulde model ved successiv fjernelse af variable. Stepwise both kombinerer de to strategier ved b√•de at tilf√∏je og fjerne variable undervejs, hvor alle tre metoder optimerer modelvalget ud fra AIC-kriteriet.

```{r}
m_step_fwd  <- step(m_null, scope = list(lower = formula(m_null), upper = formula(m_full)), direction = "forward", trace = 0)

m_step_bwd  <- step(m_full, direction = "backward", trace = 0)

m_step_both <- step(m_null, scope = list(lower = formula(m_null), upper = formula(m_full)), direction = "both", trace = 0)

```

```{r}
pred_step_fwd  <- clip_0_cap(predict(m_step_fwd,  newdata = test_step))
pred_step_bwd  <- clip_0_cap(predict(m_step_bwd,  newdata = test_step))
pred_step_both <- clip_0_cap(predict(m_step_both, newdata = test_step))
```

Modellernes forudsigelser beregnes p√• testdatas√¶ttet og efterbehandles ved at afgr√¶nse v√¶rdierne til et realistisk interval. Dette sikrer, at negative eller urealistisk h√∏je tilskuertal ikke indg√•r i den efterf√∏lgende performanceevaluerin

```{r}
perf_step <- tibble(
  model = c("Stepwise Forward (AIC)", "Stepwise Backward (AIC)", "Stepwise Both (AIC)"),
  RMSE  = c(rmse_vec(test_step$tilskuere, pred_step_fwd),
            rmse_vec(test_step$tilskuere, pred_step_bwd),
            rmse_vec(test_step$tilskuere, pred_step_both)),
  MAE   = c(mae_vec(test_step$tilskuere, pred_step_fwd),
            mae_vec(test_step$tilskuere, pred_step_bwd),
            mae_vec(test_step$tilskuere, pred_step_both)),
  R2    = c(r2_vec(test_step$tilskuere, pred_step_fwd),
            r2_vec(test_step$tilskuere, pred_step_bwd),
            r2_vec(test_step$tilskuere, pred_step_both))
)
perf_step

```

Modelperformance evalueres p√• testdatas√¶ttet ved hj√¶lp af RMSE, MAE og R¬≤ for hver stepwise-variant. Resultaterne viser identisk performance p√• tv√¶rs af forward, backward og both, hvilket indikerer, at metoderne konvergerer mod samme endelige model og pr√¶diktionsevne.

```{r}
cat("Stepwise f√¶rdig ‚úÖ\n")
print(perf_step)
cat("\nValgte features (Backward):\n"); print(names(coef(m_step_bwd))); cat("\n")

```

## Best Subset

Variabelpuljen afgr√¶nses ved at udelukke h√∏jdimensionelle faktorer for at reducere kompleksitet og beregningsbyrde. Hvis dette medf√∏rer en tom pulje, geninds√¶ttes det fulde variabels√¶t for at sikre estimerbarhed.

```{r}
subset_exclude_factors <- TRUE
predictor_pool_subset <- predictor_pool
if (subset_exclude_factors) predictor_pool_subset <- setdiff(predictor_pool_subset, c("s√¶son","modstander"))
if (length(predictor_pool_subset) == 0) predictor_pool_subset <- predictor_pool
```

Der konstrueres en modelmatrix ud fra det reducerede variabels√¶t, hvorefter tr√¶nings- og testdata opdeles konsistent. Variable med nul-varians fjernes, og testmatricen tilpasses tr√¶ningsmatricens struktur for at undg√• dimensionskonflikter.

```{r}
mm_formula <- as.formula(paste("~", paste(predictor_pool_subset, collapse = " + ")))
mm_list <- make_mm_train_test(train_step, test_step, mm_formula)
X_train <- drop_zero_variance_cols(mm_list$X_train)
X_test  <- mm_list$X_test[, colnames(X_train), drop = FALSE] 
```

Den afh√¶ngige variabel udtr√¶kkes separat for tr√¶nings- og testdatas√¶ttet for at sikre korrekt estimering og efterf√∏lgende performanceevaluering.

```{r}
y_train <- train_step$tilskuere
y_test  <- test_step$tilskuere
```

Det maksimale antal variable i best subset-selektionen begr√¶nses for at sikre beregningsm√¶ssig kontrol og reducere risikoen for overfitting. Denne afgr√¶nsning balancerer modelkompleksitet og generalisering.

```{r}
nvmax <- min(10L, ncol(X_train))
cat("Best subset setup ‚úÖ  ncol(X_train):", ncol(X_train), " nvmax:", nvmax, "\n\n")
```

Hvis tr√¶ningsmatricen ikke indeholder forklaringsvariable, anvendes en intercept-only reference¬≠model baseret p√• gennemsnittet af tr√¶ningsdata. Ellers estimeres en best subset-model via sekventiel erstatning, hvor det optimale antal variable v√¶lges ud fra BIC. Afh√¶ngigt af det valgte variabels√¶t estimeres en line√¶r model, og performance evalueres p√• testdatas√¶ttet ved hj√¶lp af RMSE, MAE og R¬≤.

```{r}
if (ncol(X_train) == 0) {
  pred_subset <- clip_0_cap(rep(mean(y_train, na.rm = TRUE), length(y_test)))
  perf_subset <- tibble(
    model = "Best Subset (Intercept-only)",
    RMSE = rmse_vec(y_test, pred_subset),
    MAE  = mae_vec(y_test, pred_subset),
    R2   = r2_vec(y_test, pred_subset),
    k_selected = 0L
  )
  regfit <- NULL; sel_cols <- character(0); fit_subset <- NULL
} else {
  regfit <- regsubsets(x = X_train, y = y_train, nvmax = nvmax, method = "seqrep")
  regsum <- summary(regfit)
  best_k_bic <- which.min(regsum$bic)
  which_mat <- regsum$which
  sel_cols <- names(which_mat[best_k_bic, ])[which_mat[best_k_bic, ]]
  sel_cols <- setdiff(sel_cols, "(Intercept)")
  
  cat("Best subset valgt (BIC) ‚úÖ  k =", best_k_bic, "\nValgte dummy-features:\n")
  print(sel_cols); cat("\n")
  
  if (length(sel_cols) == 0) {
    pred_subset <- clip_0_cap(rep(mean(y_train, na.rm = TRUE), length(y_test)))
    perf_subset <- tibble(
      model = "Best Subset (BIC ‚Üí Intercept-only)",
      RMSE = rmse_vec(y_test, pred_subset),
      MAE  = mae_vec(y_test, pred_subset),
      R2   = r2_vec(y_test, pred_subset),
      k_selected = 0L
    )
    fit_subset <- NULL
  } else {
    Xtr_sel <- X_train[, sel_cols, drop = FALSE]
    Xte_sel <- X_test[,  sel_cols, drop = FALSE]
    Xtr_sel_i <- cbind(`(Intercept)` = 1, Xtr_sel)
    Xte_sel_i <- cbind(`(Intercept)` = 1, Xte_sel)
    
    fit_subset <- lm.fit(x = Xtr_sel_i, y = y_train)
    pred_subset <- clip_0_cap(as.numeric(Xte_sel_i %*% fit_subset$coefficients))
    
    perf_subset <- tibble(
      model = "Best Subset (BIC, regsubsets, seqrep)",
      RMSE = rmse_vec(y_test, pred_subset),
      MAE  = mae_vec(y_test, pred_subset),
      R2   = r2_vec(y_test, pred_subset),
      k_selected = length(sel_cols)
    )
  }
}

cat("Best subset f√¶rdig ‚úÖ\n")
print(perf_subset); cat("\n")

```

Best subset-selektionen baseret p√• BIC identificerer en parsimonisk model med tre forklaringsvariable: billetsalg tre dage f√∏r kamp samt to kortsigtede v√¶kstindikatorer. Modellen opn√•r h√∏j pr√¶diktionsevne med RMSE p√• 213, MAE p√• 176 og R¬≤ p√• 0,966, hvilket indikerer, at kampn√¶r eftersp√∏rgselsdynamik forklarer hovedparten af variationen i tilskuertallet. Resultatet viser, at en meget enkel model kan matche performance fra mere komplekse specifikationer.

### Modelperformance for D3-modeller

Dette afsnit sammenfatter testperformance for de estimerede D3-modeller med henblik p√• at sammenligne pr√¶diktionsevne p√• tv√¶rs af forskellige modeludv√¶lgelsesstrategier. Modellerne evalueres konsekvent p√• samme testdatas√¶t og sammenlignes ved hj√¶lp af RMSE, MAE og R¬≤.

```{r}
perf_all <- bind_rows(
  perf_step,
  perf_subset %>% select(model, RMSE, MAE, R2)
) %>% arrange(RMSE)

cat("====================================\n")
cat("D3 ‚Äî SAMLET TEST PERFORMANCE (SORTERET P√Ö RMSE)\n")
cat("====================================\n")
print(perf_all); cat("\n")
```

Resultaterne viser, at best subset-modellen baseret p√• BIC opn√•r den laveste RMSE og MAE samt den h√∏jeste forklaringsgrad, om end forskellene til stepwise-modellerne er marginale. Alle stepwise-varianter (forward, backward og both) leverer identisk performance, hvilket indikerer konvergens mod samme effektive modelstruktur. Samlet peger resultaterne p√•, at en meget enkel model kan opn√• samme pr√¶diktionsevne som mere komplekse.

Resultater fra modeludv√¶lgelsen for D3 er struktureret og gemt i et samlet objekt, der indeholder datagrundlag, anvendte model¬≠specifikationer, estimerede modeller samt tilh√∏rende performance¬≠m√•l. Denne struktur sikrer fuld reproducerbarhed og g√∏r det muligt systematisk at sammenligne modeller og genanvende resultater i den videre analyse.

```{r}
d3_selection_results <- list(
  data = list(
    analysis_df_d3 = analysis_df_d3,
    df_d3_all = df_d3_all,
    train_step = train_step,
    test_step  = test_step
  ),
  formulas = list(full_formula = full_formula, mm_formula = mm_formula),
  models = list(
    step_forward  = m_step_fwd,
    step_backward = m_step_bwd,
    step_both     = m_step_both,
    best_subset = list(
      regsubsets = regfit,
      selected_cols = sel_cols,
      lmfit = fit_subset,
      subset_exclude_factors = subset_exclude_factors
    )
  ),
  performance = list(table = perf_all, step = perf_step, subset = perf_subset)
)

cat("D3 selection resultater gemt i: d3_selection_results ‚úÖ\n\n")
```

## Regulariserede modeller (Ridge og Lasso)

I dette afsnit estimeres regulariserede regressionsmodeller (Ridge og Lasso) med henblik p√• at vurdere, om shrinkage og variabelselektion kan forbedre pr√¶diktionsevnen i D3-ops√¶tningen. Modellerne estimeres p√• samme train-test-split og samme complete cases som de √∏vrige analyser for at sikre sammenlignelighed. Hyperparametre tunes udelukkende p√• tr√¶ningsdata ved hj√¶lp af tidsblok-baseret krydsvalidering, hvorefter performance evalueres √©n gang p√• testdatas√¶ttet.

Tr√¶nings- og testdatas√¶ttene kopieres til et separat datas√¶t til brug for de regulariserede modeller for at bevare konsistens med det oprindelige datasplit.

```{r}
# For at undg√• massiv dummy-eksplosion konverterer vi s√¶son -> s√¶son_start (numerisk)
train_glm <- train_step
test_glm  <- test_step
```

Den kategoriske s√¶sonvariabel transformeres til en numerisk s√¶sonstartindikator, hvorefter den oprindelige variabel fjernes. Dette reducerer dimensionalitet og sikrer en konsistent repr√¶sentation i tr√¶nings- og testdatas√¶ttene.

```{r}
if ("s√¶son" %in% names(train_glm)) {
    train_glm <- train_glm %>% mutate(s√¶son_start = season_start_year(s√¶son))
  test_glm  <- test_glm  %>% mutate(s√¶son_start = season_start_year(s√¶son))
  train_glm$s√¶son <- NULL
  test_glm$s√¶son  <- NULL
}
```

Predictor-poolen til glmnet konstrueres ved at erstatte den oprindelige s√¶sonvariabel med den numeriske s√¶sonstart og ved kun at inkludere variable, som faktisk er tilg√¶ngelige og informative i datas√¶ttet. Variable uden observationer udelukkes eksplicit for at sikre estimerbarhed af de regulariserede modeller.

```{r}
predictor_pool_glm <- predictor_pool
if ("s√¶son" %in% predictor_pool_glm) predictor_pool_glm <- setdiff(predictor_pool_glm, "s√¶son")
if ("s√¶son_start" %in% names(train_glm)) predictor_pool_glm <- unique(c("s√¶son_start", predictor_pool_glm))

predictor_pool_glm <- predictor_pool_glm[predictor_pool_glm %in% names(train_glm)]
predictor_pool_glm <- predictor_pool_glm[vapply(predictor_pool_glm, function(v) !all(is.na(train_glm[[v]])), logical(1))]
if (length(predictor_pool_glm) == 0) stop("‚ùå predictor_pool_glm endte tom. Kan ikke k√∏re glmnet.")

tibble(predictor_pool_glm)

```

Der afgr√¶nses til complete cases i b√•de tr√¶nings- og testdata, da glmnet kr√¶ver fuldst√¶ndige observationer uden manglende v√¶rdier i hverken forklaringsvariable eller respons. Dette sikrer korrekt estimering og konsistent evaluering af de regulariserede modeller.

```{r}
# complete cases igen (glmnet skal ikke have NA i X eller y)
keep_train <- complete.cases(train_glm %>% select(tilskuere, all_of(predictor_pool_glm)))

keep_test  <- complete.cases(test_glm  %>% select(tilskuere, all_of(predictor_pool_glm)))

train_glm_cc <- train_glm[keep_train, , drop = FALSE]
test_glm_cc  <- test_glm[keep_test,  , drop = FALSE]
```

Et intercept er modellens sk√¶ring med y-aksen, dvs. den forventede v√¶rdi af y, n√•r alle forklaringsvariable er 0. I denne ops√¶tning udelades et eksplicit intercept i modelmatricen, fordi glmnet selv estimerer sk√¶ringen med y-aksen internt.

Modelmatricen konstrueres uden eksplicit intercept (sk√¶ring med y-aksen), da glmnet estimerer dette internt. Modelmatricen bygges konsistent for tr√¶nings- og testdata for at sikre korrekt estimering og sammenlignelighed.

```{r}
# model.matrix: ~ 0 + ... (glmnet h√•ndterer intercept selv)
mm_rhs_terms <- paste(predictor_pool_glm, collapse = " + ")

mm_formula_glm <- as.formula(paste("~ 0 +", mm_rhs_terms))

mm_glm <- make_mm_train_test(
  train_df = train_glm_cc %>% select(all_of(predictor_pool_glm)),
  test_df  = test_glm_cc  %>% select(all_of(predictor_pool_glm)),
  mm_formula = mm_formula_glm
)
```

Modelmatricer og responsvariable klarg√∏res i numerisk form i overensstemmelse med glmnets inputkrav, hvorefter datas√¶ttets dimensioner verificeres. Dette sikrer korrekt ops√¶tning af tr√¶nings- og testdata f√∏r modelestimering.

```{r}
X_train_glm <- as.matrix(mm_glm$X_train)
X_test_glm  <- as.matrix(mm_glm$X_test)

y_train_glm <- as.numeric(train_glm_cc$tilskuere)
y_test_glm  <- as.numeric(test_glm_cc$tilskuere)

cat("glmnet setup ‚úÖ  ncol(X_train):", ncol(X_train_glm),
    "Train n:", length(y_train_glm), "Test n:", length(y_test_glm), "\n\n")

```

Krydsvalideringsfolds (CV folds) konstrueres som tidsblokke for at bevare den tidsm√¶ssige struktur i tr√¶ningsdata og undg√• informationsl√¶kage mellem tr√¶ning og validering.

```{r}
foldid <- make_time_block_foldid(n = nrow(X_train_glm), k = 10)
```

Ridge- og Lasso-modeller estimeres ved hj√¶lp af k-fold krydsvalidering med tidsblokke, hvor regulariseringsparameteren v√¶lges p√• baggrund af tr√¶ningsdata. En fast seed anvendes for at sikre reproducerbarhed af krydsvalideringen.

```{r}
set.seed(42)
cv_ridge <- cv.glmnet(x = X_train_glm, y = y_train_glm, alpha = 0, standardize = TRUE, foldid = foldid)

set.seed(42)
cv_lasso <- cv.glmnet(x = X_train_glm, y = y_train_glm, alpha = 1, standardize = TRUE, foldid = foldid)

```

Forudsigelser beregnes p√• testdatas√¶ttet for b√•de Ridge- og Lasso-modeller ved henholdsvis Œª_min og Œª_1se, hvorefter ekstreme v√¶rdier afgr√¶nses til et realistisk interval. Modelperformance evalueres ved hj√¶lp af RMSE, MAE, R¬≤ og MSE, og resultaterne samles i en oversigtstabel sorteret efter RMSE for direkte sammenligning af pr√¶diktionsevne.

```{r}
pred_ridge_min <- clip_0_cap(as.numeric(predict(cv_ridge, newx = X_test_glm, s = "lambda.min")))
pred_ridge_1se <- clip_0_cap(as.numeric(predict(cv_ridge, newx = X_test_glm, s = "lambda.1se")))
pred_lasso_min <- clip_0_cap(as.numeric(predict(cv_lasso, newx = X_test_glm, s = "lambda.min")))
pred_lasso_1se <- clip_0_cap(as.numeric(predict(cv_lasso, newx = X_test_glm, s = "lambda.1se")))

perf_glmnet <- bind_rows(
  tibble(model = "Ridge (lambda.min)", RMSE = rmse_vec(y_test_glm, pred_ridge_min), MAE = mae_vec(y_test_glm, pred_ridge_min), R2 = r2_vec(y_test_glm, pred_ridge_min), MSE = mse_vec(y_test_glm, pred_ridge_min)),
  tibble(model = "Ridge (lambda.1se)", RMSE = rmse_vec(y_test_glm, pred_ridge_1se), MAE = mae_vec(y_test_glm, pred_ridge_1se), R2 = r2_vec(y_test_glm, pred_ridge_1se), MSE = mse_vec(y_test_glm, pred_ridge_1se)),
  tibble(model = "Lasso (lambda.min)", RMSE = rmse_vec(y_test_glm, pred_lasso_min), MAE = mae_vec(y_test_glm, pred_lasso_min), R2 = r2_vec(y_test_glm, pred_lasso_min), MSE = mse_vec(y_test_glm, pred_lasso_min)),
  tibble(model = "Lasso (lambda.1se)", RMSE = rmse_vec(y_test_glm, pred_lasso_1se), MAE = mae_vec(y_test_glm, pred_lasso_1se), R2 = r2_vec(y_test_glm, pred_lasso_1se), MSE = mse_vec(y_test_glm, pred_lasso_1se))
) %>% arrange(RMSE)

cat("Ridge/Lasso f√¶rdig ‚úÖ\n")
print(perf_glmnet); cat("\n")
```

Resultaterne viser, at Lasso-modellen med Œª_min opn√•r den bedste pr√¶diktionsevne blandt de regulariserede modeller, med RMSE p√• 219, MAE p√• 178 og R¬≤ p√• 0,964. Dette indikerer, at en relativt begr√¶nset m√¶ngde forklaringsvariable er tilstr√¶kkelig til at forklare st√∏rstedelen af variationen i tilskuertallet, n√•r irrelevante variable undertrykkes gennem regularisering.

Valget af Œª_1se medf√∏rer, som forventet, en mere konservativ model med lavere kompleksitet, hvilket resulterer i en mindre forringelse af performance. Ridge-modellerne performer markant d√•rligere end Lasso, hvilket indikerer, at variabelselektion er afg√∏rende i denne ops√¶tning, og at shrinkage alene ikke er tilstr√¶kkeligt til at h√•ndtere multikollinearitet og st√∏j i datagrundlaget.

Samlet underst√∏tter resultaterne, at sparsomme modeller med eksplicit variabeludv√¶lgelse er bedre egnet end fuldt regulariserede modeller i den kampn√¶re D3-kontekst.

Efter evaluering af Ridge- og Lasso-modellerne udtr√¶kkes koefficienterne fra Lasso-modellen for b√•de Œª_min og Œª_1se. Antallet af ikke-nul koefficienter anvendes som m√•l for modellens kompleksitet og graden af variabelselektion.

```{r}
cat("Ridge/Lasso f√¶rdig ‚úÖ\n")
print(perf_glmnet); cat("\n")

lasso_coef_min <- as.matrix(coef(cv_lasso, s = "lambda.min"))
lasso_coef_1se <- as.matrix(coef(cv_lasso, s = "lambda.1se"))

sel_lasso_min <- setdiff(rownames(lasso_coef_min)[lasso_coef_min[,1] != 0], "(Intercept)")
sel_lasso_1se <- setdiff(rownames(lasso_coef_1se)[lasso_coef_1se[,1] != 0], "(Intercept)")

cat("Lasso non-zero (ekskl. intercept): lambda.min =", length(sel_lasso_min), " lambda.1se =", length(sel_lasso_1se), "\n\n")

```

Lasso-modellerne outperformer klart Ridge-modellerne p√• tv√¶rs af alle performance¬≠m√•l. Lasso (Œª_min) opn√•r den bedste pr√¶diktionsevne med RMSE = 219, MAE = 178, R¬≤ = 0,964 og MSE = 47 757, hvilket indikerer h√∏j forklaringsgrad og lav gennemsnitlig fejl. Lasso (Œª_1se) reducerer modelkompleksiteten med en begr√¶nset forringelse i performance (RMSE = 226, MAE = 183, R¬≤ = 0,961, MSE = 51 162). Ridge-modellerne performer markant d√•rligere, med RMSE over 438, MAE over 337 og R¬≤ under 0,86, hvilket viser, at shrinkage uden eksplicit variabelselektion ikke er tilstr√¶kkelig i denne kontekst.

Resultaterne fra de regulariserede D3-modeller samles i et struktureret objekt, der indeholder datagrundlag, estimerede modeller, performance¬≠m√•l samt udvalgte forklaringsvariable. Denne struktur sikrer reproducerbarhed og muligg√∏r systematisk videreanalyse og sammenligning p√• tv√¶rs af modeltyper.

```{r}
d3_glmnet_results <- list(
  data = list(
    train_cc = train_glm_cc,
    test_cc  = test_glm_cc,
    X_train  = X_train_glm,
    X_test   = X_test_glm,
    y_train  = y_train_glm,
    y_test   = y_test_glm,
    predictor_pool_glm = predictor_pool_glm,
    foldid_time_blocks = foldid
  ),
  models = list(cv_ridge = cv_ridge, cv_lasso = cv_lasso),
  performance = list(table = perf_glmnet),
  selected_features = list(lasso_lambda_min = sel_lasso_min, lasso_lambda_1se = sel_lasso_1se)
)

cat("D3 glmnet resultater gemt i: d3_glmnet_results ‚úÖ\n\n")
```

Lasso med Œª_min udv√¶lger et bredere s√¶t forklaringsvariable, herunder s√¶son, kampkontekst, kampn√¶re billetsalgsindikatorer, vejr samt et omfattende s√¶t modstander-dummies. Dette indikerer, at modellen udnytter b√•de eftersp√∏rgselsdynamik t√¶t p√• kampdatoen og kontekstuelle faktorer for at maksimere pr√¶diktionsevnen.

Ved Œª_1se reduceres variabels√¶ttet markant, idet f√¶rre modstandere og ingen runde- eller vejrkodevariable indg√•r, mens de mest centrale forklaringsvariable ‚Äì billetsalg tre dage f√∏r kamp, kortsigtede v√¶kstrater, s√¶sonstart, kampstartstid, temperatur og placering f√∏r kamp ‚Äì fastholdes. Dette underst√∏tter, at disse variable udg√∏r den robuste kerne i modelleringen, mens √∏vrige faktorer prim√¶rt bidrager marginalt til pr√¶diktionsevnen.

## Fair sammenligning af D3-modeller med og uden befolkningstal

I dette afsnit gennemf√∏res en fair sammenligning af D3-modeller med og uden befolkningstal, hvor b√•de datas√¶tst√∏rrelse og train-test-split holdes konstant. Form√•let er at isolere den marginale effekt af befolkningstal p√• modellernes pr√¶diktionsevne uden p√•virkning fra forskelle i datagrundlag eller modelops√¶tning. Analysen udf√∏res som et supplement og p√•virker ikke projektets hovedmodeller.

Funktionen estimerer en stepwise backward line√¶r model (AIC) p√• et givet train-test-split med et lokalt defineret variabels√¶t. Predictor-puljen afgr√¶nses til tilg√¶ngelige og informative variable, hvorefter der filtreres til complete cases og kategoriske variable h√•ndteres robust ved samling af sj√¶ldne niveauer. Modellen evalueres p√• testdatas√¶ttet ved hj√¶lp af RMSE, MAE og R¬≤, og b√•de model, performance og anvendt datagrundlag returneres samlet.

```{r}
run_models_on_split <- function(train_df, test_df, predictor_pool_local, tag = "") {
  predictor_pool_local <- predictor_pool_local[predictor_pool_local %in% names(train_df)]
  predictor_pool_local <- predictor_pool_local[vapply(predictor_pool_local, function(v) !all(is.na(train_df[[v]])), logical(1))]
  if (length(predictor_pool_local) == 0) stop("‚ùå predictor_pool_local endte tom for: ", tag)
  
  train_step2 <- train_df %>% select(tilskuere, all_of(predictor_pool_local)) %>% drop_na()
  test_step2  <- test_df  %>% select(tilskuere, all_of(predictor_pool_local)) %>% drop_na()
  
  if ("modstander" %in% names(train_step2)) {
    tmp <- safe_factor_with_other(train_step2$modstander, test_step2$modstander, "ANDRE")
    train_step2$modstander <- tmp$train
    test_step2$modstander  <- tmp$test
    rm(tmp)
  }
  
  full_formula2 <- as.formula(paste("tilskuere ~", paste(predictor_pool_local, collapse = " + ")))
  m_null2 <- lm(tilskuere ~ 1, data = train_step2)
  m_full2 <- lm(full_formula2, data = train_step2)
  
  m_bwd2 <- step(m_full2, direction = "backward", trace = 0)
  pred_bwd2 <- clip_0_cap(predict(m_bwd2, newdata = test_step2))
  
  perf2 <- tibble(
    model = paste0("Stepwise Backward (AIC)", tag),
    RMSE = rmse_vec(test_step2$tilskuere, pred_bwd2),
    MAE  = mae_vec(test_step2$tilskuere, pred_bwd2),
    R2   = r2_vec(test_step2$tilskuere, pred_bwd2),
    n_train_cc = nrow(train_step2),
    n_test_cc  = nrow(test_step2)
  )
  
  list(model = m_bwd2, performance = perf2, data = list(train = train_step2, test = test_step2))
}

```

Analysen afgr√¶nses til et fast deldatas√¶t best√•ende af kampe, hvor befolkningstal er observeret, for at sikre en fair sammenligning. Datas√¶ttet opdeles kronologisk i tr√¶nings- og testdata (80/20), og centrale kategoriske variable h√•ndteres robust gennem transformation af s√¶son og samling af sj√¶ldne modstandere. Herefter estimeres identiske modeller med og uden befolkningstal p√• samme datasplit, s√•ledes at den marginale effekt af befolkningstal p√• pr√¶diktionsevnen kan vurderes isoleret.

```{r}
if ("befolkningstal" %in% names(df_d3_all)) {
  
  df_base_131 <- df_d3_all %>% filter(!is.na(befolkningstal)) %>% arrange(kamp_dato)
  n_total_131 <- nrow(df_base_131)
  
  if (n_total_131 >= 30) {
    n_test_131  <- max(1, floor(n_total_131 * 0.20))
    cut_idx_131 <- n_total_131 - n_test_131
    train0 <- df_base_131[1:cut_idx_131, , drop = FALSE]
    test0  <- df_base_131[(cut_idx_131 + 1):n_total_131, , drop = FALSE]
    
    # robusthed: s√¶son -> s√¶son_start, modstander -> ANDRE
    train0 <- train0 %>% mutate(s√¶son_start = season_start_year(s√¶son)) %>% select(-s√¶son)
    test0  <- test0  %>% mutate(s√¶son_start = season_start_year(s√¶son)) %>% select(-s√¶son)
    if ("modstander" %in% names(train0)) {
      tmp <- safe_factor_with_other(train0$modstander, test0$modstander, "ANDRE")
      train0$modstander <- tmp$train
      test0$modstander  <- tmp$test
      rm(tmp)
    }
    
    common_pool <- c(
      "s√¶son_start","runde","kamp_time_h",
      "billetter_d3","v√¶kst_d10_d7","v√¶kst_d7_d3",
      if ("modstander" %in% names(train0)) "modstander" else NULL,
      "er_helligdag","er_h√•ndboldkamp_SAH","antal_h√•ndboldkampe",
      "temperatur_model","vejrkode_model","vejr_mangler_info",
      "placering_f√∏r_kamp"
    )
    common_pool <- common_pool[common_pool %in% names(train0)]
    
    predictor_with_pop <- unique(c(common_pool, "befolkningstal"))
    predictor_no_pop   <- setdiff(common_pool, "befolkningstal")
    
    cat("FAIR POP TEST: subset N =", n_total_131, " Train =", nrow(train0), " Test =", nrow(test0), "\n\n")
    
    res_with_pop <- run_models_on_split(train0, test0, predictor_with_pop, tag = " + POP (samme N)")
    res_no_pop   <- run_models_on_split(train0, test0, predictor_no_pop,   tag = " (samme N, uden POP)")
    
    fair_pop_comparison <- bind_rows(
      res_no_pop$performance %>% mutate(version = "Uden befolkning (samme N)"),
      res_with_pop$performance %>% mutate(version = "Med befolkning (samme N)")
    ) %>% select(version, model, RMSE, MAE, R2, n_train_cc, n_test_cc)
    
    print(fair_pop_comparison); cat("\n")
    
    d3_fair_pop_test <- list(
      subset = list(df_base = df_base_131, train0 = train0, test0 = test0),
      results = list(with_pop = res_with_pop, without_pop = res_no_pop),
      performance = list(fair_pop_comparison = fair_pop_comparison)
    )
    
    cat("D3 fair pop-test gemt i: d3_fair_pop_test ‚úÖ\n\n")
  } else {
    cat("FAIR POP TEST sprunget over: for f√• r√¶kker med befolkningstal (N < 30)\n\n")
  }
} else {
  cat("FAIR POP TEST sprunget over: df_d3_all mangler befolkningstal\n\n")
}
```

### Vurdering af FAIR POP-testen

Den fair sammenligning, hvor b√•de datas√¶tst√∏rrelse (N = 131), train-test-split og modelops√¶tning holdes konstant, viser ingen forskel i modelperformance ved inkludering af befolkningstal. Modellerne med og uden befolkningstal opn√•r identiske resultater med RMSE = 193, MAE = 155 og R¬≤ = 0,964. Derudover udv√¶lger stepwise backward (AIC) i begge tilf√¶lde den samme endelige modelstruktur, hvor befolkningstal ikke indg√•r som forklaringsvariabel.

Dette indikerer, at befolkningstal ikke bidrager med selvst√¶ndig forklaringskraft, n√•r der allerede indg√•r kampn√¶re eftersp√∏rgselsvariable s√•som billetsalg tre dage f√∏r kamp og kortsigtede v√¶kstrater.

### Betaler det sig at miste data for at beholde befolkningstal?

Nej. Resultaterne viser klart, at det ikke er fordelagtigt at reducere datagrundlaget for at inkludere befolkningstal. Variablen forbedrer hverken pr√¶diktionsevne eller forklaringsgrad og frav√¶lges endda implicit af modeludv√¶lgelsen. Set i forhold til modellens form√•l ‚Äì pr√¶cis kortsigtet forudsigelse af tilskuertal ‚Äì er det metodisk mere hensigtsm√¶ssigt at bevare flest mulige observationer og fokusere p√• kampn√¶re eftersp√∏rgselsdata.

Konklusionen er derfor, at befolkningstal ikke b√∏r indg√• i D3-modellen, hvis det kr√¶ver tab af observationer, da omkostningen i datatab ikke modsvares af nogen m√•lbar gevinst i performance.

## Grafisk sammenligning og modelrepr√¶sentation af de bedste D3-modeller

I dette afsnit visualiseres de bedst performende D3-modeller med henblik p√• at underst√∏tte den analytiske fortolkning i rapport og mundtlig eksamen. For hver model vises et *Predicted vs. Actual*-plot, hvor b√•de pr√¶diktionsevne og systematiske afvigelser kan vurderes visuelt. Derudover indlejres model¬≠ligningen og RMSE direkte i figurerne for at koble den statistiske model til dens praktiske pr√¶station.

N√∏dvendige pakker indl√¶ses med undertrykkelse af opstartsbeskeder for at sikre et ryddeligt output i rapporten. Derudover defineres en hj√¶lpefunktion, som kontrollerer, om p√•kr√¶vede objekter eksisterer i milj√∏et, f√∏r de anvendes i den efterf√∏lgende visualisering.

```{r}

suppressPackageStartupMessages({
  library(dplyr)
  library(tibble)
  library(ggplot2)
})

.must_exist <- function(x) exists(x, inherits = TRUE)

```

Der defineres en hj√¶lpefunktion til ensartet formatering af numeriske v√¶rdier med afrunding og dansk talnotation. Dette sikrer konsistent og l√¶sevenlig pr√¶sentation af resultater i de efterf√∏lgende figurer.

```{r}

.format_num <- function(x, digits = 3) {
  format(round(as.numeric(x), digits), big.mark = ".", decimal.mark = ",", trim = TRUE)
}

```

Funktionen genererer en kompakt tekstuel repr√¶sentation af en line√¶r models ligning ved at fremh√¶ve de forklaringsvariable med st√∏rst absolutte koefficienter. Dette muligg√∏r en l√¶sbar pr√¶sentation af modellens centrale effekter direkte i de grafiske visualiseringer.

```{r}
# OLS/LM: kort ligning (top |coef|)
lm_equation_text <- function(fit, digits = 3, max_terms = 8) {
  b <- coef(fit)
  b[is.na(b)] <- 0
  nm <- names(b)
  
  intercept <- if ("(Intercept)" %in% nm) b["(Intercept)"] else 0
  rest <- setdiff(nm, "(Intercept)")
  
  if (length(rest) == 0) {
    return(paste0("≈∑ = ", .format_num(intercept, digits)))
  }
  
  ord <- order(abs(b[rest]), decreasing = TRUE)
  rest <- rest[ord]
  if (length(rest) > max_terms) rest <- rest[1:max_terms]
  
  rhs <- vapply(rest, function(v) paste0(v, "¬∑", .format_num(b[v], digits)), character(1))
  paste0("≈∑ = ", .format_num(intercept, digits), " + ", paste(rhs, collapse = " + "))
}
```

Funktionen konstruerer en forenklet ligningsrepr√¶sentation af en glmnet-model ved at kombinere interceptet med de ikke-nul koefficienter med st√∏rst absolut effekt. Dette muligg√∏r en overskuelig pr√¶sentation af de mest betydende variable fra regulariserede modeller i de grafiske fremstillinger.

```{r}
# glmnet: ‚Äúligning‚Äù = intercept + top non-zero koefficienter
glmnet_equation_text <- function(cvobj, s = "lambda.min", digits = 3, max_terms = 10) {
  cm <- as.matrix(coef(cvobj, s = s))
  if (nrow(cm) == 0) return("Ingen koefficienter")
  
  coefs <- as.numeric(cm[, 1])
  names(coefs) <- rownames(cm)
  
  intercept <- if ("(Intercept)" %in% names(coefs)) coefs["(Intercept)"] else 0
  rest <- setdiff(names(coefs), "(Intercept)")
  
  nz <- rest[coefs[rest] != 0]
  if (length(nz) == 0) {
    return(paste0("≈∑ = ", .format_num(intercept, digits), "  (alle √∏vrige = 0)"))
  }
  
  ord <- order(abs(coefs[nz]), decreasing = TRUE)
  nz <- nz[ord]
  if (length(nz) > max_terms) nz <- nz[1:max_terms]
  
  rhs <- vapply(nz, function(v) paste0(v, "¬∑", .format_num(coefs[v], digits)), character(1))
  paste0("≈∑ = ", .format_num(intercept, digits), " + ", paste(rhs, collapse = " + "))
}
```

Funktionen genererer et *Predicted vs. Actual*-plot, hvor modellens forudsigelser sammenholdes med de observerede v√¶rdier. En reference¬≠linje med h√¶ldning 1 indikerer perfekt pr√¶diktion, mens RMSE og model¬≠ligningen indlejres i figuren for at koble visuel performance med kvantitativ modelkvalitet.

```{r}

# Pred vs Actual plot (med ligning + RMSE)
plot_pva_with_eq <- function(df, title, eq_text, rmse_val) {
  ggplot(df, aes(x = y, y = yhat)) +
    geom_point(alpha = 0.7) +
    geom_abline(slope = 1, intercept = 0) +
    labs(
      title = title,
      x = "Faktisk tilskuertal",
      y = "Forudsagt tilskuertal"
    ) +
    annotate(
      "text",
      x = Inf, y = -Inf,
      hjust = 1.02, vjust = -0.2,
      label = paste0("RMSE = ", .format_num(rmse_val, 1)),
      size = 3.8
    ) +
    annotate(
      "text",
      x = -Inf, y = Inf,
      hjust = -0.02, vjust = 1.15,
      label = eq_text,
      size = 3.2
    ) +
    theme_minimal()
}

```

Den bedst performende OLS-model baseret p√• stepwise backward (AIC) evalueres p√• testdatas√¶ttet, og forudsigelser sammenholdes med observerede v√¶rdier i et *Predicted vs. Actual*-plot. Modellens ligning og RMSE indlejres i figuren for at give en samlet visuel og kvantitativ vurdering af pr√¶diktionsevnen.

```{r}
# ---------------------------
# 10B) OLS (Stepwise backward) ‚Äî altid hvis findes
# ---------------------------
if (!.must_exist("m_step_bwd") || !.must_exist("test_step")) {
  stop("‚ùå Kan ikke lave modelplots: mangler m_step_bwd og/eller test_step.")
}

pred_ols <- clip_0_cap(predict(m_step_bwd, newdata = test_step))
df_ols <- tibble(y = as.numeric(test_step$tilskuere), yhat = as.numeric(pred_ols))
rmse_ols <- rmse_vec(df_ols$y, df_ols$yhat)
eq_ols <- lm_equation_text(m_step_bwd, digits = 3, max_terms = 8)

p_ols <- plot_pva_with_eq(
  df = df_ols,
  title = "D3 ‚Äî OLS Stepwise Backward (AIC): Pred vs Actual",
  eq_text = eq_ols,
  rmse_val = rmse_ols
)
print(p_ols)

```

/

*Grafen ‚ÄúD3 ‚Äî OLS Stepwise Backward (AIC): Pred vs Actual‚Äù viser sammenh√¶ngen mellem faktiske og forudsagte tilskuertal for den bedst performende D3-model. Ved at sammenholde observationerne med reference¬≠linjen for perfekt pr√¶diktion giver grafen et visuelt grundlag for at vurdere modellens pr√¶diktionsevne og eventuelle systematiske afvigelser.*

Best subset-modellen baseret p√• BIC visualiseres, hvis et gyldigt variabels√¶t foreligger, ved at genestimere modellen p√• tr√¶ningsdata for at opn√• en konsistent og fortolkbar ligning. Modellens forudsigelser evalueres p√• testdatas√¶ttet og pr√¶senteres i et *Predicted vs. Actual*-plot med indlejret ligning og RMSE.

```{r}
# ---------------------------
# 10C) Best subset (BIC) ‚Äî hvis sel_cols findes
#      (refit lm for at f√• ‚Äúrigtig‚Äù ligning og predict)
# ---------------------------
has_subset <- .must_exist("sel_cols") && is.character(sel_cols) && length(sel_cols) > 0 &&
  .must_exist("train_step") && .must_exist("test_step")

if (has_subset) {
  f_sub <- as.formula(paste0("tilskuere ~ ", paste(sel_cols, collapse = " + ")))
  fit_sub_refit <- lm(f_sub, data = train_step)
  
  pred_sub <- clip_0_cap(predict(fit_sub_refit, newdata = test_step))
  df_sub <- tibble(y = as.numeric(test_step$tilskuere), yhat = as.numeric(pred_sub))
  rmse_sub <- rmse_vec(df_sub$y, df_sub$yhat)
  eq_sub <- lm_equation_text(fit_sub_refit, digits = 3, max_terms = 8)
  
  p_sub <- plot_pva_with_eq(
    df = df_sub,
    title = "D3 ‚Äî Best subset (BIC, refit-lm): Pred vs Actual",
    eq_text = eq_sub,
    rmse_val = rmse_sub
  )
  print(p_sub)
} else {
  cat("\n‚ÑπÔ∏è Best subset-plot sprang over (sel_cols/train_step/test_step mangler eller sel_cols er tom).\n")
}

```

Grafen *‚ÄúD3 ‚Äî Best subset (BIC, refit-lm): Pred vs Actual‚Äù* illustrerer forholdet mellem faktiske og forudsagte tilskuertal for D3-modellen estimeret via best subset-udv√¶lgelse baseret p√• BIC. Grafen viser, hvordan en relativt kompakt model med f√• centrale forklaringsvariable form√•r at ramme observationerne t√¶t langs reference¬≠linjen for perfekt pr√¶diktion. Den lave RMSE indikerer, at modellen opn√•r en pr√¶cision, der er fuldt p√• h√∏jde med ‚Äì og marginalt bedre end ‚Äì den tilsvarende stepwise-model, samtidig med at modelkompleksiteten holdes nede.

Lasso- og Ridge-modellerne visualiseres for den optimale regulariseringsparameter Œª_min ved hj√¶lp af *Predicted vs. Actual*-plots, hvor RMSE og en forenklet ligningsrepr√¶sentation indlejres i figurerne. Derudover vises krydsvalideringskurver for begge modeller for at illustrere sammenh√¶ngen mellem regularisering og valideringsfejl. Dette giver et samlet visuelt grundlag for at vurdere b√•de pr√¶diktionsevne og modelkompleksitet.

```{r}

# ---------------------------
# 10D) glmnet: Lasso/Ridge (lambda.min) ‚Äî hvis objekter findes
# ---------------------------
has_glmnet <- .must_exist("cv_lasso") && .must_exist("cv_ridge") && .must_exist("X_test_glm") && .must_exist("y_test_glm")

if (has_glmnet) {
  pred_lasso <- clip_0_cap(as.numeric(predict(cv_lasso, newx = X_test_glm, s = "lambda.min")))
  pred_ridge <- clip_0_cap(as.numeric(predict(cv_ridge, newx = X_test_glm, s = "lambda.min")))
  
  df_lasso <- tibble(y = as.numeric(y_test_glm), yhat = as.numeric(pred_lasso))
  df_ridge <- tibble(y = as.numeric(y_test_glm), yhat = as.numeric(pred_ridge))
  
  rmse_lasso <- rmse_vec(df_lasso$y, df_lasso$yhat)
  rmse_ridge <- rmse_vec(df_ridge$y, df_ridge$yhat)
  
  eq_lasso <- glmnet_equation_text(cv_lasso, s = "lambda.min", digits = 3, max_terms = 10)
  eq_ridge <- glmnet_equation_text(cv_ridge, s = "lambda.min", digits = 3, max_terms = 10)
  
  p_lasso <- plot_pva_with_eq(
    df = df_lasso,
    title = "D3 ‚Äî Lasso (lambda.min): Pred vs Actual",
    eq_text = eq_lasso,
    rmse_val = rmse_lasso
  )
  p_ridge <- plot_pva_with_eq(
    df = df_ridge,
    title = "D3 ‚Äî Ridge (lambda.min): Pred vs Actual",
    eq_text = eq_ridge,
    rmse_val = rmse_ridge
  )
  
  print(p_lasso)
  print(p_ridge)
  
  #  CV-kurver som ggplot ‚Äî p√¶nt i rapport
  plot_cv_glmnet <- function(cvobj, title = "") {
    df <- tibble(lambda = cvobj$lambda, cvm = cvobj$cvm, cvsd = cvobj$cvsd)
    lam_min <- cvobj$lambda.min
    lam_1se <- cvobj$lambda.1se
    
    ggplot(df, aes(x = log(lambda), y = cvm)) +
      geom_line() +
      geom_line(aes(y = cvm + cvsd), linetype = 2) +
      geom_line(aes(y = cvm - cvsd), linetype = 2) +
      geom_vline(xintercept = log(lam_min), linetype = 3) +
      geom_vline(xintercept = log(lam_1se), linetype = 3) +
      labs(title = title, x = "log(Œª)", y = "CV MSE") +
      theme_minimal()
  }
  
  print(plot_cv_glmnet(cv_lasso, "D3 ‚Äî Lasso CV-kurve (ggplot)"))
  print(plot_cv_glmnet(cv_ridge, "D3 ‚Äî Ridge CV-kurve (ggplot)"))
} else {
  cat("\n‚ö†Ô∏è glmnet-plots sprang over (mangler cv_lasso/cv_ridge/X_test_glm/y_test_glm).\n")
}

```

*Grafen ‚ÄúD3 ‚Äî Lasso (lambda.min): Pred vs Actual‚Äù viser sammenh√¶ngen mellem faktiske og forudsagte tilskuertal for D3-modellen estimeret med Lasso-regularisering ved Œª_min. Punkterne ligger generelt t√¶t omkring 45-graderslinjen, hvilket indikerer en h√∏j grad af overensstemmelse mellem modelprediktioner og observerede v√¶rdier. Den opn√•ede RMSE p√• omkring 218 viser, at modellen pr√¶sterer p√• et niveau, der er sammenligneligt med de bedste OLS-baserede modeller, men med den v√¶sentlige forskel, at Lasso automatisk har foretaget variabelselektion. Det betyder, at modellen reducerer kompleksiteten ved at s√¶tte mindre relevante koefficienter til nul, samtidig med at den bevarer en h√∏j pr√¶diktionsevne.*

![](images/Ridge%20(lambda.min)%20Pred%20vs%20Actual.png){fig-align="center"}

*Grafen ‚ÄúD3 ‚Äî ‚Äù illustrerer sammenh√¶ngen mellem faktiske og forudsagte tilskuertal for D3-modellen estimeret med Ridge-regularisering ved Œª_min. I mods√¶tning til de √∏vrige modeller ses en tydelig st√∏rre spredning omkring 45-graderslinjen, hvilket indikerer en lavere pr√¶diktionsevne. Den relativt h√∏je RMSE p√• cirka 439 afspejler, at modellen har vanskeligt ved pr√¶cist at ramme b√•de lave og h√∏je tilskuertal. Resultatet viser, at Ridge-modellen ‚Äì trods regularisering ‚Äì ikke form√•r at tilpasse sig datam√∏nstrene p√• samme niveau som OLS- og Lasso-modellerne i denne D3-kontekst.*

![](images/2026-01-05_03h44_25.png)

*N√•r vi ser p√• grafen ‚ÄúD3 ‚Äî Lasso CV-kurve (ggplot)‚Äù, illustrerer den, hvordan modellens pr√¶diktionsfejl varierer som funktion af regulariseringsparameteren Œª i Lasso-modellen. X-aksen viser log(Œª), mens y-aksen viser den krydsvaliderede middelkvadrerede fejl (CV MSE), som er beregnet via tidsblok-baseret krydsvalidering. Kurvens laveste punkt angiver det Œª-niveau, hvor modellen opn√•r den bedste gennemsnitlige performance p√• tv√¶rs af foldene (Œª_min). De lodrette stiplede linjer markerer henholdsvis Œª_min og Œª_1se, hvor sidstn√¶vnte repr√¶senterer en mere konservativ model, der accepterer en marginalt h√∏jere fejl til geng√¶ld for √∏get regularisering og lavere modelkompleksitet. Grafen viser samtidig, at fejlen stiger markant ved h√∏je Œª-v√¶rdier, hvilket afspejler underfitting, n√•r for mange koefficienter presses mod nul.*

![](images/2026-01-05_03h45_16.png)

*N√•r vi betragter grafen ‚ÄúD3 ‚Äî Ridge CV-kurve (ggplot)‚Äù, viser den sammenh√¶ngen mellem regulariseringsparameteren Œª og modellens krydsvaliderede fejl for Ridge-modellen. X-aksen angiver log(Œª), mens y-aksen viser den krydsvaliderede middelkvadrerede fejl (CV MSE), beregnet via tidsblok-opdelt krydsvalidering. Kurven illustrerer, at modellen har lavest fejl ved relativt lave Œª-v√¶rdier, hvor regulariseringen er svag. De lodrette stiplede linjer markerer Œª_min og Œª_1se, som angiver henholdsvis den Œª-v√¶rdi med lavest gennemsnitlig CV-fejl og en mere konservativ l√∏sning inden for √©n standardafvigelse. I takt med at Œª √∏ges, stiger fejlen markant, hvilket indikerer underfitting som f√∏lge af kraftig shrinkage af koefficienterne. I mods√¶tning til Lasso s√¶tter Ridge ikke koefficienter pr√¶cist til nul, og grafen afspejler derfor, at √∏get regularisering hurtigt reducerer modellens fleksibilitet uden at tilf√∏re stabil pr√¶diktionsevne i denne D3-kontekst.*

## Operationalisering af D3-modeller via Shiny-applikation

For at demonstrere, hvordan de estimerede D3-modeller kunnen anvendes i praksis, er der udviklet en interaktiv Shiny-applikation. Applikationen indg√•r ikke som en integreret del af selve QMD-filen, men pr√¶senteres her som dokumentation for, at modellerne er operationaliseret og kan anvendes i en beslutningsst√∏ttekontekst.

Form√•let med applikationen er at afpr√∏ve modellernes anvendelighed i et realistisk scenarie, hvor en bruger ‚Äì eksempelvis en medarbejder i Viborg FF ‚Äì kan indtaste kamp- og kontekstspecifikke oplysninger og modtage en konkret prognose for det forventede tilskuertal. Dermed fungerer applikationen som et bindeled mellem den statistiske modellering og den forretningsm√¶ssige anvendelse.

Applikationen bygger direkte p√• de samme modeller, datastrukturer og pr√¶diktionstrin, som er anvendt i analyse- og evalueringsafsnittene. Koden gennemg√•s derfor p√• samme m√•de som resten af projektets pipeline, med fokus p√• transparens, reproducerbarhed og konsistens mellem analyse og produkt.

Koden indl√¶ser de n√∏dvendige pakker og sikrer, at den estimerede D3-model samt tr√¶ningsdata er tilg√¶ngelige, s√• applikationen anvender samme grundlag som analysen.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

suppressPackageStartupMessages({
  library(shiny)
  library(dplyr)
  library(ggplot2)
})

if (!exists("m_step_bwd", inherits = TRUE)) stop("Mangler m_step_bwd i environment.")
if (!exists("train_step", inherits = TRUE)) stop("Mangler train_step i environment.")

```

Denne hj√¶lpefunktion anvendes til at formatere numeriske v√¶rdier ensartet, s√• modeloutput pr√¶senteres l√¶sbart med korrekt afrunding og dansk talnotation.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

.format_num <- function(x, digits = 3) {
  format(round(as.numeric(x), digits), big.mark = ".", decimal.mark = ",", trim = TRUE)
}

```

Funktionen genererer en kort, l√¶sbar repr√¶sentation af en line√¶r models ligning ved at vise interceptet og de mest betydende koefficienter baseret p√• absolut st√∏rrelse.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

# Kort ligning for lm: viser intercept + top |coef|
lm_equation_text <- function(fit, digits = 3, max_terms = 8) {
  b <- coef(fit)
  b[is.na(b)] <- 0
  nm <- names(b)
  
  intercept <- if ("(Intercept)" %in% nm) b["(Intercept)"] else 0
  rest <- setdiff(nm, "(Intercept)")
  
  if (length(rest) == 0) return(paste0("≈∑ = ", .format_num(intercept, digits)))
  
  ord <- order(abs(b[rest]), decreasing = TRUE)
  rest <- rest[ord]
  if (length(rest) > max_terms) rest <- rest[1:max_terms]
  
  rhs <- vapply(rest, function(v) paste0(v, "¬∑", .format_num(b[v], digits)), character(1))
  paste0("≈∑ = ", .format_num(intercept, digits), " + ", paste(rhs, collapse = " + "))
}

```

Denne hj√¶lpefunktion sikrer, at brugerinput castes til samme datatype og struktur som i tr√¶ningsdata, s√• pr√¶diktioner kan foretages korrekt og robust.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

# Helper: lav korrekt datatype ud fra train_step
.cast_like_train <- function(var, value) {
  ref <- train_step[[var]]
  
  if (is.factor(ref)) {
    lvls <- levels(ref)
    v <- as.character(value)
    if (is.na(v) || !(v %in% lvls)) {
      if ("ANDRE" %in% lvls) v <- "ANDRE" else v <- lvls[1]
    }
    return(factor(v, levels = lvls))
  }
  
  if (inherits(ref, "Date")) return(as.Date(value))
  if (is.integer(ref)) return(as.integer(value))
  if (is.numeric(ref)) return(as.numeric(value))
  
  as.character(value)
}

```

Funktionen opretter dynamiske inputfelter i brugergr√¶nsefladen baseret p√• variablernes datatyper i tr√¶ningsdata, s√• brugeren kun kan indtaste gyldige v√¶rdier for den valgte model.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


# UI controls dynamisk ud fra valgte model_vars + train_step
.make_input_control <- function(var) {
  x <- train_step[[var]]
  
  if (is.factor(x)) {
    selectInput(
      inputId = var,
      label = var,
      choices = levels(x),
      selected = levels(x)[1]
    )
  } else if (is.numeric(x) || is.integer(x)) {
    rng <- range(x, na.rm = TRUE)
    val <- stats::median(x, na.rm = TRUE)
    numericInput(
      inputId = var,
      label = var,
      value = val,
      min = rng[1],
      max = rng[2]
    )
  } else if (inherits(x, "Date")) {
    dateInput(
      inputId = var,
      label = var,
      value = Sys.Date()
    )
  } else {
    textInput(
      inputId = var,
      label = var,
      value = ""
    )
  }
}

```

Funktionen klassificerer den estimerede stadionfyldning i diskrete niveauer baseret p√• procentvis kapacitetsudnyttelse, s√• resultatet kan formidles enkelt og intuitivt.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

# Fyldnings-buckets
.fill_bucket <- function(pct) {
  if (!is.finite(pct)) return("UKENDT")
  if (pct >= 85) return("H√òJ")
  if (pct >= 60) return("MIDDEL")
  "LAV"
}
```

Denne kode kontrollerer, om en Best Subset-model kan genskabes p√• baggrund af de valgte variable og tr√¶ningsdata. Hvis det er muligt, refittes modellen og v√¶lges som standard; ellers anvendes den estimerede stepwise OLS-model.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

# ---------------------------
# Byg Best Subset refit-model hvis muligt
# ---------------------------
best_subset_available <- exists("sel_cols", inherits = TRUE) &&
  is.character(sel_cols) && length(sel_cols) > 0 &&
  all(sel_cols %in% names(train_step))

fit_best_subset <- NULL
if (best_subset_available) {
  f_sub <- as.formula(paste0("tilskuere ~ ", paste(sel_cols, collapse = " + ")))
  fit_best_subset <- lm(f_sub, data = train_step)
}

# Default model: bedste hvis available, ellers stepwise
default_model_key <- if (!is.null(fit_best_subset)) "best_subset" else "stepwise"

```

Denne kode kontrollerer, om en Best Subset-model kan genskabes p√• baggrund af de valgte variable og tr√¶ningsdata. Hvis det er muligt, refittes modellen og v√¶lges som standard; ellers anvendes den estimerede stepwise OLS-model.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


# ---------------------------
# UI
# ---------------------------
ui <- fluidPage(
  titlePanel("D3 ‚Äî Prediction (Modelvalg)"),
  
  sidebarLayout(
    sidebarPanel(
      tags$h4("Model"),
      selectInput(
        "model_choice",
        "V√¶lg model (Bedste model valgt by default",
        choices = c(
          "Best subset (BIC) ‚Äî refit-lm" = "best_subset",
          "OLS stepwise backward (AIC)" = "stepwise"
        ),
        selected = default_model_key
      ),
      tags$hr(),
      
      tags$h4("Inputs (kun de variable modellen bruger)"),
      uiOutput("dyn_inputs"),
      
      tags$hr(),
      numericInput("capacity", "Stadion-kapacitet", value = 10000, min = 1),
      actionButton("go", "Predict", class = "btn-primary")
    ),
    
    mainPanel(
      tags$h4("Output"),
      tags$div(style="font-size:20px; margin-bottom:8px;",
               textOutput("pred_txt")),
      tags$div(style="font-size:20px; margin-bottom:8px;",
               textOutput("pct_txt")),
      tags$div(style="font-size:20px; margin-bottom:8px;",
               textOutput("delta_txt")),
      tags$div(style="font-size:14px; margin-bottom:14px; color:#333;",
               textOutput("eq_txt")),
      plotOutput("cap_plot", height = "520px")
    )
  )
)

```

Denne server-del udg√∏r den operationelle kerne i Shiny-applikationen og binder model, input og output sammen i en interaktiv arbejdsgang.

Serveren h√•ndterer f√∏rst valg af aktiv model (Best Subset eller OLS stepwise) og sikrer et robust fallback, hvis den foretrukne model ikke er tilg√¶ngelig. P√• baggrund af den valgte model identificeres de relevante forklarende variable, hvorefter inputfelterne genereres dynamisk, s√• brugeren kun pr√¶senteres for variable, der faktisk indg√•r i modellen.

N√•r brugeren aktiverer en prediction, konstrueres et korrekt typet input-datas√¶t, som anvendes til at beregne det forudsagte tilskuertal. Resultatet efterbehandles med simple, forretningsn√¶re m√•l s√•som kapacitetsudnyttelse og forventet ekstra billetsalg fra D3 til kampdag. Output pr√¶senteres b√•de tekstuelt og grafisk, herunder en kapacitetsgraf, der tydeligg√∏r forholdet mellem den estimerede eftersp√∏rgsel og stadionets maksimale kapacitet.

Samlet set demonstrerer server-logikken, hvordan de estimerede modeller kan operationaliseres i et beslutningsst√∏ttev√¶rkt√∏j, der oms√¶tter statistiske modeller til konkrete og anvendelige indsigter for en organisation.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


# ---------------------------
# Server
# ---------------------------
server <- function(input, output, session) {
  
  # Aktiv model (reactive)
  active_model <- reactive({
    key <- input$model_choice
    
    if (key == "best_subset") {
      if (is.null(fit_best_subset)) {
        return(list(
          key = "stepwise",
          fit = m_step_bwd,
          name = "OLS stepwise backward (AIC) (fallback)",
          note = "Best subset er ikke tilg√¶ngelig (sel_cols mangler eller passer ikke til train_step)."
        ))
      }
      return(list(
        key = "best_subset",
        fit = fit_best_subset,
        name = "Best subset (BIC) ‚Äî refit-lm",
        note = ""
      ))
    }
    
    list(
      key = "stepwise",
      fit = m_step_bwd,
      name = "OLS stepwise backward (AIC)",
      note = ""
    )
  })
  
  # Hvilke variable bruger den valgte model?
  model_vars <- reactive({
    fit <- active_model()$fit
    vars <- all.vars(stats::terms(fit)) |> setdiff("tilskuere")
    vars
  })
  
  # Dynamiske inputs
  output$dyn_inputs <- renderUI({
    tagList(lapply(model_vars(), .make_input_control))
  })
  
  # Prediction objekt
  pred_obj <- eventReactive(input$go, {
    
    fit <- active_model()$fit
    vars <- model_vars()
    
    # Byg √©n-r√¶kkes newdata med korrekt type pr variabel
    nd <- as.data.frame(setNames(replicate(length(vars), NA, simplify = FALSE), vars))
    
    for (v in vars) {
      nd[[v]] <- .cast_like_train(v, input[[v]])
    }
    
    # Predict
    yhat <- suppressWarnings(as.numeric(predict(fit, newdata = nd)))
    if (length(yhat) == 0) yhat <- NA_real_
    
    # Clip til ikke-negative (ingen h√•rd cap p√• 1.000.000 i pipeline, men vi holder det her som sikkerhed)
    yhat_clip <- max(min(yhat, 1000000), 0)
    
    cap <- as.numeric(input$capacity)
    if (!is.finite(cap) || cap <= 0) cap <- 1
    
    pct <- (yhat_clip / cap) * 100
    pct_clip <- max(min(pct, 100), 0)
    
    # Ekstra billetsalg fra D3 -> kampdag: ≈∑ - billetter_d3 (kun hvis billetter_d3 i modellen/inputs)
    bil_d3 <- if ("billetter_d3" %in% vars) as.numeric(input$billetter_d3) else NA_real_
    delta <- if (is.finite(bil_d3)) (yhat_clip - bil_d3) else NA_real_
    
    eq_text <- lm_equation_text(fit, digits = 3, max_terms = 10)
    
    list(
      pred = yhat_clip,
      pct = pct_clip,
      cap = cap,
      bil_d3 = bil_d3,
      delta = delta,
      eq = eq_text,
      model_name = active_model()$name,
      model_note = active_model()$note
    )
  })
  
  output$pred_txt <- renderText({
    x <- pred_obj()
    if (is.null(x)) return("Ingen prediction endnu.")
    paste0("Model: ", x$model_name, "\nForudsagt tilskuertal: ",
           format(round(x$pred), big.mark = ".", decimal.mark = ","))
  })
  
  output$pct_txt <- renderText({
    x <- pred_obj()
    if (is.null(x)) return("")
    paste0("Stadion fyldt: ", format(round(x$pct, 1), big.mark = ".", decimal.mark = ","), " %")
  })
  
  output$delta_txt <- renderText({
    x <- pred_obj()
    if (is.null(x)) return("")
    if (!is.finite(x$bil_d3)) return("Ekstra billetter (D3 ‚Üí kampdag): kan ikke beregnes (billetter_d3 er ikke valgt/input)")
    paste0(
      "Ekstra billetter (D3 ‚Üí kampdag): ",
      format(round(x$delta), big.mark = ".", decimal.mark = ","),
      "  (≈∑ ‚àí billetter_d3)"
    )
  })
  
  output$eq_txt <- renderText({
    x <- pred_obj()
    if (is.null(x)) return("")
    note <- if (!is.null(x$model_note) && nzchar(x$model_note)) paste0("\nNote: ", x$model_note) else ""
    paste0("Ligning (kort): ", x$eq, note)
  })
  
  output$cap_plot <- renderPlot({
    x <- pred_obj()
    if (is.null(x)) return(NULL)
    
    bucket <- .fill_bucket(x$pct)
    
    df <- data.frame(
      label = "Stadionkapacitet",
      y = x$pred,
      bucket = bucket
    )
    
    ggplot(df, aes(x = label, y = y, fill = bucket)) +
      geom_col(width = 0.6) +
      geom_hline(yintercept = x$cap, linewidth = 0.9, linetype = 2) +
      coord_cartesian(ylim = c(0, x$cap)) +
      scale_fill_manual(
        values = c("LAV" = "#d55e00", "MIDDEL" = "#e69f00", "H√òJ" = "#009e73", "UKENDT" = "grey60"),
        breaks = c("LAV","MIDDEL","H√òJ","UKENDT"),
        name = "Fyldningsniveau"
      ) +
      labs(
        x = NULL,
        y = "Tilskuere (forudsagt)",
        title = "Forudsagt tilskuertal vs stadionkapacitet",
        subtitle = paste0(
          "Kapacitet (stiplet linje): ",
          format(round(x$cap), big.mark=".", decimal.mark=",")
        )
      ) +
      theme_minimal(base_size = 16) +
      theme(
        legend.position = "top",
        plot.title = element_text(face = "bold"),
        panel.grid.minor = element_blank()
      )
  })
}

shinyApp(ui, server)


```

## To scenarier for tilskuertal i Superligaen baseret p√• D3-modellen

### Scenarie 1 ‚Äì H√∏j interesse og n√¶sten fyldt stadion

Palle arbejder med billetsalg og planl√¶gning hos Viborg FF og st√•r tre dage f√∏r en Superliga-hjemmekamp over for en modstander, der historisk tr√¶kker mange tilskuere. Allerede p√• D3-tidspunktet er der solgt 7.200 billetter. I perioden fra 10 til 7 dage f√∏r kamp er billetsalget steget med 1.400 billetter, og fra 7 dage til 3 dage f√∏r kamp er salget yderligere accelereret med 1.900 billetter.

![](images/2026-01-05_04h00_17.png)

Disse tal indtaster Palle i Shiny-applikationen, hvor stadionkapaciteten er sat til 10.000 pladser. Den valgte model (Best subset, BIC) estimerer p√• baggrund af disse inputs et forventet tilskuertal p√• 8.573, svarende til en fyldningsgrad p√• 85,7 %. Modellen indikerer dermed, at der fortsat kan forventes et betydeligt billetsalg frem mod kampdagen, med cirka 1.373 ekstra solgte billetter fra D3 til kickoff.

For Palle betyder dette, at kampen med h√∏j sandsynlighed bliver t√¶t p√• udsolgt. Resultatet kan bruges direkte i den operative planl√¶gning, eksempelvis i forhold til bemanding, catering, sikkerhed og markedsf√∏ring, hvor fokus nu kan flyttes fra bred synlighed til m√•lrettet sidste-√∏jebliks salg.

### Scenarie 2 ‚Äì Lav eftersp√∏rgsel og behov for salgsindsats

Daniel arbejder i den kommercielle afdeling og analyserer en anden Superliga-hjemmekamp, hvor interessen ser mere afd√¶mpet ud. Tre dage f√∏r kamp er der solgt 3.501 billetter. Billetsalget har haft en moderat udvikling, med en stigning p√• 733 billetter fra 10 til 7 dage f√∏r kamp og yderligere 911 billetter fra 7 til 3 dage f√∏r kamp.

![](images/2026-01-05_03h55_21-01.png)

Daniel indtaster disse v√¶rdier i Shiny-appen sammen med stadionkapaciteten p√• 10.000. Modellen estimerer her et forventet tilskuertal p√• 4.101, hvilket svarer til en fyldningsgrad p√• cirka 41 %. Der forventes kun omkring 600 ekstra solgte billetter frem mod kampdagen, hvis udviklingen forts√¶tter u√¶ndret.

Dette scenarie giver Daniel et klart beslutningsgrundlag: uden en ekstra salgs- eller marketingindsats vil kampen sandsynligvis f√• et lavt fremm√∏de. Modellen kan dermed bruges som et tidligt advarselssignal, der g√∏r det muligt at iv√¶rks√¶tte kampagner, tilbud eller samarbejder med kort varsel for at l√∏fte interessen.

# ML model D7

Her pr√¶senteres udviklingen af **MODEL_D7**, som har til form√•l at forudsige tilskuertallet til Viborg FF‚Äôs hjemmekampe **7 dage f√∏r kampstart**. Modellen indg√•r i et samlet prognoseframework med fokus p√• robuste, forklarlige og operationelle l√∏sninger frem for maksimal kompleksitet.

Analysen tager udgangspunkt i et baseline-datas√¶t med √©n observation pr. kamp, som gradvist udvides med relevante forklaringsvariable, herunder billetsalg, kampkontekst, kalender¬≠effekter, vejr og temperatur samt udvalgte strukturelle forhold. Nye variable testes systematisk mod en fast baseline og vurderes p√• baggrund af statistiske kriterier, modelkvalitet og datatab.

Den endelige D7-model evalueres ved et tidssplit og sammenlignes p√• tv√¶rs af OLS-, Ridge- og Lasso-modeller. Resultaterne anvendes b√•de analytisk og i et efterf√∏lgende produktlag, hvor modellen operationaliseres gennem visualiseringer og en interaktiv applikation.

## Pakker og globale indstillinger

Denne kodeblok indl√¶ser de n√∏dvendige pakker til analysen.\
Samtidig justeres globale indstillinger for mere l√¶sbart output.

```{r}
if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman")
}

suppressPackageStartupMessages({
  pacman::p_load(
    DBI,
    odbc,
    dplyr,
    tidyr,
    lubridate,
    stringr,
    tibble,
    ggplot2,
    glmnet,
    rsample
  )
})

options(scipen = 999)
cat("Pakker er klar ‚úÖ\n\n")

```

## Hj√¶lpefunktioner

Denne funktion sikrer, at alle n√∏dvendige milj√∏variabler til databaseforbindelsen er korrekt sat. Hvis kravene ikke er opfyldt, stoppes analysen for at undg√• skjulte forbindelsesfejl senere i pipeline‚Äôen.

### .Renviron

```{r}
ensure_renviron <- function() {
required_vars <- c("AZURE_SQL_SERVER",
                   "AZURE_SQL_DB",
                   "AZURE_SQL_UID",
                   "AZURE_SQL_PWD")
  values <- Sys.getenv(required_vars)
  missing_vars <- required_vars[values == ""]
  if (length(missing_vars) > 0) stop("‚ùå Manglende milj√∏variabler i .Renviron: ", paste(missing_vars, collapse = ", "))
  cat("‚úî .Renviron OK\n\n")
}
```

### Robust databaseforbindelse

Denne funktion opretter en stabil forbindelse til Azure SQL med gentagne fors√∏g og stigende timeouts. Form√•let er at reducere midlertidige forbindelsesfejl og sikre, at analysen kan k√∏re reproducerbart.

```{r}

connect_azure_retry <- function(fors√∏g_max = 6, timeouts = c(60, 180, 200, 260, 360, 600), delay_sec = 10) {
  for (fors√∏g in seq_len(fors√∏g_max)) {
    timeout_brug <- timeouts[min(fors√∏g, length(timeouts))]
    cat("Fors√∏g", fors√∏g, "- ConnectionTimeout =", timeout_brug, "sekunder\n")
    con_try <- try(
      DBI::dbConnect(
        odbc::odbc(),
        driver   = "ODBC Driver 18 for SQL Server",
        server   = Sys.getenv("AZURE_SQL_SERVER"),
        database = Sys.getenv("AZURE_SQL_DB"),
        uid      = Sys.getenv("AZURE_SQL_UID"),
        pwd      = Sys.getenv("AZURE_SQL_PWD"),
        Encrypt  = "yes",
        TrustServerCertificate = "no",
        ConnectionTimeout = timeout_brug
      ),
      silent = TRUE
    )
    if (!inherits(con_try, "try-error")) {
      cat("‚úÖ Forbundet til Azure SQL p√• fors√∏g", fors√∏g, "\n\n")
      return(con_try)
    }
    if (fors√∏g < fors√∏g_max) Sys.sleep(delay_sec)
  }
  stop("‚ùå Kunne ikke forbinde til Azure SQL efter ", fors√∏g_max, " fors√∏g.")
}
```

### Sikker indl√¶sning af databaser

Denne funktion l√¶ser tabeller fra databasen med indbyggede genfors√∏g ved fejl.\
Den sikrer, at midlertidige l√¶sefejl ikke stopper analysen un√∏digt.

```{r}

safe_dbReadTable <- function(con, schema, table, fors√∏g_max = 4, delay_sec = 3) {
  for (i in seq_len(fors√∏g_max)) {
    out <- try(DBI::dbReadTable(con, DBI::Id(schema = schema, table = table)), silent = TRUE)
    if (!inherits(out, "try-error")) return(out)
    msg <- as.character(out)
    cat("‚ö†Ô∏è dbReadTable fejlede (fors√∏g", i, "af", fors√∏g_max, "):", schema, ".", table, "\n")
    cat(substr(msg, 1, 220), "...\n\n")
    if (i < fors√∏g_max) Sys.sleep(delay_sec)
  }
  stop("‚ùå Kunne ikke l√¶se tabel: ", schema, ".", table)
}

```

### Normalisering af tidsformater

Denne funktion sikrer ensartet tidsformat ved at udvide klokkesl√¶t uden sekunder.\
Det g√∏r efterf√∏lgende tidsbaserede beregninger mere robuste.

```{r}
normalize_time_chr <- function(x) {
  x <- str_trim(as.character(x))
  if_else(str_detect(x, "^\\d{1,2}:\\d{2}$"), paste0(x, ":00"), x)
}

```

### Udtr√¶k af timekomponent

Denne funktion konverterer tidsstrenge til heltals-timer.\
Det muligg√∏r simple og konsistente tidsafh√¶ngige features i analysen.

```{r}
time_chr_to_hour <- function(x) {
  x <- normalize_time_chr(x)
  ok <- str_detect(x, "^\\d{1,2}:\\d{2}:\\d{2}$")
  out <- rep(NA_integer_, length(x))
  out[ok] <- as.integer(str_extract(x[ok], "^\\d{1,2}"))
  out
}

```

### Parsing af observationsdatoer

Denne funktion sikrer korrekt konvertering af datoer til Date-format.\
Det giver konsistent datoh√•ndtering p√• tv√¶rs af datakilder.

```{r}

parse_obs_date <- function(x) {
  if (inherits(x, "Date")) return(x)
  as.Date(x, format = "%d-%m-%Y")
}
```

### Udledning af s√¶sonens start√•r

Denne funktion udtr√¶kker s√¶sonens start√•r fra s√¶sonbetegnelser.\
Det muligg√∏r numerisk modellering af s√¶sonvariationer.

```{r}

season_start_year <- function(x) {
  x <- as.character(x)
  suppressWarnings(as.integer(sub("^([0-9]{4}).*$", "\\1", x)))
}
```

### Evalueringsm√•l

Disse funktioner beregner RMSE, MAE og R¬≤ til vurdering af modellernes pr√¶cision. De anvendes konsekvent til sammenligning af modelperformance.

```{r}
rmse_vec <- function(y, yhat) sqrt(mean((y - yhat) ^ 2, na.rm = TRUE))
mae_vec  <- function(y, yhat) mean(abs(y - yhat), na.rm = TRUE)
r2_vec <- function(y, yhat) {
  sse <- sum((y - yhat) ^ 2, na.rm = TRUE)
  sst <- sum((y - mean(y, na.rm = TRUE)) ^ 2, na.rm = TRUE)
  1 - (sse / sst)
}
```

### Hj√¶lpefunktioner til datarensning

Disse funktioner sikrer henholdsvis, at forudsigelser ikke bliver negative, og at der kun bevares √©n observation pr. n√∏gle. Ved dubletter prioriteres r√¶kker med f√¶rrest manglende v√¶rdier.

```{r}

clip_nonneg <- function(x) pmax(x, 0)

dedup_by_na <- function(df, id_col) {
  id_col <- rlang::ensym(id_col)
  df2 <- df
  df2$.na_count <- rowSums(is.na(df2))
  df2 |>
    arrange(!!id_col, .na_count) |>
    group_by(!!id_col) |>
    slice(1) |>
    ungroup() |>
    select(-.na_count)
}
```

### Samlet feature-testfunktion

Denne funktion sammenligner systematisk en baseline-model med en udvidet model, hvor √©n ekstra variabel tilf√∏jes. Effekten vurderes via modelresum√©, ANOVA og AIC for at sikre konsistente og sammenlignelige beslutninger om feature-inklusion.

```{r}
run_feature_test <- function(df, base_vars, add_var = NULL, label = "TEST", force_int = character()) {
  vars <- base_vars
  if (!is.null(add_var)) vars <- c(vars, add_var)
  
  d <- df |>
    select(all_of(vars)) |>
    drop_na() |>
    mutate(
      s√¶son = as.factor(s√¶son),
      across(any_of(force_int), as.integer)
    )
  
  f_base <- as.formula(paste0("tilskuere ~ ", paste(base_vars[base_vars != "tilskuere"], collapse = " + ")))
  m_base <- lm(f_base, data = d)
  
  if (is.null(add_var)) {
    cat("====================================\n")
    cat(label, "‚Äî SUMMARY\n")
    cat("====================================\n")
    print(summary(m_base))
    cat("\nAIC:\n")
    print(AIC(m_base))
    return(invisible(list(data = d, m_base = m_base, m_full = m_base)))
  }
  
  f_full <- as.formula(paste0("tilskuere ~ ", paste(vars[vars != "tilskuere"], collapse = " + ")))
  m_full <- lm(f_full, data = d)
  
  cat("====================================\n")
  cat(label, "‚Äî SUMMARY\n")
  cat("====================================\n")
  print(summary(m_full))
  
  cat("\n====================================\n")
  cat("ANOVA: BASE vs +", add_var, "\n")
  cat("====================================\n")
  print(anova(m_base, m_full))
  
  cat("\n====================================\n")
  cat("AIC-SAMMENLIGNING\n")
  cat("====================================\n")
  print(AIC(m_base, m_full))
  
  invisible(list(data = d, m_base = m_base, m_full = m_full))
}
```

### Milj√∏- og forbindelsestjek

Denne kode sikrer, at n√∏dvendige milj√∏variabler er sat korrekt og opretter herefter forbindelse til databasen. Dermed stoppes analysen tidligt, hvis foruds√¶tningerne ikke er opfyldt.

```{r}
# =============================================================================
# 2) Safeguard: .Renviron + connection
# =============================================================================
ensure_renviron()
con <- connect_azure_retry()

```

### Indl√¶sning af baseline-datas√¶t

Denne kode indl√¶ser det centrale baseline-datas√¶t med √©n observation pr. kamp.\
Samtidig foretages simple type- og strukturchecks for at sikre datakvalitet.

```{r}
baseline_dir  <- "C:/Users/janpe/OneDrive/Skrivebord/PBA Dataanlyse/01_F√∏rste semester/1 Semester projekt/Baseline"
baseline_file <- file.path(baseline_dir, "baseline_azure.rds")
stopifnot(file.exists(baseline_file))

baseline <- readRDS(baseline_file) |>
  mutate(kamp_id = as.character(kamp_id), kamp_dato = as.Date(kamp_dato))

stopifnot(all(c("kamp_id","kamp_dato","tilskuere") %in% names(baseline)))
cat("Baseline loaded ‚úÖ  R√¶kker:", nrow(baseline), "Unikke kamp_id:", n_distinct(baseline$kamp_id), "\n\n")


```

### Klarg√∏ring af kampstartstid og baseline-kvalitet

Denne kode sikrer, at kampstartstid er tilg√¶ngelig, ensartet formateret og konverteret til numerisk time. Samtidig udf√∏res et kvalitetstjek og deduplikering, s√• baseline ender med √©n entydig r√¶kke pr. kamp.

```{r}
# Hvis kamp_tid mangler: hent fra future_baseline_feature_azure.rds (samme som du g√∏r)
if (!("kamp_tid" %in% names(baseline))) {
  cat("‚ö†Ô∏è baseline_azure.rds har ikke 'kamp_tid'. Henter fra future_baseline_feature_azure.rds...\n")
  feature_baseline_file <- file.path(baseline_dir, "future_baseline_feature_azure.rds")
  stopifnot(file.exists(feature_baseline_file))
  
  fb <- readRDS(feature_baseline_file) |>
    mutate(kamp_id = as.character(kamp_id), kamp_dato = as.Date(kamp_dato)) |>
    arrange(kamp_id) |>
    group_by(kamp_id) |>
    slice(1) |>
    ungroup() |>
    select(kamp_id, kamp_tid)
  
  baseline <- baseline |> left_join(fb, by = "kamp_id")
  cat("‚úî kamp_tid joinet ind (1 r√¶kke pr kamp_id)\n\n")
  rm(fb)
}

baseline <- baseline |>
  mutate(
    kamp_tid_chr = normalize_time_chr(kamp_tid),
    kamp_time_h  = time_chr_to_hour(kamp_tid_chr)
  )

cat("Kamp-r√¶kker uden parsebar kamp_time_h:", sum(is.na(baseline$kamp_time_h)), "\n\n")

cat("\n--- BASELINE QA: DUPLIKAT-TJEK ---\n")
dup_ids <- baseline |> count(kamp_id, sort = TRUE) |> filter(n > 1)
cat("Antal kamp_id med dubletter:", nrow(dup_ids), "\n")

if (nrow(dup_ids) > 0) {
  baseline <- dedup_by_na(baseline, kamp_id)
  stopifnot(nrow(baseline) == n_distinct(baseline$kamp_id))
  cat("‚úÖ Baseline deduplikeret (1 r√¶kke pr kamp_id)\n\n")
} else {
  cat("‚úÖ Ingen dubletter fundet\n\n")
}

baseline_key <- baseline |> transmute(kamp_id, kamp_dato, kamp_time_h)

```

### Features & variabler

#### Helligdage

Denne kode tilf√∏jer en bin√¶r indikator for, om kampen afvikles p√• en helligdag.\
Form√•let er at indfange eventuelle kalender-effekter p√• tilskuertallet.

```{r}
hellig_raw <- safe_dbReadTable(con, "PBA01_Raw", "dim_helligdage_dkk_raw")
stopifnot(all(c("dato","helligdag_navn") %in% names(hellig_raw)))

hellig_min <- hellig_raw |>
  mutate(hellig_dato = as.Date(dato)) |>
  filter(!is.na(hellig_dato)) |>
  group_by(hellig_dato) |>
  summarise(er_helligdag = 1L, .groups = "drop")

baseline <- baseline |>
  left_join(hellig_min, by = c("kamp_dato" = "hellig_dato")) |>
  mutate(er_helligdag = if_else(is.na(er_helligdag), 0L, er_helligdag))

cat("Helligdage joinet ‚úÖ\n\n")

```

#### Samtidige h√•ndboldkampe (SAH)

Denne kode tilf√∏jer information om samtidige h√•ndboldkampe i SAH p√• kampdagen. Form√•let er at modellere potentiel konkurrence om tilskuernes opm√¶rksomhed.

```{r}
sah_raw <- safe_dbReadTable(con, "PBA02_Clean", "fact_h√•ndboldkampe_SAH_clean")
stopifnot(all(c("kamp_dato","kamp_tid","Event") %in% names(sah_raw)))

sah_min <- sah_raw |>
  mutate(sah_dato = as.Date(kamp_dato)) |>
  filter(!is.na(sah_dato)) |>
  group_by(sah_dato) |>
  summarise(
    er_h√•ndboldkamp_SAH = 1L,
    antal_h√•ndboldkampe = n(),
    .groups = "drop"
  )

baseline <- baseline |>
  left_join(sah_min, by = c("kamp_dato" = "sah_dato")) |>
  mutate(
    er_h√•ndboldkamp_SAH = if_else(is.na(er_h√•ndboldkamp_SAH), 0L, er_h√•ndboldkamp_SAH),
    antal_h√•ndboldkampe = if_else(is.na(antal_h√•ndboldkampe), 0L, antal_h√•ndboldkampe)
  )

cat("H√•ndbold SAH joinet ‚úÖ\n\n")

```

#### Befolkning

Denne kode tilf√∏jer kvartalsvise befolkningstal til hver kamp ved at matche med n√¶rmeste tidligere observation. Form√•let er at indfange langsigtede strukturelle √¶ndringer i befolkningsgrundlaget.

```{r}

bef_raw <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_Viborg_befolkning_join_ready")
stopifnot(all(c("k√∏n","civilstand","dato","befolkningstal") %in% names(bef_raw)))

bef_all <- bef_raw |>
  mutate(
    k√∏n = str_to_lower(trimws(as.character(k√∏n))),
    civilstand = str_to_lower(trimws(as.character(civilstand))),
    dato = as.Date(dato),
    befolkningstal = as.numeric(befolkningstal)
  ) |>
  filter(
    !is.na(dato),
    !is.na(befolkningstal),
    k√∏n %in% c("i alt", "alt"),
    civilstand %in% c("i alt", "alt")
  ) |>
  distinct(dato, .keep_all = TRUE) |>
  arrange(dato) |>
  transmute(bef_dato = dato, befolkningstal = befolkningstal)

baseline_bef <- baseline |>
  transmute(kamp_id, kamp_dato) |>
  left_join(bef_all, join_by(closest(kamp_dato >= bef_dato)))

baseline <- baseline |>
  left_join(baseline_bef |> select(kamp_id, befolkningstal), by = "kamp_id")

cat("Befolkning joinet ‚úÖ\n\n")

```

#### Vejrdata (n√¶rmeste observation)

Denne kode matcher hver kamp med den tidsm√¶ssigt n√¶rmeste vejr-observation p√• kampdagen ud fra faste m√•letidspunkter. Form√•let er at tilknytte robuste vejrfeatures og samtidig h√•ndtere manglende eller ufuldst√¶ndige observationer.

```{r}

cat("\n--- FEATURE: VEJR (n√¶rmeste blandt 08/11/14/17) ---\n")

vejr_sql <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_vejr_join_ready")
stopifnot(all(c("obs_dato","tid","vejrkode","vejrbeskrivelse") %in% names(vejr_sql)))

build_weather_match <- function(baseline_key, vejr_sql, grid_hours = c(8L,11L,14L,17L)) {
  vejr_pre <- vejr_sql |>
    mutate(
      vejr_dato = parse_obs_date(obs_dato),
      vejr_tid_chr = normalize_time_chr(tid),
      vejr_time_h = time_chr_to_hour(vejr_tid_chr),
      vejrkode = suppressWarnings(as.integer(vejrkode)),
      vejrbeskrivelse = as.character(vejrbeskrivelse)
    ) |>
    filter(!is.na(vejr_dato), !is.na(vejr_time_h))
  
  vejr_grid <- vejr_pre |>
    filter(vejr_time_h %in% grid_hours) |>
    group_by(vejr_dato, vejr_time_h) |>
    slice(1) |>
    ungroup()
  
  vejr_fallback_1 <- vejr_pre |>
    arrange(vejr_dato, vejr_time_h) |>
    group_by(vejr_dato) |>
    slice(1) |>
    ungroup()
  
  kandidater <- baseline_key |>
    filter(!is.na(kamp_dato), !is.na(kamp_time_h)) |>
    inner_join(vejr_grid |> select(vejr_dato, vejr_time_h, vejrkode, vejrbeskrivelse),
               by = c("kamp_dato" = "vejr_dato")) |>
    mutate(dist_hours_to_kickoff = abs(kamp_time_h - vejr_time_h)) |>
    group_by(kamp_id) |>
    arrange(dist_hours_to_kickoff, .by_group = TRUE) |>
    slice(1) |>
    ungroup() |>
    transmute(
      kamp_id,
      vejr_tid_h = vejr_time_h,
      vejrkode,
      vejrbeskrivelse,
      dist_hours_to_kickoff,
      vejr_match_type = "grid_nearest"
    )
  
  mangler <- baseline_key |> anti_join(kandidater |> select(kamp_id), by = "kamp_id")
  
  fallback <- mangler |>
    left_join(vejr_fallback_1 |> select(vejr_dato, vejr_time_h, vejrkode, vejrbeskrivelse),
              by = c("kamp_dato" = "vejr_dato")) |>
    transmute(
      kamp_id,
      vejr_tid_h = vejr_time_h,
      vejrkode,
      vejrbeskrivelse,
      dist_hours_to_kickoff = NA_integer_,
      vejr_match_type = "fallback_dato"
    )
  
  out <- bind_rows(kandidater, fallback)
  stopifnot(sum(duplicated(out$kamp_id)) == 0)
  out
}
```

#### Sammenkobling af vejrdata

Her kobles de matchede vejrdata p√• baseline-datas√¶ttet.\
Der udskrives samtidig simple diagnosticer for manglende eller ikke-observerbare vejrkoder.

```{r}
vejr_match <- build_weather_match(baseline_key, vejr_sql)

baseline <- baseline |>
  left_join(vejr_match, by = "kamp_id")

cat("Vejr joinet ‚úÖ\n")
cat("Kampe uden vejrkode (NA):", sum(is.na(baseline$vejrkode)), "\n")
cat("Kampe med vejrkode=0:", sum(baseline$vejrkode == 0, na.rm = TRUE), "\n\n")

```

#### Robust h√•ndtering af manglende vejrdata

Denne kode adskiller manglende og ikke-observerbare vejrdata og oms√¶tter dem til konsistente model-features.\
Form√•let er at bevare alle kampe i datas√¶ttet uden at indf√∏re skjult bias fra manglende vejrinformation.

```{r}

baseline <- baseline |>
  mutate(
    vejr_mangler_obs = if_else(is.na(vejrkode), 1L, 0L),
    vejr_ikke_observerbar = if_else(!is.na(vejrkode) & vejrkode == 0, 1L, 0L),
    vejr_mangler_info = if_else(vejr_mangler_obs == 1L | vejr_ikke_observerbar == 1L, 1L, 0L),
    
    vejrkode_model = if_else(vejr_mangler_info == 1L, -1L, as.integer(vejrkode)),
    vejrbeskrivelse_model = case_when(
      vejr_mangler_obs == 1L ~ "UKENDT",
      vejr_ikke_observerbar == 1L ~ "IKKE_OBSERVERBAR",
      TRUE ~ as.character(vejrbeskrivelse)
    ),
    vejr_tid_h_model = if_else(vejr_mangler_info == 1L, -1L, as.integer(vejr_tid_h)),
    dist_hours_to_kickoff_model = if_else(vejr_mangler_info == 1L, -1L, as.integer(dist_hours_to_kickoff)),
    vejr_match_type_model = if_else(is.na(vejr_match_type), "NO_WEATHER", as.character(vejr_match_type))
  )

cat("--- VEJR H√ÖNDTERING ---\n")
cat("vejr_mangler_obs (NA):", sum(baseline$vejr_mangler_obs == 1L, na.rm = TRUE), "\n")
cat("vejr_ikke_observerbar (kode=0):", sum(baseline$vejr_ikke_observerbar == 1L, na.rm = TRUE), "\n")
cat("vejr_mangler_info (NA eller 0):", sum(baseline$vejr_mangler_info == 1L, na.rm = TRUE), "\n\n")
```

#### Temperatur f√∏r kamp

Denne kode matcher hver kamp med den senest observerede temperatur f√∏r kickoff via en bagudg√•ende tidslogik. Form√•let er at knytte en realistisk og konsistent temperaturfeature til kampafviklingen.

```{r}
cat("\n--- FEATURE: TEMPERATUR (bagud-trappe 18‚Üí15‚Üí12‚Üí09) ---\n")

temp_sql <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_temperatur_join_ready")
stopifnot(all(c("obs_dato","tid","temperatur") %in% names(temp_sql)))

build_temp_match <- function(baseline_key, temp_sql, hours = c(9L,12L,15L,18L)) {
  temp_grid <- temp_sql |>
    mutate(
      temp_dato = parse_obs_date(obs_dato),
      temp_tid_chr = normalize_time_chr(tid),
      temp_time_h = time_chr_to_hour(temp_tid_chr),
      temperatur = suppressWarnings(as.numeric(temperatur))
    ) |>
    filter(!is.na(temp_dato), !is.na(temp_time_h), temp_time_h %in% hours) |>
    group_by(temp_dato, temp_time_h) |>
    slice(1) |>
    ungroup()
  
  kandidater <- baseline_key |>
    inner_join(temp_grid |> select(temp_dato, temp_time_h, temperatur),
               by = c("kamp_dato" = "temp_dato")) |>
    filter(!is.na(kamp_time_h), temp_time_h <= kamp_time_h) |>
    mutate(temp_dist_hours_to_kickoff = kamp_time_h - temp_time_h)
  
  valgt <- kandidater |>
    group_by(kamp_id) |>
    arrange(desc(temp_time_h), .by_group = TRUE) |>
    slice(1) |>
    ungroup() |>
    transmute(
      kamp_id,
      temp_tid_h = temp_time_h,
      temperatur,
      temp_dist_hours_to_kickoff = as.integer(temp_dist_hours_to_kickoff),
      temp_match_type = "step_back_same_day"
    )
  
  mangler <- baseline_key |>
    anti_join(valgt |> select(kamp_id), by = "kamp_id") |>
    transmute(
      kamp_id,
      temp_tid_h = NA_integer_,
      temperatur = NA_real_,
      temp_dist_hours_to_kickoff = NA_integer_,
      temp_match_type = case_when(
        is.na(kamp_time_h) ~ "NO_KICKOFF_TIME",
        TRUE               ~ "NO_TEMP_BEFORE_KICKOFF"
      )
    )
  
  out <- bind_rows(valgt, mangler)
  stopifnot(sum(duplicated(out$kamp_id)) == 0)
  out
}
```

#### Sammenkobling og h√•ndtering af temperaturdata

Her kobles de matchede temperaturdata p√• baseline og oms√¶ttes til modelklare features. Der udskrives samtidig diagnostik for manglende temperaturobservationer og match-typer.

```{r}
temp_match <- build_temp_match(baseline_key, temp_sql)

baseline <- baseline |>
  left_join(temp_match, by = "kamp_id") |>
  mutate(
    temp_mangler_obs = if_else(is.na(temperatur), 1L, 0L),
    temperatur_model = as.numeric(temperatur),
    temp_tid_h_model = as.integer(temp_tid_h),
    temp_dist_hours_to_kickoff_model = as.integer(temp_dist_hours_to_kickoff),
    temp_match_type_model = if_else(is.na(temp_match_type), "NO_TEMP", as.character(temp_match_type))
  )

cat("Temperatur joinet ‚úÖ\n")
cat("step_back_same_day:", sum(baseline$temp_match_type == "step_back_same_day", na.rm = TRUE), "\n")
cat("NO_KICKOFF_TIME:", sum(baseline$temp_match_type == "NO_KICKOFF_TIME", na.rm = TRUE), "\n")
cat("NO_TEMP_BEFORE_KICKOFF:", sum(baseline$temp_match_type == "NO_TEMP_BEFORE_KICKOFF", na.rm = TRUE), "\n")
cat("NA temperatur i alt:", sum(is.na(baseline$temperatur)), "\n\n")

```

#### Billetsalg og v√¶kstfeatures

Denne sektion konstruerer centrale billetsalgsfeatures til D7-modellen, herunder solgte billetter 7 dage f√∏r kamp samt v√¶kst i billetsalg fra dag 10 til dag 7. Form√•let er at indfange den kortsigtede eftersp√∏rgsel t√¶t p√• kampdatoen i et konsistent og modelklart format.

```{r}
vff_billetsalg <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_VFF_Billetsalg_join_ready") |>
  mutate(
    kamp_id       = as.character(kamp_id),
    d10_tilskuere = as.numeric(d10_tilskuere),
    d7_tilskuere  = as.numeric(d7_tilskuere)
  )
stopifnot(all(c("kamp_id","d10_tilskuere","d7_tilskuere") %in% names(vff_billetsalg)))
cat("Billetsalg hentet ‚úÖ  R√¶kker:", nrow(vff_billetsalg), "\n\n")

```

#### Konstruktion af D7-billetsalgsfeatures

Denne kode aggregerer billetsalgsdata til √©n observation pr. kamp og konstruerer centrale D7-features. De afledte variable kobles herefter p√• baseline-datas√¶ttet og danner grundlag for den videre analyse.

```{r}

vff_billetsalg_1row <- vff_billetsalg |>
  group_by(kamp_id) |>
  summarise(
    d10_tilskuere = max(d10_tilskuere, na.rm = TRUE),
    d7_tilskuere  = max(d7_tilskuere,  na.rm = TRUE),
    .groups = "drop"
  ) |>
  mutate(
    d10_tilskuere = if_else(is.infinite(d10_tilskuere), NA_real_, d10_tilskuere),
    d7_tilskuere  = if_else(is.infinite(d7_tilskuere),  NA_real_, d7_tilskuere)
  )

tickets_feats_d7 <- vff_billetsalg_1row |>
  mutate(
    billetter_d7 = d7_tilskuere,
    v√¶kst_d10_d7 = pmax(d7_tilskuere - d10_tilskuere, 0)
  ) |>
  select(kamp_id, billetter_d7, d10_tilskuere, d7_tilskuere, v√¶kst_d10_d7)

d7_dataset <- baseline |> left_join(tickets_feats_d7, by = "kamp_id")
cat("Join gennemf√∏rt ‚úÖ  R√¶kker:", nrow(d7_dataset),
    "Unikke kamp_id:", n_distinct(d7_dataset$kamp_id), "\n\n")


```

### Diagnostik og datakvalitetstjek

Denne kode opsummerer datakvaliteten i D7-datas√¶ttet efter alle joins.\
Form√•let er at give et hurtigt overblik over datatab, manglende observationer og kvaliteten af feature-matchene.

```{r}
diag <- d7_dataset |>
  summarise(
    r√¶kker_total = n(),
    unikke_kamp_id = n_distinct(kamp_id),
    uden_d7  = sum(is.na(billetter_d7)),
    uden_bef = sum(is.na(befolkningstal)),
    uden_vejrkode_raw = sum(is.na(vejrkode)),
    vejrkode0_raw     = sum(vejrkode == 0, na.rm = TRUE),
    uden_temp_raw     = sum(is.na(temperatur)),
    vejr_mangler_obs_total = sum(vejr_mangler_obs == 1L, na.rm = TRUE),
    temp_mangler_obs_total = sum(temp_mangler_obs == 1L, na.rm = TRUE),
    vejr_grid_match = sum(vejr_match_type == "grid_nearest", na.rm = TRUE),
    vejr_fallback   = sum(vejr_match_type == "fallback_dato", na.rm = TRUE),
    temp_stepback   = sum(temp_match_type == "step_back_same_day", na.rm = TRUE),
    temp_nomatch    = sum(temp_match_type == "NO_TEMP_BEFORE_KICKOFF", na.rm = TRUE)
  )
print(diag)

```

### Endeligt D7-analysedatas√¶t

Denne kode filtrerer datas√¶ttet til kampe med komplette billetsalgsfeatures og f√¶rdigg√∏r kodningen af modelvariable.\
Resultatet er et konsistent og modelklart D7-datas√¶t, som anvendes i de efterf√∏lgende modeltests.

```{r}

analysis_df_d7 <- d7_dataset |>
  filter(!is.na(billetter_d7), !is.na(v√¶kst_d10_d7)) |>
  mutate(
    vejrkode_model = if_else(is.na(vejrkode_model), -1L, vejrkode_model),
    vejrbeskrivelse_model = if_else(is.na(vejrbeskrivelse_model), "UKENDT", vejrbeskrivelse_model),
    vejr_tid_h_model = if_else(is.na(vejr_tid_h_model), -1L, vejr_tid_h_model),
    dist_hours_to_kickoff_model = if_else(is.na(dist_hours_to_kickoff_model), -1L, dist_hours_to_kickoff_model),
    vejr_match_type_model = if_else(is.na(vejr_match_type_model), "NO_WEATHER", vejr_match_type_model),
    temperatur_model = as.numeric(temperatur_model),
    temp_tid_h_model = as.integer(temp_tid_h_model),
    temp_dist_hours_to_kickoff_model = as.integer(temp_dist_hours_to_kickoff_model),
    temp_match_type_model = if_else(is.na(temp_match_type_model), "NO_TEMP", as.character(temp_match_type_model))
  )

cat("Analyse-datas√¶t (D7) klar ‚úÖ  R√¶kker:", nrow(analysis_df_d7), "\n\n")

```

### Ops√¶tning af baseline til modeltests

Her defineres de faste baseline-variable, som anvendes i alle efterf√∏lgende modeltests.\
Det sikrer, at effekten af nye features vurderes konsistent mod samme reference-model.

```{r}

base_vars <- c("tilskuere","s√¶son","runde","kamp_time_h","billetter_d7","v√¶kst_d10_d7")

```

### Nulmodel (baseline)

Her estimeres nulmodellen uden ekstra forklaringsvariable.\
Den fungerer som reference for vurdering af alle efterf√∏lgende feature-udvidelser.

```{r}
# NULMODEL
m0 <- run_feature_test(
  df = analysis_df_d7,
  base_vars = base_vars,
  add_var = NULL,
  label = "MODEL_D7_00 ‚Äî NULMODEL"
)
```

Nulmodellen viser, at billetter_d7 er den klart vigtigste forklaringsvariabel og har en st√¶rk, signifikant positiv effekt p√• tilskuertallet, mens v√¶kst_d10_d7 er signifikant med negativ koefficient og indikerer aftagende marginaleffekt t√¶t p√• kampdatoen. Modellens AIC p√• 3631,5 anvendes som reference for vurdering af, om efterf√∏lgende feature-udvidelser forbedrer modelkvaliteten.

#### Feature-test: Helligdag

Denne test vurderer, om kampe p√• helligdage har en selvst√¶ndig effekt p√• tilskuertallet. Effekten sammenlignes direkte med nulmodellen.

```{r}
# + Helligdag
run_feature_test(
  df = analysis_df_d7,
  base_vars = base_vars,
  add_var = "er_helligdag",
  label = "MODEL_D7_01 ‚Äî + HELLIGDAG",
  force_int = c("er_helligdag")
)


```

Helligdagsvariablen har ingen signifikant effekt p√• tilskuertallet (p = 0,66), og ANOVA-testen viser, at modellen ikke forbedres ved inkludering af er_helligdag. AIC forv√¶rres i forhold til nulmodellen, hvilket indikerer, at variablen ikke bidrager med yderligere forklaringskraft og derfor forkastes i den videre modellering.

#### Feature-test: Samtidig h√•ndboldkamp (SAH)

Denne test unders√∏ger, om samtidige h√•ndboldkampe p√•virker tilskuertallet til fodboldkampene. Resultatet vurderes relativt til nulmodellen.

```{r}
# + H√•ndbold SAH
run_feature_test(
  df = analysis_df_d7,
  base_vars = base_vars,
  add_var = "er_h√•ndboldkamp_SAH",
  label = "MODEL_D7_02 ‚Äî + H√ÖNDBOLD SAH",
  force_int = c("er_h√•ndboldkamp_SAH")
)

```

Variablen er_h√•ndboldkamp_SAH har en positiv koefficient, men er kun svagt signifikant p√• 10 %-niveauet (p ‚âà 0,097) og er ikke robust ved 5 %-niveauet. ANOVA-testen viser ingen klar forbedring i forhold til nulmodellen, og AIC forbedres ikke tilstr√¶kkeligt til at retf√¶rdigg√∏re variablen. P√• den baggrund vurderes effekten som usikker, og variablen frav√¶lges i den endelige model.

#### Feature-test: Temperatur (fair sammenligning)

Her testes temperaturens betydning p√• et f√¶lles datas√¶t uden manglende observationer. Det sikrer, at effekten vurderes uafh√¶ngigt af datatab.

```{r}
# + Temperatur (fair test: common dataset, som du gjorde)
# + Temperatur (fair test: common dataset, som du gjorde)
df_temp_common <- analysis_df_d7 |>
  select(all_of(c(base_vars, "temperatur_model"))) |>
  drop_na()

run_feature_test(
  df = df_temp_common,
  base_vars = base_vars,
  add_var = "temperatur_model",
  label = "MODEL_D7_03 ‚Äî + TEMPERATUR (common)"
)
```

Temperaturvariablen har ingen signifikant effekt p√• tilskuertallet (p ‚âà 0,88), og ANOVA-testen viser, at modellen ikke forbedres ved at inkludere temperatur_model p√• et f√¶lles datas√¶t. AIC forbedres ikke i forhold til baselinemodellen, hvilket indikerer, at temperatur ikke bidrager med yderligere forklaringskraft i D7-setup og derfor frav√¶lges i den videre modellering.

```{r}
# + vejr_mangler_info
run_feature_test(
  df = analysis_df_d7,
  base_vars = base_vars,
  add_var = "vejr_mangler_info",
  label = "MODEL_D7_04 ‚Äî + VEJR_MANGLER_INFO",
  force_int = c("vejr_mangler_info")
)

```

Variablen vejr_mangler_info har ingen signifikant effekt p√• tilskuertallet (p ‚âà 0,44), og ANOVA-testen viser, at modellen ikke forbedres ved at inkludere indikatoren for manglende vejrinformation. AIC forbedres ikke i forhold til baselinemodellen, hvilket indikerer, at frav√¶r af vejrdata ikke har systematisk betydning for tilskuertallet i D7-setup og derfor ikke bidrager med yderligere forklaringskraft.

#### Feature-test: Placering f√∏r kamp

Denne sektion tilf√∏jer og tester VFF‚Äôs placering f√∏r kamp som forklaringsvariabel.\
Placeringerne renses og reduceres til √©n entydig observation pr. kamp, hvorefter effekten vurderes p√• et komplet datas√¶t for at sikre en fair sammenligning med baseline-modellen.

```{r}


cat("\n--- Henter VFF rundeplaceringer (CLEAN) ---\n")

plac_raw <- safe_dbReadTable(con, "PBA02_Clean", "fact_vff_rundeplaceringer_clean") |>
  mutate(kamp_id = as.character(kamp_id))

need_cols <- c("kamp_id", "placering_f√∏r_kamp")
missing <- setdiff(need_cols, names(plac_raw))
if (length(missing) > 0) {
  cat("‚ö†Ô∏è Mangler kolonner i placeringstabellen: ", paste(missing, collapse = ", "), "\n")
  cat("Kolonner i tabellen er:\n")
  print(names(plac_raw))
  stop("Stopper s√• du kan se mismatch.")
}

plac_1row <- plac_raw |>
  select(kamp_id, placering_f√∏r_kamp) |>
  mutate(
    kamp_id = as.character(kamp_id),
    placering_f√∏r_kamp = suppressWarnings(as.integer(placering_f√∏r_kamp))
  ) |>
  arrange(kamp_id) |>
  group_by(kamp_id) |>
  slice(1) |>
  ungroup()

stopifnot(sum(duplicated(plac_1row$kamp_id)) == 0)

cat("Placeringstabel klar ‚úÖ  R√¶kker:", nrow(plac_1row),
    "Unikke kamp_id:", n_distinct(plac_1row$kamp_id), "\n\n")

# Byg datas√¶t til placeringstest (kun komplette r√¶kker)
df_pos <- analysis_df_d7 |>
  mutate(kamp_id = as.character(kamp_id)) |>
  left_join(plac_1row, by = "kamp_id") |>
  transmute(
    tilskuere = as.numeric(tilskuere),
    s√¶son = as.factor(s√¶son),
    runde = as.integer(runde),
    kamp_time_h = as.integer(kamp_time_h),
    billetter_d7 = as.numeric(billetter_d7),
    v√¶kst_d10_d7 = as.numeric(v√¶kst_d10_d7),
    placering_f√∏r_kamp = as.integer(placering_f√∏r_kamp)
  ) |>
  filter(if_all(everything(), ~ !is.na(.)))

cat("df_pos klar ‚úÖ  R√¶kker:", nrow(df_pos), "\n")
cat("Placering NA efter join (f√∏r filter):",
    sum(is.na((analysis_df_d7 |>
                 mutate(kamp_id = as.character(kamp_id)) |>
                 left_join(plac_1row, by = "kamp_id"))$placering_f√∏r_kamp)),
    "\n\n")

# K√∏r feature-test p√• placering
base_vars_pos <- c("tilskuere","s√¶son","runde","kamp_time_h","billetter_d7","v√¶kst_d10_d7")

run_feature_test(
  df = df_pos,
  base_vars = base_vars_pos,
  add_var = "placering_f√∏r_kamp",
  label = "MODEL_D7_05 ‚Äî + PLACERING_F√òR_KAMP",
  force_int = c("runde","kamp_time_h","placering_f√∏r_kamp")
)
```

Placering_f√∏r_kamp har ingen signifikant effekt p√• tilskuertallet (p ‚âà 0,90), og ANOVA-testen viser, at modellen ikke forbedres ved inkludering af variablen. AIC √¶ndres ikke i forhold til baselinemodellen, hvilket indikerer, at liga¬≠placeringen f√∏r kamp ikke tilf√∏rer selvst√¶ndig forklaringskraft, n√•r der allerede kontrolleres for billetsalg t√¶t p√• kampdatoen. Resultatet peger p√•, at information om holdets sportslige position i h√∏j grad allerede er indlejret i billetsalgsvariablerne, og at placering derfor ikke bidrager yderligere i D7-setup.

#### Feature-test: Befolkning (fair test og omkostning)

Denne sektion tester befolkningstal som forklaringsvariabel ved at sammenligne modeller med og uden befolkning p√• et f√¶lles datas√¶t.\
Dermed vurderes b√•de den statistiske effekt og omkostningen i form af reduceret datagrundlag, f√∏r variablen eventuelt inkluderes.

```{r}
# =============================================================================
# 12) TEST: Befolkning (fair test + omkostning) ‚Äî FIX
# =============================================================================
set.seed(42)
test_prop <- 0.20

# Baseline datas√¶t (uden befolkning) ‚Äî kun komplette r√¶kker
df_d7_full <- analysis_df_d7 |>
  transmute(
    tilskuere     = as.numeric(tilskuere),
    s√¶son         = as.factor(s√¶son),
    runde         = as.integer(runde),
    kamp_time_h   = as.integer(kamp_time_h),
    billetter_d7  = as.numeric(billetter_d7),
    v√¶kst_d10_d7  = as.numeric(v√¶kst_d10_d7)
  ) |>
  filter(if_all(everything(), ~ !is.na(.)))

cat("df_d7_full (uden befolkning) ‚úÖ  R√¶kker:", nrow(df_d7_full), "\n")

# Fair test: f√¶lles datas√¶t (samme r√¶kker) n√•r vi sammenligner med befolkning
df_d7_bef_common <- analysis_df_d7 |>
  transmute(
    tilskuere     = as.numeric(tilskuere),
    s√¶son         = as.factor(s√¶son),
    runde         = as.integer(runde),
    kamp_time_h   = as.integer(kamp_time_h),
    billetter_d7  = as.numeric(billetter_d7),
    v√¶kst_d10_d7  = as.numeric(v√¶kst_d10_d7),
    befolkningstal = as.numeric(befolkningstal)
  ) |>
  filter(if_all(everything(), ~ !is.na(.)))

cat("df_d7_bef_common (med befolkning) ‚úÖ  R√¶kker:", nrow(df_d7_bef_common),
    " (tabt pga NA befolkning:", nrow(df_d7_full) - nrow(df_d7_bef_common), ")\n\n")

# Modeltest: uden befolkning vs + befolkning (samme r√¶kker)
base_vars_bef <- c("tilskuere","s√¶son","runde","kamp_time_h","billetter_d7","v√¶kst_d10_d7")

run_feature_test(
  df = df_d7_bef_common,
  base_vars = base_vars_bef,
  add_var = NULL,
  label = "MODEL_D7_06A ‚Äî BASE (common for befolkning)"
)

run_feature_test(
  df = df_d7_bef_common,
  base_vars = base_vars_bef,
  add_var = "befolkningstal",
  label = "MODEL_D7_06B ‚Äî + BEFOLKNING (common)"
)

# (Valgfrit) split til senere out-of-sample test (samme common datas√¶t)
split_obj <- rsample::initial_split(df_d7_bef_common, prop = 1 - test_prop)
train_df  <- rsample::training(split_obj)
test_df   <- rsample::testing(split_obj)

cat("Train r√¶kker:", nrow(train_df), " Test r√¶kker:", nrow(test_df), "\n")

```

Befolkningstallet testes p√• et f√¶lles datas√¶t for at sikre en fair sammenligning, men dette medf√∏rer et markant datatab, idet antallet af observationer reduceres fra 254 til 131 p√• grund af manglende befolkningsdata. P√• dette reducerede datas√¶t viser befolkningstal ingen signifikant effekt p√• tilskuertallet (p ‚âà 0,26), og ANOVA-testen indikerer, at modellen ikke forbedres ved at inkludere variablen. AIC forbedres ikke i forhold til baselinemodellen, og den marginale √¶ndring i forklaringsgrad er ubetydelig. Samlet set vurderes omkostningen i form af halveret datagrundlag at overstige den potentielle gevinst, hvorfor befolkningstal frav√¶lges i den endelige D7-model.

#### Samlet oversigt over variabeltests

Denne tabel sammenfatter resultaterne af alle gennemf√∏rte feature-tests i D7-analysen. Den giver et samlet beslutningsgrundlag for, hvilke variable der fastholdes i den endelige model, baseret p√• statistisk evidens, AIC og datam√¶ssige omkostninger.

```{r}

# =============================================================================
# 13) Samlet variabeltest-oversigt (u√¶ndret)
# =============================================================================
variabeltest_oversigt_d7 <- tibble::tibble(
  variabel = c(
    "placering_f√∏r_kamp",
    "billetter_d7",
    "v√¶kst_d10_d7",
    "s√¶son",
    "runde",
    "kamp_time_h",
    "er_helligdag",
    "er_h√•ndboldkamp_SAH",
    "temperatur_model",
    "vejr_mangler_info",
    "befolkningstal"
  ),
  n_test = c(
    249,
    254, 254,
    254, 254, 254,
    254, 254,
    253, 254,
    131
  ),
  p_koefficient = c(
    0.9032,
    NA, NA,
    NA, NA, NA,
    0.656,
    0.097,
    0.8824,
    0.437,
    0.577
  ),
  p_anova = c(
    0.9032,
    NA, NA,
    NA, NA, NA,
    0.656,
    0.097,
    0.8824,
    0.437,
    0.577
  ),
  delta_AIC = c(
    +1.984,
    NA, NA,
    NA, NA, NA,
    +1.62,
    -1.02,
    +1.88,
    +1.10,
    +1.64
  ),
  beslutning = c(
    "Forkastet",
    "Fast baseline-feature",
    "Fast baseline-feature",
    "Fast baseline-feature",
    "Fast baseline-feature",
    "Fast baseline-feature",
    "Forkastet",
    "Forkastet",
    "Forkastet",
    "Forkastet",
    "Forkastet (cost > benefit)"
  ),
  begrundelse = c(
    "Ingen signifikant effekt (p‚âà0.90) og forv√¶rrer AIC",
    "Prim√¶r forklaringsvariabel 7 dage f√∏r kamp",
    "St√¶rk v√¶kstindikator t√¶t p√• kamp",
    "Kontrollerer for strukturelle s√¶sonforskelle",
    "Kampkontekst",
    "Tidsm√¶ssig eftersp√∏rgselseffekt",
    "Ingen signifikant effekt (p>0.6)",
    "Svag evidens (10%-niveau), ikke robust",
    "Ingen effekt og forv√¶rrer AIC",
    "Manglende vejrinfo er ikke systematisk",
    "Ingen signifikant effekt og halverer datas√¶ttet"
  )
)
print(variabeltest_oversigt_d7)
```

#### Endelig D7-model: tidssplit og model¬≠sammenligning

Denne sektion bygger den endelige D7-model ved hj√¶lp af et tidssplit, hvor tidlige kampe anvendes til tr√¶ning og de seneste til test. OLS-, Ridge- og Lasso-modeller sammenlignes p√• identiske features, og resultaterne opsummeres via performance-m√•l, standardplots og artefakter til videre brug i rapport og produktlag.

```{r}
stopifnot(all(c(
  "kamp_id","kamp_dato","tilskuere","s√¶son","runde","kamp_time_h","billetter_d7","v√¶kst_d10_d7"
) %in% names(analysis_df_d7)))

```

#### Hj√¶lpere til ligningsformidling (OLS)

Disse funktioner formatterer modelkoefficienter til l√¶sbare ligninger og s√∏rger for p√¶n linjeombrydning. Form√•let er at g√∏re OLS-modellens resultat let forst√•eligt i plots og rapportering.

```{r}
wrap_text <- function(s, width = 85) {
  paste(strwrap(as.character(s), width = width), collapse = "\n")
}

build_lm_equation_text <- function(lm_model, y_name = "tilskuere", yhat_name = "≈∑") {
  cf <- stats::coef(lm_model)
  cf <- cf[!is.na(cf)]
  nm <- names(cf)
  
  intercept <- unname(cf[1])
  terms <- nm[-1]
  betas <- unname(cf[-1])
  
  # p√¶n formatering (3 decimaler)
  fmt <- function(x) formatC(x, format = "f", digits = 3)
  
  rhs <- paste0(fmt(intercept))
  if (length(terms) > 0) {
    for (i in seq_along(terms)) {
      b <- betas[i]
      sign_txt <- if (b >= 0) " + " else " ‚àí "
      rhs <- paste0(rhs, sign_txt, fmt(abs(b)), "¬∑", terms[i])
    }
  }
  
  paste0(yhat_name, " = ", rhs, "    (OLS)")
}

```

#### Hj√¶lpere til ligningsformidling (Ridge/Lasso)

Disse funktioner oms√¶tter glmnet-modeller til l√¶sbare ligninger baseret p√• Œª‚Çò·µ¢‚Çô og inds√¶tter dem direkte i plots. Form√•let er at sikre konsistent og sammenlignelig formidling af Ridge- og Lasso-resultater.

```{r}

build_glmnet_equation_text <- function(cv_model, x_names, model_label = "GLMNET", yhat_name = "≈∑") {
  # coef() returnerer en dgCMatrix med (Intercept) + koef for hver feature
  b <- as.matrix(stats::coef(cv_model, s = "lambda.min"))
  b <- as.numeric(b)
  names(b) <- rownames(as.matrix(stats::coef(cv_model, s = "lambda.min")))
  
  # intercept
  intercept <- b[1]
  beta <- b[-1]
  names(beta) <- names(b)[-1]
  
  # s√∏rg for at r√¶kkef√∏lge matcher X-kolonner (model.matrix)
  beta <- beta[x_names]
  
  fmt <- function(x) formatC(x, format = "f", digits = 3)
  
  rhs <- paste0(fmt(intercept))
  if (length(beta) > 0) {
    for (i in seq_along(beta)) {
      bi <- beta[i]
      sign_txt <- if (bi >= 0) " + " else " ‚àí "
      rhs <- paste0(rhs, sign_txt, fmt(abs(bi)), "¬∑", names(beta)[i])
    }
  }
  
  paste0(yhat_name, " = ", rhs, "    (", model_label, ", Œª‚Çò·µ¢‚Çô)")
}

add_eq_to_plot <- function(p, eq_text, size = 3) {
  p + ggplot2::annotate(
    "text",
    x = -Inf, y = Inf,
    label = wrap_text(eq_text, width = 85),
    hjust = -0.05, vjust = 1.1,
    size = size
  )
}

```

```{r}
#  Klarg√∏r modelling-datas√¶t (√©n r√¶kke pr kamp) ---
df_d7_final <- analysis_df_d7 |>
  dplyr::transmute(
    kamp_id      = as.character(kamp_id),
    kamp_dato    = as.Date(kamp_dato),
    tilskuere    = as.numeric(tilskuere),
    s√¶son_chr    = as.character(s√¶son),
    s√¶son_start  = season_start_year(s√¶son_chr),
    runde        = as.integer(runde),
    kamp_time_h  = as.integer(kamp_time_h),
    billetter_d7 = as.numeric(billetter_d7),
    v√¶kst_d10_d7 = as.numeric(v√¶kst_d10_d7)
  ) |>
  dplyr::filter(dplyr::if_all(dplyr::everything(), ~ !is.na(.))) |>
  dplyr::arrange(kamp_dato)

cat("df_d7_final klar ‚úÖ  R√¶kker:", nrow(df_d7_final),
    "Periode:", as.character(min(df_d7_final$kamp_dato)), "‚Üí", as.character(max(df_d7_final$kamp_dato)), "\n")
cat("Antal unikke s√¶soner:", dplyr::n_distinct(df_d7_final$s√¶son_chr), "\n\n")

```

#### Tidssplit til modelvalidering

Her opdeles datas√¶ttet tidsm√¶ssigt, s√• de seneste kampe anvendes som testdata.\
Det sikrer en realistisk evaluering af modellernes pr√¶diktive evne.

```{r}

# Tidssplit (seneste 20% som test) ---
set.seed(42)
test_prop <- 0.20

n_total <- nrow(df_d7_final)
n_test  <- max(1, floor(n_total * test_prop))
cut_idx <- n_total - n_test

train_d7 <- df_d7_final[1:cut_idx, ]
test_d7  <- df_d7_final[(cut_idx + 1):n_total, ]

cat("Tidssplit klar ‚úÖ\n")
cat("Train:", nrow(train_d7), " Test:", nrow(test_d7), "\n")
cat("Test-periode starter:", as.character(min(test_d7$kamp_dato)), "\n\n")

```

#### Endelig OLS-model og testperformance

Her estimeres den endelige OLS-model p√• tr√¶ningsdata og evalueres p√• testdatas√¶ttet. Modelkvaliteten rapporteres ved RMSE, MAE og R¬≤ for en samlet vurdering af pr√¶cisionen.

```{r}
m_d7_final_lm <- lm(
  tilskuere ~ s√¶son_start + runde + kamp_time_h + billetter_d7 + v√¶kst_d10_d7,
  data = train_d7
)

pred_lm <- as.numeric(predict(m_d7_final_lm, newdata = test_d7))

rmse_lm <- rmse_vec(test_d7$tilskuere, pred_lm)
mae_lm  <- mae_vec(test_d7$tilskuere, pred_lm)
r2_lm   <- r2_vec(test_d7$tilskuere, pred_lm)

cat("====================================\n")
cat("D7 FINAL OLS ‚Äî TEST METRICS\n")
cat("====================================\n")
cat("RMSE:", rmse_lm, " MAE:", mae_lm, " R2:", r2_lm, "\n\n")
```

Den endelige D7 OLS-model opn√•r en RMSE p√• cirka 378 og en MAE p√• cirka 312, hvilket indikerer en relativt stabil pr√¶diktiv pr√¶cision p√• testdatas√¶ttet. Med en R¬≤ p√• omkring 0,89 forklarer modellen st√∏rstedelen af variationen i tilskuertallet og vurderes som velegnet til operationel anvendelse syv dage f√∏r kampstart. Men vi kigger ogs√• p√• mere avancerede modeller.

### Designmatricer til Ridge og Lasso

Denne kode opbygger modelmatricer for tr√¶nings- og testdata, som kr√¶ves af glmnet. Det sikrer, at Ridge- og Lasso-modeller estimeres p√• samme features som OLS-modellen.

```{r}
x_train <- model.matrix(
  tilskuere ~ s√¶son_start + runde + kamp_time_h + billetter_d7 + v√¶kst_d10_d7,
  data = train_d7
)[, -1, drop = FALSE]
y_train <- train_d7$tilskuere

x_test <- model.matrix(
  tilskuere ~ s√¶son_start + runde + kamp_time_h + billetter_d7 + v√¶kst_d10_d7,
  data = test_d7
)[, -1, drop = FALSE]
y_test <- test_d7$tilskuere

x_names <- colnames(x_train)

```

#### Ridge-model og testperformance

Her estimeres en Ridge-model med krydsvalidering og evalueres p√• testdatas√¶ttet. Resultaterne rapporteres via RMSE, MAE og R¬≤ sammen med det optimale Œª.

```{r}

# 14.5) Ridge (alpha = 0)

set.seed(42)
cv_ridge <- glmnet::cv.glmnet(
  x = x_train, y = y_train,
  alpha = 0,
  nfolds = 10,
  standardize = TRUE
)

lambda_ridge <- cv_ridge$lambda.min
pred_ridge <- as.numeric(predict(cv_ridge, newx = x_test, s = "lambda.min"))

rmse_ridge <- rmse_vec(y_test, pred_ridge)
mae_ridge  <- mae_vec(y_test, pred_ridge)
r2_ridge   <- r2_vec(y_test, pred_ridge)

cat("====================================\n")
cat("D7 RIDGE ‚Äî TEST METRICS\n")
cat("====================================\n")
cat("lambda.min:", lambda_ridge, "\n")
cat("RMSE:", rmse_ridge, " MAE:", mae_ridge, " R2:", r2_ridge, "\n\n")

```

Ridge-modellen opn√•r en RMSE p√• cirka 540 og en MAE p√• cirka 423, hvilket er markant d√•rligere end OLS-modellen p√• testdatas√¶ttet. Med en R¬≤ p√• omkring 0,78 forklarer modellen v√¶sentligt mindre af variationen i tilskuertallet, og regulariseringen reducerer her modellens pr√¶cision uden at give en bedre generalisering. Ridge vurderes derfor ikke som konkurrencedygtig i D7-setup.

#### Lasso-model og testperformance

Denne kode estimerer en Lasso-model med krydsvalidering og evaluerer den p√• testdatas√¶ttet.\
Resultaterne sammenlignes direkte med OLS- og Ridge-modellerne.

```{r}

# 14.6) Lasso (alpha = 1)

set.seed(42)
cv_lasso <- glmnet::cv.glmnet(
  x = x_train, y = y_train,
  alpha = 1,
  nfolds = 10,
  standardize = TRUE
)

lambda_lasso <- cv_lasso$lambda.min
pred_lasso <- as.numeric(predict(cv_lasso, newx = x_test, s = "lambda.min"))

rmse_lasso <- rmse_vec(y_test, pred_lasso)
mae_lasso  <- mae_vec(y_test, pred_lasso)
r2_lasso   <- r2_vec(y_test, pred_lasso)

cat("====================================\n")
cat("D7 LASSO ‚Äî TEST METRICS\n")
cat("====================================\n")
cat("lambda.min:", lambda_lasso, "\n")
cat("RMSE:", rmse_lasso, " MAE:", mae_lasso, " R2:", r2_lasso, "\n\n")
```

```{r}

# Samlet performance-tabel 

perf_d7 <- tibble::tibble(
  model = c("OLS (lm)", "Ridge (cv.glmnet)", "Lasso (cv.glmnet)"),
  RMSE  = c(rmse_lm, rmse_ridge, rmse_lasso),
  MAE   = c(mae_lm,  mae_ridge,  mae_lasso),
  R2    = c(r2_lm,   r2_ridge,   r2_lasso)
)

cat("====================================\n")
cat("D7 ‚Äî SAMLET TEST PERFORMANCE\n")
cat("====================================\n")
print(perf_d7)
cat("\n")

```

Sammenligningen viser, at OLS-modellen opn√•r den laveste RMSE og dermed den bedste samlede pr√¶diktive pr√¶cision p√• testdatas√¶ttet. Lasso ligger meget t√¶t p√• OLS med n√¶sten identiske MAE- og R¬≤-v√¶rdier, men uden en reel forbedring i performance. Ridge klarer sig markant d√•rligere p√• alle m√•l. P√• den baggrund v√¶lges OLS som den endelige D7-model, mens Lasso prim√¶rt fungerer som en robusthedskontrol, der bekr√¶fter modellens stabilitet.

### Klarg√∏ring af plot-data og residualer

Denne kode samler faktiske v√¶rdier og forudsigelser fra alle tre modeller i √©t datas√¶t.\
Datas√¶ttet anvendes til standardplots for sammenligning af prediction og residualer.

```{r}

#  Plot-data + standard plots (actual vs pred, residual plots)

plot_df <- tibble::tibble(
  kamp_dato   = test_d7$kamp_dato,
  actual      = y_test,
  pred_lm     = pred_lm,
  pred_ridge  = pred_ridge,
  pred_lasso  = pred_lasso
) |>
  dplyr::mutate(
    resid_lm    = actual - pred_lm,
    resid_ridge = actual - pred_ridge,
    resid_lasso = actual - pred_lasso
  )

```

#### Ligninger for de endelige modeller

Her udledes l√¶sbare ligninger for OLS-, Ridge- og Lasso-modellerne baseret p√• de estimerede koefficienter. Form√•let er at g√∏re modellernes struktur og forskelle let forst√•elige i den efterf√∏lgende formidling.

```{r}

# --- LIGNINGSTEKSTER (alle tre modeller) ---
eq_ols   <- build_lm_equation_text(m_d7_final_lm, y_name = "tilskuere", yhat_name = "≈∑")
eq_ridge <- build_glmnet_equation_text(cv_ridge, x_names = x_names, model_label = "Ridge", yhat_name = "≈∑")
eq_lasso <- build_glmnet_equation_text(cv_lasso, x_names = x_names, model_label = "Lasso", yhat_name = "≈∑")



```

#### Plot: Faktiske vs. forudsagte tilskuere (OLS)

Dette plot sammenligner faktiske og forudsagte tilskuertal for OLS-modellen p√• testdatas√¶ttet. Ligningen inds√¶ttes direkte i figuren for at underst√∏tte fortolkningen af modellen.

```{r}
p1 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_lm)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D7 TEST: Actual vs Pred (OLS)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p1 <- add_eq_to_plot(p1, eq_ols)
print(p1)
```

I grafen ‚ÄúD7 TEST: Actual vs Pred (OLS)‚Äù vises forholdet mellem faktiske og forudsagte tilskuertal i testdatas√¶ttet. Hvert punkt repr√¶senterer en kamp, hvor den vandrette akse er de faktiske tilskuere, og den lodrette akse er modellens forudsigelse. At punkterne overvejende ligger t√¶t p√• diagonalen indikerer, at OLS-modellen har en god pr√¶cision og er velegnet til at forudsige tilskuertallet syv dage f√∏r kamp.

```{r}
p2 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_ridge)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D7 TEST: Actual vs Pred (Ridge)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p2 <- add_eq_to_plot(p2, eq_ridge)
print(p2)

```

```{r}
p3 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_lasso)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D7 TEST: Actual vs Pred (Lasso)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p3 <- add_eq_to_plot(p3, eq_lasso)
print(p3
       )
```

I grafen ‚ÄúD7 TEST: Actual vs Pred (Ridge)‚Äù vises sammenh√¶ngen mellem faktiske og forudsagte tilskuertal for Ridge-modellen. Hvert punkt repr√¶senterer en kamp, hvor x-aksen angiver de faktiske tilskuertal og y-aksen de forudsagte. Punkterne ligger generelt l√¶ngere fra diagonalen end i OLS-grafen, hvilket indikerer st√∏rre usikkerhed og lavere pr√¶cision i modellens forudsigelser, s√¶rligt ved h√∏je tilskuertal.

```{r}
p4 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_lm, y = resid_lm)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D7 TEST: Residualer vs Pred (OLS)",
    x = "Forudsagt",
    y = "Residual"
  )
p4 <- add_eq_to_plot(p4, eq_ols)
print(p4)
```

I grafen ‚ÄúD7 TEST: Residualer vs Pred (Lasso)‚Äù vises residualerne som funktion af de forudsagte tilskuertal fra Lasso-modellen. Residualerne er overordnet centreret omkring nul-linjen uden et tydeligt systematisk m√∏nster, hvilket indikerer, at modellen ikke har en klar strukturel bias. Der ses dog en relativt stor spredning, s√¶rligt i midteromr√•det af de forudsagte v√¶rdier, som tyder p√•, at Lasso-modellen har vanskeligere ved pr√¶cist at ramme individuelle kampe sammenlignet med OLS, selvom den overordnet f√∏lger niveauet rimeligt.

```{r}
p5 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_ridge, y = resid_ridge)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D7 TEST: Residualer vs Pred (Ridge)",
    x = "Forudsagt",
    y = "Residual"
  )
p5 <- add_eq_to_plot(p5, eq_ridge)
print(p5)
```

I grafen ‚ÄúD7 TEST: Residualer vs Pred (Ridge)‚Äù ses residualerne plottet mod de forudsagte tilskuertal fra Ridge-modellen. Residualerne ligger overordnet omkring nul, men der er en tydelig st√∏rre spredning end ved OLS, is√¶r ved b√•de lave og h√∏je forudsagte v√¶rdier. Dette indikerer, at Ridge-modellen har sv√¶rere ved at ramme de enkelte kampe pr√¶cist og udviser tegn p√• systematiske afvigelser i yderomr√•derne, hvilket stemmer overens med modellens ringere test-performance m√•lt p√• RMSE og R¬≤.

```{r}
p6 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_lasso, y = resid_lasso)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D7 TEST: Residualer vs Pred (Lasso)",
    x = "Forudsagt",
    y = "Residual"
  )
p6 <- add_eq_to_plot(p6, eq_lasso)
print(p6)
```

I grafen ‚ÄúD7 TEST: Residualer vs Pred (Lasso)‚Äù vises sammenh√¶ngen mellem de forudsagte tilskuertal og modellens residualer. Residualerne er overvejende centreret omkring nul og fordeler sig relativt j√¶vnt p√• tv√¶rs af de forudsagte v√¶rdier, uden tydelige systematiske m√∏nstre. Det indikerer, at Lasso-modellen generelt fanger strukturen i data fornuftigt, men med en lidt st√∏rre spredning end OLS, is√¶r omkring midteromr√•det. Dette underst√∏tter, at Lasso pr√¶sterer t√¶t p√• OLS, men uden at give en egentlig forbedring i pr√¶cision.

```{r}
# - Resultat-objekt ---
d7_results <- list(
  perf         = perf_d7,
  lm_model     = m_d7_final_lm,
  ridge_lambda = lambda_ridge,
  lasso_lambda = lambda_lasso,
  plot_data    = plot_df,
  equations    = list(ols = eq_ols, ridge = eq_ridge, lasso = eq_lasso)
)

cat("D7 final resultater gemt i objektet: d7_results ‚úÖ\n")
```

#### Forberedelse af input-features til D7-modellen

Denne funktion udv√¶lger og transformer¬≠er de n√∏dvendige variable til et konsistent feature-s√¶t. Form√•let er at sikre korrekt datatyper og genbrugelig klarg√∏ring f√∏r modellering og prediction.

```{r}
prep_features_d7 <- function(df) {
  stopifnot(all(c(
    "kamp_id","kamp_dato","s√¶son","runde","kamp_time_h","billetter_d7","v√¶kst_d10_d7"
  ) %in% names(df)))
  
  df |>
    dplyr::transmute(
      kamp_id      = as.character(kamp_id),
      kamp_dato    = as.Date(kamp_dato),
      s√¶son_chr    = as.character(s√¶son),
      s√¶son_start  = season_start_year(s√¶son_chr),
      runde        = as.integer(runde),
      kamp_time_h  = as.integer(kamp_time_h),
      billetter_d7 = as.numeric(billetter_d7),
      v√¶kst_d10_d7 = as.numeric(v√¶kst_d10_d7)
    )
}
```

#### Prediction-helper til D7 (OLS)

Denne funktion genererer forudsigelser fra den endelige OLS-model p√• nye data. Negative v√¶rdier klippes til nul for at sikre realistiske prognoser.

```{r}
predict_d7_lm <- function(model_lm, new_df) {
  new_x <- prep_features_d7(new_df)
  keep <- stats::complete.cases(new_x)
  
  out <- tibble::tibble(
    kamp_id   = new_x$kamp_id,
    kamp_dato = new_x$kamp_dato,
    pred      = NA_real_
  )
  
  out$pred[keep] <- clip_nonneg(as.numeric(stats::predict(model_lm, newdata = new_x[keep, ])))
  out
}

```

```{r}
predict_d7_glmnet <- function(cv_model, new_df) {
  new_x <- prep_features_d7(new_df)
  keep <- stats::complete.cases(new_x)
  
  X <- stats::model.matrix(
    ~ s√¶son_start + runde + kamp_time_h + billetter_d7 + v√¶kst_d10_d7,
    data = new_x
  )[, -1, drop = FALSE]
  
  out <- tibble::tibble(
    kamp_id   = new_x$kamp_id,
    kamp_dato = new_x$kamp_dato,
    pred      = NA_real_
  )
  
  out$pred[keep] <- clip_nonneg(as.numeric(stats::predict(
    cv_model,
    newx = X[keep, , drop = FALSE],
    s = "lambda.min"
  )))
  out
}
```

#### Prediction-helper til D7 (Ridge/Lasso)

Denne funktion genererer forudsigelser fra Ridge- og Lasso-modeller p√• nye data. Den sikrer konsistent feature-opbygning og h√•ndtering af manglende v√¶rdier.

```{r}
d7_artifacts <- list(
  perf  = perf_d7,
  models = list(
    lm    = m_d7_final_lm,
    ridge = cv_ridge,
    lasso = cv_lasso
  ),
  split_info = list(
    test_prop            = test_prop,
    cut_date_test_start  = min(test_d7$kamp_dato),
    n_train              = nrow(train_d7),
    n_test               = nrow(test_d7)
  ),
  equations = list(ols = eq_ols, ridge = eq_ridge, lasso = eq_lasso)
)

cat("D7 pipeline klar ‚úÖ Artefakter gemt i: d7_artifacts\n")
```

##Shiny prognose App

### Afgr√¶nsning af forudsigelser til stadionkapacitet

Denne funktion sikrer, at model¬≠forudsigelser holdes inden for realistiske gr√¶nser.\
Forudsigelser klippes til intervallet fra 0 til stadionets maksimale kapacitet.

```{r}


#  CAP/CLIP (stadionloft) ‚Äî klar til dit produktlag

STADIUM_CAP_VFF <- 10000

clip_to_cap <- function(x, cap = STADIUM_CAP_VFF) {
  pmin(pmax(as.numeric(x), 0), cap)
}

```

### Klarg√∏ring til Shiny-applikation

Denne kode forbereder milj√∏et til Shiny ved at indl√¶se n√∏dvendige pakker og validere, at alle p√•kr√¶vede objekter findes. Form√•let er at sikre, at applikationen kan afvikles stabilt uden runtime-fejl.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

suppressPackageStartupMessages({
  library(dplyr)
  library(tibble)
  library(ggplot2)
  library(shiny)
})

.must_exist <- function(x) exists(x, inherits = TRUE)

stopifnot(.must_exist("perf_d7"), .must_exist("plot_df"), .must_exist("train_d7"), .must_exist("test_d7"))
stopifnot(.must_exist("m_d7_final_lm"), .must_exist("cv_lasso"))
stopifnot(.must_exist("rmse_vec"), .must_exist("clip_nonneg"), .must_exist("clip_to_cap"))

stopifnot(all(c("model","RMSE") %in% names(perf_d7)))
stopifnot(all(c("actual","pred_lm","pred_lasso") %in% names(plot_df)))
stopifnot(all(c("s√¶son_start","runde","kamp_time_h","billetter_d7","v√¶kst_d10_d7") %in% names(train_d7)))

```

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny



# 1) TOP 2: v√¶lg default (bedst) mellem OLS og Lasso ud fra perf_d7

perf_top2 <- perf_d7 |>
  dplyr::filter(grepl("^OLS", model, ignore.case = TRUE) | grepl("^Lasso", model, ignore.case = TRUE))

# Fail-safe hvis labels er anderledes
if (nrow(perf_top2) == 0) {
  perf_top2 <- tibble::tibble(
    model = c("OLS (lm)", "Lasso (cv.glmnet)"),
    RMSE  = c(Inf, Inf),
    MAE   = c(NA_real_, NA_real_),
    R2    = c(NA_real_, NA_real_)
  )
}

top2_best_row <- perf_top2 |> arrange(RMSE) |> slice(1)
default_key <- dplyr::case_when(
  grepl("^OLS", top2_best_row$model[1], ignore.case = TRUE)   ~ "lm",
  grepl("^Lasso", top2_best_row$model[1], ignore.case = TRUE) ~ "lasso",
  TRUE ~ "lm"
)

cat("‚úÖ Default model (bedst af OLS/LASSO):", as.character(top2_best_row$model[1]), "=>", default_key, "\n\n")

```

### Valg af standardmodel til Shiny

Denne kode identificerer den bedste model mellem OLS og Lasso baseret p√• RMSE.\
Den valgte model s√¶ttes som default i Shiny-applikationen med indbyggede failsafes.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


# =============================================================================
# 2) Hj√¶lpere: format + ligningstekst
# =============================================================================
.format_num <- function(x, digits = 3) {
  format(round(as.numeric(x), digits), big.mark = ".", decimal.mark = ",", trim = TRUE)
}

lm_equation_text <- function(fit, digits = 3, max_terms = 8) {
  b <- coef(fit)
  b[is.na(b)] <- 0
  nm <- names(b)
  
  intercept <- if ("(Intercept)" %in% nm) b["(Intercept)"] else 0
  rest <- setdiff(nm, "(Intercept)")
  if (length(rest) == 0) return(paste0("≈∑ = ", .format_num(intercept, digits)))
  
  ord <- order(abs(b[rest]), decreasing = TRUE)
  rest <- rest[ord]
  if (length(rest) > max_terms) rest <- rest[1:max_terms]
  
  rhs <- vapply(rest, function(v) paste0(v, "¬∑", .format_num(b[v], digits)), character(1))
  paste0("≈∑ = ", .format_num(intercept, digits), " + ", paste(rhs, collapse = " + "))
}

glmnet_equation_text <- function(cvobj, s = "lambda.min", digits = 3, max_terms = 10) {
  cm <- as.matrix(coef(cvobj, s = s))
  if (nrow(cm) == 0) return("Ingen koefficienter")
  
  coefs <- as.numeric(cm[, 1])
  names(coefs) <- rownames(cm)
  
  intercept <- if ("(Intercept)" %in% names(coefs)) coefs["(Intercept)"] else 0
  rest <- setdiff(names(coefs), "(Intercept)")
  
  nz <- rest[coefs[rest] != 0]
  if (length(nz) == 0) return(paste0("≈∑ = ", .format_num(intercept, digits), "  (alle √∏vrige = 0)"))
  
  ord <- order(abs(coefs[nz]), decreasing = TRUE)
  nz <- nz[ord]
  if (length(nz) > max_terms) nz <- nz[1:max_terms]
  
  rhs <- vapply(nz, function(v) paste0(v, "¬∑", .format_num(coefs[v], digits)), character(1))
  paste0("≈∑ = ", .format_num(intercept, digits), " + ", paste(rhs, collapse = " + "))
}

plot_pva_with_eq <- function(df, title, eq_text, rmse_val) {
  ggplot(df, aes(x = y, y = yhat)) +
    geom_point(alpha = 0.7) +
    geom_abline(slope = 1, intercept = 0) +
    labs(
      title = title,
      x = "Faktiske tilskuere",
      y = "Forudsagte tilskuere"
    ) +
    annotate(
      "text",
      x = Inf, y = -Inf,
      hjust = 1.02, vjust = -0.2,
      label = paste0("RMSE = ", .format_num(rmse_val, 1)),
      size = 3.8
    ) +
    annotate(
      "text",
      x = -Inf, y = Inf,
      hjust = -0.02, vjust = 1.15,
      label = eq_text,
      size = 3.2
    ) +
    theme_minimal()
}

```

### Hj√¶lpefunktioner til s√¶soninput i Shiny

Disse funktioner h√•ndterer konvertering og validering af s√¶soninput fra brugeren, fx ‚Äú2025/2026‚Äù. Form√•let er at sikre robust fortolkning af s√¶sonen og give klare fallback-beskeder ved ugyldigt format.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

# =============================================================================
# 3) S√¶son-helpers: "2025/2026" -> s√¶son_start = 2025
# =============================================================================
season_label <- function(season_start_int) {
  paste0(as.integer(season_start_int), "/", as.integer(season_start_int) + 1L)
}

parse_season_start <- function(season_text) {
  s <- trimws(as.character(season_text))
  ok <- grepl("^\\d{4}/\\d{4}$", s)
  
  if (!ok) {
    # fallback: pr√∏v at finde f√∏rste 4 cifre
    y <- suppressWarnings(as.integer(substr(s, 1, 4)))
    if (!is.finite(y)) return(list(start = NA_integer_, note = "Ugyldigt s√¶sonformat. Brug fx 2025/2026."))
    return(list(start = y, note = "S√¶sonformat er ikke 'YYYY/YYYY'. Jeg bruger f√∏rste √•r som s√¶son_start."))
  }
  
  y1 <- suppressWarnings(as.integer(substr(s, 1, 4)))
  y2 <- suppressWarnings(as.integer(substr(s, 6, 9)))
  if (!is.finite(y1) || !is.finite(y2)) return(list(start = NA_integer_, note = "Ugyldigt s√¶sonformat."))
  if (y2 != y1 + 1L) {
    return(list(start = y1, note = "Andet √•r er ikke f√∏rste+1. Jeg bruger f√∏rste √•r som s√¶son_start."))
  }
  list(start = y1, note = "")
}

```

### Visualisering af bedste D7-model (OLS/Lasso)

Denne kode genererer √©t samlet *Pred vs. Actual*-plot for den bedst performende model mellem OLS og Lasso. Valget sker automatisk ud fra test-RMSE, s√• visualiseringen altid afspejler den st√¶rkeste D7-model.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


# =============================================================================
# 4) √âN graf: Pred vs Actual for default bedste (OLS/LASSO) ‚Äî s√¶sontekst neutral
# =============================================================================
y <- as.numeric(plot_df$actual)

if (default_key == "lm") {
  yhat <- as.numeric(plot_df$pred_lm)
  eq_best <- lm_equation_text(m_d7_final_lm, digits = 3, max_terms = 8)
  title_best <- "D7 ‚Äî BEDSTE (OLS/LASSO): OLS (lm) ‚Äî Pred vs Actual"
} else {
  yhat <- as.numeric(plot_df$pred_lasso)
  eq_best <- glmnet_equation_text(cv_lasso, s = "lambda.min", digits = 3, max_terms = 10)
  title_best <- "D7 ‚Äî BEDSTE (OLS/LASSO): Lasso (Œª‚Çò·µ¢‚Çô) ‚Äî Pred vs Actual"
}

df_best <- tibble::tibble(y = y, yhat = yhat)
rmse_best <- rmse_vec(df_best$y, df_best$yhat)

print(plot_pva_with_eq(df_best, title_best, eq_best, rmse_best))
cat("\n‚úÖ D7 top2-plot f√¶rdig\n\n")

```

### Shiny-applikation til D7-prognoser

Denne sektion definerer brugergr√¶nsefladen til en Shiny-applikation, hvor D7-modellen anvendes operationelt. Brugeren kan v√¶lge model, inds√¶tte centrale kampinput og f√• en realistisk tilsku¬≠erprognose under hensyntagen til stadionkapacitet.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


# =============================================================================
# 5) SHINY APP ‚Äî s√¶son er input (default 2025/2026)
# =============================================================================
.range_or <- function(x, fallback = c(0, 1)) {
  r <- range(as.numeric(x), na.rm = TRUE)
  if (any(!is.finite(r))) fallback else r
}

.med_or <- function(x, fallback = 0) {
  v <- stats::median(as.numeric(x), na.rm = TRUE)
  if (!is.finite(v)) fallback else v
}

.fill_bucket <- function(pct) {
  if (!is.finite(pct)) return("UKENDT")
  if (pct >= 85) return("H√òJ")
  if (pct >= 60) return("MIDDEL")
  "LAV"
}

.predict_model <- function(model_key, s√¶son_start, runde, kamp_time_h, billetter_d7, v√¶kst_d10_d7) {
  
  nd <- data.frame(
    s√¶son_start  = as.integer(s√¶son_start),
    runde        = as.integer(runde),
    kamp_time_h  = as.integer(kamp_time_h),
    billetter_d7 = as.numeric(billetter_d7),
    v√¶kst_d10_d7 = as.numeric(v√¶kst_d10_d7)
  )
  
  if (model_key == "lm") {
    yhat <- suppressWarnings(as.numeric(predict(m_d7_final_lm, newdata = nd)))
  } else {
    X <- model.matrix(~ s√¶son_start + runde + kamp_time_h + billetter_d7 + v√¶kst_d10_d7, data = nd)[, -1, drop = FALSE]
    yhat <- suppressWarnings(as.numeric(predict(cv_lasso, newx = X, s = "lambda.min")))
  }
  
  if (length(yhat) == 0) yhat <- NA_real_
  clip_nonneg(yhat)
}

.eq_for_key <- function(model_key) {
  if (model_key == "lm") {
    lm_equation_text(m_d7_final_lm, digits = 3, max_terms = 8)
  } else {
    glmnet_equation_text(cv_lasso, s = "lambda.min", digits = 3, max_terms = 10)
  }
}

.model_name <- function(model_key) {
  if (model_key == "lm") "OLS (lm)" else "Lasso (cv.glmnet)"
}

ui <- fluidPage(
  titlePanel("D7 ‚Äî Prediction (OLS vs Lasso)"),
  
  sidebarLayout(
    sidebarPanel(
      tags$h4("Model"),
      selectInput(
        "model_choice",
        "V√¶lg model (default = bedst)",
        choices = c("OLS (lm)" = "lm", "Lasso (cv.glmnet)" = "lasso"),
        selected = default_key
      ),
      tags$hr(),
      
      tags$h4("Inputs"),
      textInput("season_txt", "S√¶son (YYYY/YYYY)", value = "2025/2026"),
      
      numericInput(
        "runde", "runde",
        value = .med_or(train_d7$runde, fallback = 1),
        min = .range_or(train_d7$runde, fallback = c(1, 40))[1],
        max = .range_or(train_d7$runde, fallback = c(1, 40))[2]
      ),
      numericInput(
        "kamp_time_h", "kamp_time_h",
        value = .med_or(train_d7$kamp_time_h, fallback = 18),
        min = .range_or(train_d7$kamp_time_h, fallback = c(10, 22))[1],
        max = .range_or(train_d7$kamp_time_h, fallback = c(10, 22))[2]
      ),
      numericInput(
        "billetter_d7", "billetter_d7",
        value = .med_or(train_d7$billetter_d7, fallback = 0),
        min = .range_or(train_d7$billetter_d7, fallback = c(0, 12000))[1],
        max = .range_or(train_d7$billetter_d7, fallback = c(0, 12000))[2]
      ),
      numericInput(
        "v√¶kst_d10_d7", "v√¶kst_d10_d7",
        value = .med_or(train_d7$v√¶kst_d10_d7, fallback = 0),
        min = 0,
        max = max(0, .range_or(train_d7$v√¶kst_d10_d7, fallback = c(0, 12000))[2])
      ),
      
      tags$hr(),
      numericInput("capacity", "Stadion-kapacitet", value = 10000, min = 1),
      actionButton("go", "Predict", class = "btn-primary")
    ),
    
    mainPanel(
      tags$h4("Output"),
      tags$div(style="font-size:20px; margin-bottom:8px;", textOutput("pred_txt")),
      tags$div(style="font-size:20px; margin-bottom:8px;", textOutput("pct_txt")),
      tags$div(style="font-size:20px; margin-bottom:8px;", textOutput("delta_txt")),
      tags$div(style="font-size:14px; margin-bottom:6px; color:#333;", textOutput("season_note_txt")),
      tags$div(style="font-size:14px; margin-bottom:14px; color:#333;", textOutput("eq_txt")),
      plotOutput("cap_plot", height = "520px")
    )
  )
)

```

#### Serverlogik til Shiny-applikationen

Denne sektion definerer server-logikken for Shiny-applikationen, herunder beregning af prognoser, validering af input og dynamisk opdatering af output. Modellen anvendes operationelt til at levere tilsku¬≠erprognoser, kapacitetsudnyttelse og visualiseringer baseret p√• brugerens valg.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


server <- function(input, output, session) {
  
  pred_obj <- eventReactive(input$go, {
    
    cap <- as.numeric(input$capacity)
    if (!is.finite(cap) || cap <= 0) cap <- 1
    
    key <- input$model_choice
    
    season_parsed <- parse_season_start(input$season_txt)
    s√¶son_start <- season_parsed$start
    
    if (!is.finite(s√¶son_start)) {
      return(list(
        ok = FALSE,
        msg = "Ugyldig s√¶son. Brug formatet 2025/2026.",
        note = season_parsed$note
      ))
    }
    
    yhat <- .predict_model(
      model_key   = key,
      s√¶son_start = s√¶son_start,
      runde       = input$runde,
      kamp_time_h = input$kamp_time_h,
      billetter_d7 = input$billetter_d7,
      v√¶kst_d10_d7 = input$v√¶kst_d10_d7
    )
    
    yhat_cap <- clip_to_cap(yhat, cap = cap)
    
    pct <- (as.numeric(yhat_cap) / cap) * 100
    pct_clip <- max(min(pct, 100), 0)
    
    bil <- as.numeric(input$billetter_d7)
    delta <- if (is.finite(bil)) (as.numeric(yhat_cap) - bil) else NA_real_
    
    list(
      ok = TRUE,
      pred = as.numeric(yhat_cap),
      pct  = pct_clip,
      cap  = cap,
      bil_d7 = bil,
      delta = delta,
      eq = .eq_for_key(key),
      model_name = .model_name(key),
      season_txt = season_label(s√¶son_start),
      note = season_parsed$note
    )
  })
  
  output$pred_txt <- renderText({
    x <- pred_obj()
    if (is.null(x)) return("Ingen prediction endnu.")
    if (!isTRUE(x$ok)) return(x$msg)
    
    paste0(
      "Model: ", x$model_name, " ‚Äî s√¶son ", x$season_txt, "\n",
      "Forudsagt tilskuertal: ", format(round(x$pred), big.mark = ".", decimal.mark = ",")
    )
  })
  
  output$pct_txt <- renderText({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return("")
    paste0("Stadion fyldt: ", format(round(x$pct, 1), big.mark = ".", decimal.mark = ","), " %")
  })
  
  output$delta_txt <- renderText({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return("")
    if (!is.finite(x$bil_d7)) return("Ekstra billetter (D7 ‚Üí kampdag): kan ikke beregnes (billetter_d7 mangler)")
    paste0(
      "Ekstra billetter (D7 ‚Üí kampdag): ",
      format(round(x$delta), big.mark = ".", decimal.mark = ","),
      "  (≈∑ ‚àí billetter_d7)"
    )
  })
  
  output$season_note_txt <- renderText({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return("")
    if (is.null(x$note) || !nzchar(x$note)) return("")
    paste0("Note: ", x$note)
  })
  
  output$eq_txt <- renderText({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return("")
    paste0("Ligning (kort): ", x$eq)
  })
  
  output$cap_plot <- renderPlot({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return(NULL)
    
    bucket <- .fill_bucket(x$pct)
    
    df <- data.frame(
      label = "Stadionkapacitet",
      y = x$pred,
      bucket = bucket
    )
    
    ggplot(df, aes(x = label, y = y, fill = bucket)) +
      geom_col(width = 0.6) +
      geom_hline(yintercept = x$cap, linewidth = 0.9, linetype = 2) +
      coord_cartesian(ylim = c(0, x$cap)) +
      scale_fill_manual(
        values = c("LAV" = "#d55e00", "MIDDEL" = "#e69f00", "H√òJ" = "#009e73", "UKENDT" = "grey60"),
        breaks = c("LAV","MIDDEL","H√òJ","UKENDT"),
        name = "Fyldningsniveau"
      ) +
      labs(
        x = NULL,
        y = "Tilskuere (forudsagt)",
        title = "Forudsagt tilskuertal vs stadionkapacitet",
        subtitle = paste0(
          "Kapacitet (stiplet linje): ",
          format(round(x$cap), big.mark=".", decimal.mark=",")
        )
      ) +
      theme_minimal(base_size = 16) +
      theme(
        legend.position = "top",
        plot.title = element_text(face = "bold"),
        panel.grid.minor = element_blank()
      )
  })
}

shinyApp(ui, server)
```

#### Case: D7-prediction som aktivt beslutningsv√¶rkt√∏j

Der er en Superliga-hjemmekamp p√• Energi Viborg Arena om syv dage, og Palle, som er ansvarlig for bemanding og kampafvikling hos Viborg FF, skal i gang med planl√¶gningen. Med et stadion, der rummer 10.000 pladser, er det afg√∏rende tidligt at vurdere, om eftersp√∏rgslen peger mod et lavt, middel eller h√∏jt fremm√∏de.

Palle anvender D7-prediction-appen og indtaster de kendte oplysninger: s√¶son 2025/2026, runde 21, kampstart kl. 18 samt et aktuelt billetsalg p√• 2.680 billetter syv dage f√∏r kamp.

![](images/2026-01-05_11h29_34.png)

OLS-model giver en prognose p√• ca. 4.560 tilskuere, svarende til en forventet kapacitetsudnyttelse p√• 45,6 %.

Denne prognose indikerer, at der fortsat er betydelig ledig kapacitet p√• stadion. P√• den baggrund v√¶lger Palle at aktivere marketingindsatsen. Den SoMe-ansvarlige f√•r gr√∏nt lys til at iv√¶rks√¶tte m√•lrettede kampagner p√• Facebook og Instagram, eksempelvis med fokus p√• kampstemning, familietilbud eller sidste-√∏jebliks-billetter, for at l√∏fte eftersp√∏rgslen i dagene op til kampstart.

Samtidig estimerer modellen et forventet ekstra billetsalg p√• omkring 1.880 billetter frem mod kampdagen. Det giver Palle et realistisk pejlem√¶rke for, hvor meget bemandingen skal kunne skaleres, hvis marketingindsatsen lykkes. D7-predictionen bruges dermed ikke kun passivt, men som et aktivt styringsv√¶rkt√∏j, hvor prognosen danner grundlag for b√•de marketingbeslutninger og operationel planl√¶gning.

# ML model D10

Dette afsnit samler hele D10-workflowet i √©t sammenh√¶ngende script. Der bygges f√∏rst en f√¶lles baseline med √©n r√¶kke pr. kamp og tilh√∏rende features, hvorefter et D10-analysedatas√¶t konstrueres med billetsalg 10 dage f√∏r kamp. Herefter gennemf√∏res systematiske variabeltests mod en fast nulmodel for at vurdere marginal effekt og data-omkostning. Afslutningsvis estimeres og evalueres endelige D10-modeller via et tidsbaseret split, hvor OLS, Ridge og Lasso sammenlignes, og den bedste model g√∏res operationel gennem artefakter, plots og en Shiny-applikation.

### Pakker og ops√¶tning

Her indl√¶ses alle n√∏dvendige pakker samlet via pacman, s√• milj√∏et er konsistent og reproducerbart. Samtidig fasts√¶ttes globale indstillinger, der sikrer l√¶sbar output og stabil k√∏rsel under hele analysen.

```{r}

if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman")
}

pacman::p_load(
  DBI,
  odbc,
  dplyr,
  lubridate,
  stringr,
  tibble,
  ggplot2,
  glmnet,
  rsample
)

options(scipen = 999)
cat("Pakker er klar ‚úÖ\n\n")



```

### Hj√¶lpefunktioner

```{r}
ensure_renviron <- function() {
  req <- c("AZURE_SQL_SERVER","AZURE_SQL_DB","AZURE_SQL_UID","AZURE_SQL_PWD")
  vals <- Sys.getenv(req)
  miss <- req[vals == ""]
  if (length(miss) > 0) stop("‚ùå Manglende milj√∏variabler i .Renviron: ", paste(miss, collapse = ", "))
  cat("‚úî .Renviron OK\n\n")
}
```

#### Milj√∏variabler og adgang

Denne funktion sikrer, at alle n√∏dvendige Azure-forbindelsesoplysninger er korrekt sat i .Renviron, f√∏r der arbejdes videre. Hvis noget mangler, stoppes scriptet med det samme for at undg√• skjulte forbindelsesfejl senere i pipeline.

```{r}
connect_azure_retry <- function(
    fors√∏g_max = 6,
    timeouts   = c(60, 180, 240, 360, 600, 900),
    delay_sec  = 10
) {
  for (i in seq_len(fors√∏g_max)) {
    timeout_brug <- timeouts[min(i, length(timeouts))]
    cat("Fors√∏g ", i, " / ", fors√∏g_max, " ‚Äî ConnectionTimeout = ", timeout_brug, " sek\n", sep = "")
    con_try <- try(
      DBI::dbConnect(
        odbc::odbc(),
        driver   = "ODBC Driver 18 for SQL Server",
        server   = Sys.getenv("AZURE_SQL_SERVER"),
        database = Sys.getenv("AZURE_SQL_DB"),
        uid      = Sys.getenv("AZURE_SQL_UID"),
        pwd      = Sys.getenv("AZURE_SQL_PWD"),
        Encrypt  = "yes",
        TrustServerCertificate = "no",
        ConnectionTimeout = timeout_brug
      ),
      silent = TRUE
    )
    if (!inherits(con_try, "try-error")) {
      cat("‚úÖ Forbundet til Azure SQL\n\n")
      return(con_try)
    }
    if (i < fors√∏g_max) Sys.sleep(delay_sec)
  }
  stop("‚ùå Kunne ikke forbinde til Azure SQL efter ", fors√∏g_max, " fors√∏g.")
}

```

```{r}
safe_dbReadTable <- function(con, schema, table, fors√∏g_max = 4, delay_sec = 3) {
  for (i in seq_len(fors√∏g_max)) {
    out <- try(DBI::dbReadTable(con, DBI::Id(schema = schema, table = table)), silent = TRUE)
    if (!inherits(out, "try-error")) return(out)
    msg <- as.character(out)
    cat("‚ö†Ô∏è dbReadTable fejlede (", i, " / ", fors√∏g_max, "): ", schema, ".", table, "\n", sep = "")
    cat(substr(msg, 1, 220), "...\n\n")
    if (i < fors√∏g_max) Sys.sleep(delay_sec)
  }
  stop("‚ùå Kunne ikke l√¶se tabel: ", schema, ".", table)
}
```

#### Sikker datal√¶sning fra SQL

Funktionen l√¶ser en tabel fra Azure SQL med indbygget retry-logik. Hvis l√¶sningen fejler midlertidigt, fors√∏ger den igen et fast antal gange med korte pauser, s√• ustabile forbindelser ikke stopper hele pipeline un√∏digt.

```{r}
time_chr_to_hour <- function(x) {
  x <- str_trim(as.character(x))
  x <- if_else(str_detect(x, "^\\d{1,2}:\\d{2}$"), paste0(x, ":00"), x)
  ok <- str_detect(x, "^\\d{1,2}:\\d{2}:\\d{2}$")
  out <- rep(NA_integer_, length(x))
  out[ok] <- as.integer(str_extract(x[ok], "^\\d{1,2}"))
  out
}
```

#### Dublet-h√•ndtering pr kamp

Funktionen sikrer, at der kun findes √©n r√¶kke pr kamp_id. Hvis der er dubletter, beholdes den mest komplette r√¶kke ved at v√¶lge den med f√¶rrest manglende v√¶rdier, s√• datatabet minimeres.

```{r}
dedup_1row_by_id <- function(df, id_col = "kamp_id") {
  stopifnot(id_col %in% names(df))
  df2 <- df
  df2$.na_count <- rowSums(is.na(df2))
  df2 |>
    arrange(.data[[id_col]], .na_count) |>
    group_by(.data[[id_col]]) |>
    slice(1) |>
    ungroup() |>
    select(-.na_count)
}
```

#### Sikker datokonvertering

Funktionen konverterer v√¶rdier til datoformat p√• en robust m√•de. Hvis input allerede er en dato, returneres den u√¶ndret, og ellers fors√∏ges en kontrolleret konvertering uden at afbryde koden ved fejl.

```{r}
as_date_safely <- function(x) {
  if (inherits(x, "Date")) return(x)
  suppressWarnings(as.Date(x, format = "%d-%m-%Y"))
}
```

#### S√¶sonens start√•r

Funktionen udtr√¶kker det f√∏rste √•rstal fra en s√¶sonangivelse og bruger det som numerisk start√•r for s√¶sonen i modelleringen.

```{r}
season_start_year <- function(season_chr) {
  x <- as.character(season_chr)
  suppressWarnings(as.integer(stringr::str_extract(x, "\\d{4}")))
}
```

#### Negativ afsk√¶ring

Funktionen sikrer, at v√¶rdier ikke bliver negative ved at erstatte alle tal under nul med 0, s√• modellens output altid giver realistiske tilskuertal.

```{r}
clip_nonneg <- function(x) pmax(as.numeric(x), 0)
```

#### Modelm√•l for pr√¶cision

Disse funktioner beregner standardm√•l for modelkvalitet. RMSE m√•ler den typiske fejlst√∏rrelse og straffer store fejl h√•rdt. MAE viser den gennemsnitlige absolutte fejl og er lettere at fortolke. R¬≤ angiver, hvor stor en andel af variationen i tilskuertallet modellen forklarer.

```{r}
rmse_vec <- function(y, yhat) sqrt(mean((y - yhat) ^ 2, na.rm = TRUE))

mae_vec  <- function(y, yhat) mean(abs(y - yhat), na.rm = TRUE)

r2_vec <- function(y, yhat) {
  sse <- sum((y - yhat) ^ 2, na.rm = TRUE)
  sst <- sum((y - mean(y, na.rm = TRUE)) ^ 2, na.rm = TRUE)
  1 - (sse / sst)
}

```

### Forbindelse til datagrundlag

Her kontrolleres det, at alle n√∏dvendige loginoplysninger findes i .Renviron, hvorefter der oprettes en stabil forbindelse til Azure SQL-databasen med automatisk genfors√∏g ved fejl.

```{r}
ensure_renviron()
con <- connect_azure_retry()
```

### Indl√¶sning af baseline

Her indl√¶ses den f√¶lles baseline fra en gemt RDS-fil. Datas√¶ttet standardiseres, s√• kamp_id og kamp_dato har korrekt datatype, og der kontrolleres, at der findes pr√¶cis de centrale variable, som resten af modellen bygger videre p√•.

```{r}
baseline_dir  <- "C:/Users/janpe/OneDrive/Skrivebord/PBA Dataanlyse/01_F√∏rste semester/1 Semester projekt/Baseline"
baseline_file <- file.path(baseline_dir, "baseline_azure.rds")
stopifnot(file.exists(baseline_file))

baseline <- readRDS(baseline_file) |>
  mutate(
    kamp_id   = as.character(kamp_id),
    kamp_dato = as.Date(kamp_dato)
  )

stopifnot(all(c("kamp_id","kamp_dato","tilskuere") %in% names(baseline)))

cat("Baseline loaded ‚úÖ  R√¶kker: ", nrow(baseline),
    "  Unikke kamp_id: ", n_distinct(baseline$kamp_id), "\n\n", sep = "")

```

### Dublettjek af baseline

Her kontrolleres det, om der findes flere r√¶kker med samme kamp_id. Hvis der opdages dubletter, reduceres datas√¶ttet automatisk til √©n r√¶kke pr. kamp ved at beholde den mest komplette observation. Dermed sikres en entydig baseline, som er stabil for al efterf√∏lgende modellering.

```{r}
dup_ids <- baseline |> count(kamp_id) |> filter(n > 1)
cat("--- BASELINE QA: DUPLIKAT-TJEK ---\n")
cat("Antal kamp_id med dubletter: ", nrow(dup_ids), "\n", sep = "")
if (nrow(dup_ids) > 0) {
  baseline <- dedup_1row_by_id(baseline, "kamp_id")
  stopifnot(nrow(baseline) == n_distinct(baseline$kamp_id))
  cat("‚úÖ Baseline deduplikeret (1 r√¶kke pr kamp_id)\n\n")
} else {
  cat("‚úÖ Ingen dubletter fundet\n\n")
}
```

### Sikring af kamp_tid

Her tjekkes det, om kamp_tid findes i baseline. Hvis den mangler, hentes tidspunktet fra et supplerende baseline-datas√¶t og joines ind, s√• hver kamp f√•r et entydigt kickoff-tidspunkt. Det er n√∏dvendigt for korrekt feature-opbygning og senere modellering.

```{r}
# 3B) Sikr kamp_tid (hvis baseline ikke har den)
if (!("kamp_tid" %in% names(baseline))) {
  cat("‚ö†Ô∏è baseline_azure.rds mangler 'kamp_tid' ‚Äî henter fra future_baseline_feature_azure.rds\n")
  fb_file <- file.path(baseline_dir, "future_baseline_feature_azure.rds")
  stopifnot(file.exists(fb_file))
  
  fb <- readRDS(fb_file) |>
    mutate(
      kamp_id   = as.character(kamp_id),
      kamp_dato = as.Date(kamp_dato)
    ) |>
    select(kamp_id, kamp_tid)
  
  fb <- dedup_1row_by_id(fb, "kamp_id")
  baseline <- baseline |> left_join(fb, by = "kamp_id")
  cat("‚úî kamp_tid joinet ind\n\n")
  rm(fb)
}
```

### Oprettelse af kamp_time_h

Her standardiseres kamp_tid til et ensartet tidsformat og oms√¶ttes til en numerisk timev√¶rdi. Det g√∏r kampstart sammenlignelig p√• tv√¶rs af kampe og klar til brug som forklarende variabel i modellerne.

```{r}
# 3C) Opret kamp_time_h
baseline <- baseline |>
  mutate(
    kamp_tid_chr = str_trim(as.character(kamp_tid)),
    kamp_tid_chr = if_else(str_detect(kamp_tid_chr, "^\\d{1,2}:\\d{2}$"), paste0(kamp_tid_chr, ":00"), kamp_tid_chr),
    kamp_time_h  = time_chr_to_hour(kamp_tid_chr)
  )

cat("Kamp-r√¶kker uden parsebar kamp_time_h: ", sum(is.na(baseline$kamp_time_h)), "\n\n", sep = "")

```

### Features

#### Helligdage

Her kobles officielle helligdage p√• kampdatoen, og der oprettes en bin√¶r indikator for, om kampen afvikles p√• en helligdag. Form√•let er at indfange effekten af fridage, som kan p√•virke tilskuertallet gennem √¶ndret tilg√¶ngelighed og adf√¶rd.

```{r}

hellig_raw <- safe_dbReadTable(con, "PBA01_Raw", "dim_helligdage_dkk_raw")
stopifnot(all(c("dato","helligdag_navn") %in% names(hellig_raw)))

hellig_min <- hellig_raw |>
  mutate(hellig_dato = as.Date(dato)) |>
  filter(!is.na(hellig_dato)) |>
  distinct(hellig_dato) |>
  transmute(hellig_dato, er_helligdag = 1L)

baseline <- baseline |>
  left_join(hellig_min, by = c("kamp_dato" = "hellig_dato")) |>
  mutate(er_helligdag = if_else(is.na(er_helligdag), 0L, er_helligdag))

cat("Helligdage joinet ‚úÖ\n\n")

```

#### H√•ndboldkamp samme dag (SAH)

Her identificeres dage med SAH-h√•ndboldkampe og der oprettes b√•de en indikator for om der spilles h√•ndbold samme dag samt et antal kampe. Variablen bruges til at fange potentiel konkurrence om publikums opm√¶rksomhed p√• kampdagen.

```{r}
sah_raw <- safe_dbReadTable(con, "PBA02_Clean", "fact_h√•ndboldkampe_SAH_clean")
stopifnot(all(c("kamp_dato","kamp_tid","Event") %in% names(sah_raw)))

sah_min <- sah_raw |>
  mutate(sah_dato = as.Date(kamp_dato)) |>
  filter(!is.na(sah_dato)) |>
  group_by(sah_dato) |>
  summarise(
    er_h√•ndboldkamp_SAH = 1L,
    antal_h√•ndboldkampe = n(),
    .groups = "drop"
  )

baseline <- baseline |>
  left_join(sah_min, by = c("kamp_dato" = "sah_dato")) |>
  mutate(
    er_h√•ndboldkamp_SAH = if_else(is.na(er_h√•ndboldkamp_SAH), 0L, er_h√•ndboldkamp_SAH),
    antal_h√•ndboldkampe = if_else(is.na(antal_h√•ndboldkampe), 0L, antal_h√•ndboldkampe)
  )

cat("H√•ndbold SAH joinet ‚úÖ\n\n")


```

#### Befolkning

Her kobles Viborgs befolkningstal p√• kampene ved at anvende det senest kendte kvartalstal f√∏r kampdatoen. Form√•let er at give modellen et strukturelt m√•l for det potentielle publikum uden at introducere fremtidsinformation.

```{r}


bef_raw <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_Viborg_befolkning_join_ready")
stopifnot(all(c("k√∏n","civilstand","dato","befolkningstal") %in% names(bef_raw)))

bef_all <- bef_raw |>
  mutate(
    k√∏n = str_to_lower(str_trim(as.character(k√∏n))),
    civilstand = str_to_lower(str_trim(as.character(civilstand))),
    dato = as.Date(dato),
    befolkningstal = as.numeric(befolkningstal)
  ) |>
  filter(
    !is.na(dato),
    !is.na(befolkningstal),
    k√∏n %in% c("i alt", "alt"),
    civilstand %in% c("i alt", "alt")
  ) |>
  distinct(dato, .keep_all = TRUE) |>
  arrange(dato) |>
  transmute(bef_dato = dato, befolkningstal = befolkningstal)

baseline_bef <- baseline |>
  transmute(kamp_id, kamp_dato) |>
  left_join(bef_all, join_by(closest(kamp_dato >= bef_dato)))

baseline <- baseline |>
  left_join(baseline_bef |> select(kamp_id, befolkningstal), by = "kamp_id")

cat("Befolkning joinet ‚úÖ  NA: ", sum(is.na(baseline$befolkningstal)), "\n\n", sep = "")

```

#### Vejr

Her kobles vejrobservationer p√• hver kamp ved at v√¶lge den observation, der ligger t√¶ttest p√• kampstart blandt faste tidspunkter p√• dagen. Hvis en pr√¶cis match ikke findes, anvendes et simpelt fallback fra samme dato. Samtidig markeres manglende eller ikke-observerbare vejrdata eksplicit, s√• modellen kan h√•ndtere usikkerhed uden at miste observationer.

```{r}

cat("--- FEATURE: VEJR (n√¶rmeste blandt 08/11/14/17) ---\n")

vejr_sql <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_vejr_join_ready")
stopifnot(all(c("obs_dato","tid","vejrkode","vejrbeskrivelse") %in% names(vejr_sql)))

vejr_grid_tider_h <- c(8L, 11L, 14L, 17L)

vejr_pre <- vejr_sql |>
  mutate(
    vejr_dato = as_date_safely(obs_dato),
    vejr_tid_chr = str_trim(as.character(tid)),
    vejr_tid_chr = if_else(str_detect(vejr_tid_chr, "^\\d{1,2}:\\d{2}$"), paste0(vejr_tid_chr, ":00"), vejr_tid_chr),
    vejr_time_h = time_chr_to_hour(vejr_tid_chr),
    vejrkode = suppressWarnings(as.integer(vejrkode)),
    vejrbeskrivelse = as.character(vejrbeskrivelse)
  ) |>
  filter(!is.na(vejr_dato), !is.na(vejr_time_h))

vejr_grid <- vejr_pre |>
  filter(vejr_time_h %in% vejr_grid_tider_h) |>
  group_by(vejr_dato, vejr_time_h) |>
  slice(1) |>
  ungroup()

vejr_fallback_1 <- vejr_pre |>
  arrange(vejr_dato, vejr_time_h) |>
  group_by(vejr_dato) |>
  slice(1) |>
  ungroup()

baseline_key <- baseline |>
  transmute(kamp_id, kamp_dato, kamp_time_h)

kandidater_vejr <- baseline_key |>
  filter(!is.na(kamp_dato), !is.na(kamp_time_h)) |>
  inner_join(
    vejr_grid |> select(vejr_dato, vejr_time_h, vejrkode, vejrbeskrivelse),
    by = c("kamp_dato" = "vejr_dato")
  ) |>
  mutate(dist_hours_to_kickoff = abs(kamp_time_h - vejr_time_h)) |>
  group_by(kamp_id) |>
  arrange(dist_hours_to_kickoff, .by_group = TRUE) |>
  slice(1) |>
  ungroup() |>
  transmute(
    kamp_id,
    vejr_tid_h = vejr_time_h,
    vejrkode,
    vejrbeskrivelse,
    dist_hours_to_kickoff,
    vejr_match_type = "grid_nearest"
  )

fallback_vejr <- baseline_key |>
  anti_join(kandidater_vejr |> select(kamp_id), by = "kamp_id") |>
  left_join(
    vejr_fallback_1 |> select(vejr_dato, vejr_time_h, vejrkode, vejrbeskrivelse),
    by = c("kamp_dato" = "vejr_dato")
  ) |>
  transmute(
    kamp_id,
    vejr_tid_h = vejr_time_h,
    vejrkode,
    vejrbeskrivelse,
    dist_hours_to_kickoff = NA_integer_,
    vejr_match_type = "fallback_dato"
  )

vejr_match <- bind_rows(kandidater_vejr, fallback_vejr)
stopifnot(sum(duplicated(vejr_match$kamp_id)) == 0)

baseline <- baseline |> left_join(vejr_match, by = "kamp_id")

cat("Vejr joinet ‚úÖ  NA vejrkode: ", sum(is.na(baseline$vejrkode)),
    "  vejrkode=0: ", sum(baseline$vejrkode == 0, na.rm = TRUE), "\n", sep = "")

baseline <- baseline |>
  mutate(
    vejr_mangler_obs       = if_else(is.na(vejrkode), 1L, 0L),
    vejr_ikke_observerbar  = if_else(!is.na(vejrkode) & vejrkode == 0, 1L, 0L),
    vejr_mangler_info      = if_else(vejr_mangler_obs == 1L | vejr_ikke_observerbar == 1L, 1L, 0L),
    
    vejrkode_model         = if_else(vejr_mangler_info == 1L, -1L, as.integer(vejrkode)),
    vejrbeskrivelse_model  = case_when(
      vejr_mangler_obs == 1L      ~ "UKENDT",
      vejr_ikke_observerbar == 1L ~ "IKKE_OBSERVERBAR",
      TRUE                        ~ as.character(vejrbeskrivelse)
    ),
    vejr_tid_h_model       = if_else(vejr_mangler_info == 1L, -1L, as.integer(vejr_tid_h)),
    dist_hours_to_kickoff_model = if_else(vejr_mangler_info == 1L, -1L, as.integer(dist_hours_to_kickoff)),
    vejr_match_type_model  = if_else(is.na(vejr_match_type), "NO_WEATHER", as.character(vejr_match_type))
  )

cat("VEJR: mangler_obs=", sum(baseline$vejr_mangler_obs == 1L, na.rm = TRUE),
    "  ikke_observerbar=", sum(baseline$vejr_ikke_observerbar == 1L, na.rm = TRUE),
    "  mangler_info=", sum(baseline$vejr_mangler_info == 1L, na.rm = TRUE), "\n\n", sep = "")


```

#### Temperatur

Her kobles temperatur p√• hver kamp ved at v√¶lge den seneste observerede temperatur f√∏r kickoff samme dag. Der anvendes en fast bagud-trappe i tid, s√• temperaturen hentes fra kl. 18, 15, 12 eller 9 afh√¶ngigt af kampstart. Hvis ingen observation findes f√∏r kickoff, markeres dette eksplicit, s√• datatab undg√•s og usikkerhed h√•ndteres systematisk i modellen.

```{r}


cat("--- FEATURE: TEMPERATUR (bagud-trappe 18‚Üí15‚Üí12‚Üí09) ---\n")

temp_sql <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_temperatur_join_ready")
stopifnot(all(c("obs_dato","tid","temperatur") %in% names(temp_sql)))

temp_tider_h <- c(9L, 12L, 15L, 18L)

temp_grid <- temp_sql |>
  mutate(
    temp_dato = as_date_safely(obs_dato),
    temp_tid_chr = str_trim(as.character(tid)),
    temp_tid_chr = if_else(str_detect(temp_tid_chr, "^\\d{1,2}:\\d{2}$"), paste0(temp_tid_chr, ":00"), temp_tid_chr),
    temp_time_h = time_chr_to_hour(temp_tid_chr),
    temperatur = suppressWarnings(as.numeric(temperatur))
  ) |>
  filter(!is.na(temp_dato), !is.na(temp_time_h), temp_time_h %in% temp_tider_h) |>
  group_by(temp_dato, temp_time_h) |>
  slice(1) |>
  ungroup()

temp_kandidater <- baseline_key |>
  inner_join(
    temp_grid |> select(temp_dato, temp_time_h, temperatur),
    by = c("kamp_dato" = "temp_dato")
  ) |>
  filter(!is.na(kamp_time_h), temp_time_h <= kamp_time_h) |>
  mutate(temp_dist_hours_to_kickoff = kamp_time_h - temp_time_h)

temp_valgt <- temp_kandidater |>
  group_by(kamp_id) |>
  arrange(desc(temp_time_h), .by_group = TRUE) |>
  slice(1) |>
  ungroup() |>
  transmute(
    kamp_id,
    temp_tid_h = temp_time_h,
    temperatur,
    temp_dist_hours_to_kickoff = as.integer(temp_dist_hours_to_kickoff),
    temp_match_type = "step_back_same_day"
  )

temp_mangler <- baseline_key |>
  anti_join(temp_valgt |> select(kamp_id), by = "kamp_id") |>
  transmute(
    kamp_id,
    temp_tid_h = NA_integer_,
    temperatur = NA_real_,
    temp_dist_hours_to_kickoff = NA_integer_,
    temp_match_type = case_when(
      is.na(kamp_time_h) ~ "NO_KICKOFF_TIME",
      TRUE               ~ "NO_TEMP_BEFORE_KICKOFF"
    )
  )

temp_match <- bind_rows(temp_valgt, temp_mangler)
stopifnot(sum(duplicated(temp_match$kamp_id)) == 0)

baseline <- baseline |>
  left_join(temp_match, by = "kamp_id") |>
  mutate(
    temp_mangler_obs            = if_else(is.na(temperatur), 1L, 0L),
    temperatur_model            = as.numeric(temperatur),
    temp_tid_h_model            = as.integer(temp_tid_h),
    temp_dist_hours_to_kickoff_model = as.integer(temp_dist_hours_to_kickoff),
    temp_match_type_model       = if_else(is.na(temp_match_type), "NO_TEMP", as.character(temp_match_type))
  )

cat("Temperatur joinet ‚úÖ  NA temperatur: ", sum(is.na(baseline$temperatur)),
    "  step_back_same_day: ", sum(baseline$temp_match_type == "step_back_same_day", na.rm = TRUE),
    "  NO_KICKOFF_TIME: ", sum(baseline$temp_match_type == "NO_KICKOFF_TIME", na.rm = TRUE),
    "  NO_TEMP_BEFORE_KICKOFF: ", sum(baseline$temp_match_type == "NO_TEMP_BEFORE_KICKOFF", na.rm = TRUE),
    "\n\n", sep = "")

```

#### Billetsalg

Her indl√¶ses billetsalgsdata fra Azure med fokus p√• D10-horisonten. For hver kamp reduceres data til √©n r√¶kke ved at v√¶lge det h√∏jeste registrerede billetsalg, s√• hvert kamp_id kun optr√¶der √©n gang og datas√¶ttet er konsistent til videre analyse og modellering.

```{r}

vff_billetsalg <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_VFF_Billetsalg_join_ready") |>
  mutate(
    kamp_id       = as.character(kamp_id),
    d10_tilskuere = as.numeric(d10_tilskuere)
  )

stopifnot(all(c("kamp_id","d10_tilskuere") %in% names(vff_billetsalg)))
cat("Billetsalg hentet ‚úÖ  R√¶kker: ", nrow(vff_billetsalg), "\n\n", sep = "")

vff_billetsalg_1row <- vff_billetsalg |>
  group_by(kamp_id) |>
  summarise(
    d10_tilskuere = suppressWarnings(max(d10_tilskuere, na.rm = TRUE)),
    .groups = "drop"
  ) |>
  mutate(
    d10_tilskuere = if_else(is.infinite(d10_tilskuere), NA_real_, d10_tilskuere)
  )

cat("Billetsalg dedup (1 r√¶kke pr kamp_id) ‚úÖ\n\n")


```

### D10-datas√¶t og analysegrundlag

Her samles baseline og D10-billetsalg til √©t samlet datas√¶t. Der k√∏res et kort kvalitetstjek for at f√• overblik over mangler i n√∏glev√¶rdier og features. Til sidst filtreres datas√¶ttet ned til de observationer, der er fuldt anvendelige, og `analysis_df_d10` klarg√∏res som endeligt input til modellering.

```{r}

tickets_feats_d10 <- vff_billetsalg_1row |>
  transmute(
    kamp_id,
    billetter_d10 = d10_tilskuere
  )

d10_dataset <- baseline |> left_join(tickets_feats_d10, by = "kamp_id")

cat("D10 join ‚úÖ  R√¶kker: ", nrow(d10_dataset),
    "  Unikke kamp_id: ", n_distinct(d10_dataset$kamp_id), "\n\n", sep = "")

diag_d10 <- d10_dataset |>
  summarise(
    r√¶kker_total = n(),
    unikke_kamp_id = n_distinct(kamp_id),
    uden_d10 = sum(is.na(billetter_d10)),
    uden_tilskuere = sum(is.na(tilskuere)),
    uden_time_h = sum(is.na(kamp_time_h)),
    uden_bef = sum(is.na(befolkningstal)),
    uden_vejrkode_raw = sum(is.na(vejrkode)),
    vejrkode0_raw = sum(vejrkode == 0, na.rm = TRUE),
    uden_temp_raw = sum(is.na(temperatur)),
    vejr_grid_match = sum(vejr_match_type == "grid_nearest", na.rm = TRUE),
    vejr_fallback = sum(vejr_match_type == "fallback_dato", na.rm = TRUE),
    temp_stepback = sum(temp_match_type == "step_back_same_day", na.rm = TRUE),
    temp_nomatch = sum(temp_match_type == "NO_TEMP_BEFORE_KICKOFF", na.rm = TRUE)
  )
print(diag_d10)

analysis_df_d10 <- d10_dataset |>
  filter(
    !is.na(billetter_d10),
    !is.na(kamp_time_h),
    !is.na(tilskuere),
    !is.na(s√¶son),
    !is.na(runde)
  ) |>
  mutate(
    vejrkode_model = if_else(is.na(vejrkode_model), -1L, vejrkode_model),
    vejrbeskrivelse_model = if_else(is.na(vejrbeskrivelse_model), "UKENDT", vejrbeskrivelse_model),
    vejr_tid_h_model = if_else(is.na(vejr_tid_h_model), -1L, vejr_tid_h_model),
    dist_hours_to_kickoff_model = if_else(is.na(dist_hours_to_kickoff_model), -1L, dist_hours_to_kickoff_model),
    vejr_match_type_model = if_else(is.na(vejr_match_type_model), "NO_WEATHER", vejr_match_type_model),
    
    temperatur_model = as.numeric(temperatur_model),
    temp_tid_h_model = as.integer(temp_tid_h_model),
    temp_dist_hours_to_kickoff_model = as.integer(temp_dist_hours_to_kickoff_model),
    temp_match_type_model = if_else(is.na(temp_match_type_model), "NO_TEMP", as.character(temp_match_type_model)),
    
    billetter_d10 = as.numeric(billetter_d10)
  )

cat("analysis_df_d10 klar ‚úÖ  R√¶kker: ", nrow(analysis_df_d10), "\n\n", sep = "")

# (valgfrit) manuel check ‚Äî sl√• til hvis du vil
# View(analysis_df_d10)
# glimpse(analysis_df_d10)
```

### Testpipeline for D10-modellen

Her opstilles en enkel nulmodel baseret p√• s√¶son, runde, kampstartstidspunkt og billetsalg ti dage f√∏r kamp. Derefter testes ekstra variable √©n ad gangen under samme datagrundlag, s√• sammenligningen er fair og effekten kan vurderes isoleret.

#### Hj√¶lpefunktioner til modeltest

Disse funktioner bruges til at udtr√¶kke p-v√¶rdier fra modellerne. Den ene henter p-v√¶rdien fra en ANOVA-sammenligning mellem to modeller, og den anden henter p-v√¶rdien for en specifik variabel direkte fra modelkoefficienterne. Form√•let er at kunne vurdere statistisk betydning p√• en ensartet og automatiseret m√•de.

```{r}

safe_p_from_anova <- function(a) suppressWarnings(as.numeric(a[nrow(a), ncol(a)]))

coef_p <- function(mod, term) {
  sm <- summary(mod)
  cf <- sm$coefficients
  if (!(term %in% rownames(cf))) return(NA_real_)
  suppressWarnings(as.numeric(cf[term, "Pr(>|t|)"]))
}

```

#### Enkelt variabeltest mod nulmodel

Denne funktion tester √©n ekstra variabel ad gangen mod nulmodellen. Den sikrer, at begge modeller estimeres p√• pr√¶cis samme datas√¶t, s√• sammenligningen er fair. Resultatet opsummerer antal observationer, p-v√¶rdier og √¶ndring i AIC, hvilket g√∏r det muligt systematisk at vurdere, om variablen bidrager med reel forklaringskraft.

```{r}

safe_p_from_anova <- function(a) suppressWarnings(as.numeric(a[nrow(a), ncol(a)]))

coef_p <- function(mod, term) {
  sm <- summary(mod)
  cf <- sm$coefficients
  if (!(term %in% rownames(cf))) return(NA_real_)
  suppressWarnings(as.numeric(cf[term, "Pr(>|t|)"]))
}

run_single_test <- function(df_base, extra_var, label = extra_var) {
  need_cols <- c("tilskuere","s√¶son","runde","kamp_time_h","billetter_d10", extra_var)
  miss <- setdiff(need_cols, names(df_base))
  if (length(miss) > 0) stop("‚ùå Mangler kolonner i df_base: ", paste(miss, collapse = ", "))
  
  df_common <- df_base |>
    dplyr::transmute(
      tilskuere     = as.numeric(tilskuere),
      s√¶son         = as.factor(s√¶son),
      runde         = as.integer(runde),
      kamp_time_h   = as.integer(kamp_time_h),
      billetter_d10 = as.numeric(billetter_d10),
      extra         = .data[[extra_var]]
    ) |>
    dplyr::filter(
      !is.na(tilskuere),
      !is.na(s√¶son),
      !is.na(runde),
      !is.na(kamp_time_h),
      !is.na(billetter_d10),
      !is.na(extra)
    )
  
  m0 <- lm(tilskuere ~ s√¶son + runde + kamp_time_h + billetter_d10, data = df_common)
  m1 <- lm(tilskuere ~ s√¶son + runde + kamp_time_h + billetter_d10 + extra, data = df_common)
  a  <- anova(m0, m1)
  
  out <- tibble::tibble(
    variabel       = label,
    n_test         = nrow(df_common),
    p_koefficient  = coef_p(m1, "extra"),
    p_anova        = safe_p_from_anova(a),
    delta_AIC      = as.numeric(AIC(m1) - AIC(m0)),
    AIC_nul        = as.numeric(AIC(m0)),
    AIC_plus       = as.numeric(AIC(m1))
  )
  
  list(out = out, df_common = df_common, m0 = m0, m1 = m1, anova = a)
}

```

### Klarg√∏ring af D10-basisdatas√¶t

Her udv√¶lges og typesikres de variable, der indg√•r i D10-analyserne. Datas√¶ttet reduceres til √©n konsistent struktur med b√•de basisforklarende variable og potentielle testvariable. Til sidst filtreres der til et rent nulmodel-datas√¶t uden manglende v√¶rdier, som bruges som f√¶lles udgangspunkt for alle efterf√∏lgende model- og variabeltests.

```{r}

df_d10_base <- analysis_df_d10 |>
  dplyr::transmute(
    kamp_id       = as.character(kamp_id),
    tilskuere     = as.numeric(tilskuere),
    s√¶son         = as.factor(s√¶son),
    runde         = as.integer(runde),
    kamp_time_h   = as.integer(kamp_time_h),
    billetter_d10 = as.numeric(billetter_d10),
    
    er_helligdag        = as.integer(er_helligdag),
    er_h√•ndboldkamp_SAH = as.integer(er_h√•ndboldkamp_SAH),
    temperatur_model    = as.numeric(temperatur_model),
    vejr_mangler_info   = as.integer(vejr_mangler_info),
    befolkningstal      = as.numeric(befolkningstal)
  )

df_d10_0 <- df_d10_base |>
  dplyr::filter(
    !is.na(tilskuere),
    !is.na(s√¶son),
    !is.na(runde),
    !is.na(kamp_time_h),
    !is.na(billetter_d10)
  )

```

### D10 nulmodel

Her estimeres den grundl√¶ggende D10-model, som forklarer det endelige tilskuertal ud fra s√¶son, runde, kampstartstidspunkt og billetsalg ti dage f√∏r kamp. Denne model fungerer som reference, n√•r ekstra variable efterf√∏lgende vurderes.

```{r}

cat("D10 base datas√¶t klar ‚úÖ  N=", nrow(df_d10_0), "\n", sep = "")

m_d10_0 <- lm(tilskuere ~ s√¶son + runde + kamp_time_h + billetter_d10, data = df_d10_0)

```

### Test af ekstra forklarende variable

Her udvides D10-nulmodellen √©n variabel ad gangen. For hver test sammenlignes nulmodellen med en udvidet model p√• samme datagrundlag, s√• effekten kan vurderes fair via ANOVA og √¶ndring i AIC. Form√•let er at afg√∏re, om helligdage, h√•ndboldkampe, temperatur, manglende vejrdata eller sportslig placering giver en reel forbedring af modellen i forhold til den simple baseline.

```{r}

cat("\n====================================\n")
cat("MODEL_D10_00 ‚Äî NULMODEL (D10)\n")
cat("====================================\n")
print(summary(m_d10_0))
cat("\nAIC nulmodel:", as.numeric(AIC(m_d10_0)), "\n\n")

results_list <- list()

cat("====================================\n")
cat("MODEL_D10_01 ‚Äî TEST: er_helligdag\n")
cat("====================================\n")
t_holiday <- run_single_test(df_d10_base, extra_var = "er_helligdag", label = "er_helligdag")
print(t_holiday$anova)
results_list[["er_helligdag"]] <- t_holiday$out

cat("\n====================================\n")
cat("MODEL_D10_02 ‚Äî TEST: er_h√•ndboldkamp_SAH\n")
cat("====================================\n")
t_sah <- run_single_test(df_d10_base, extra_var = "er_h√•ndboldkamp_SAH", label = "er_h√•ndboldkamp_SAH")
print(t_sah$anova)
results_list[["er_h√•ndboldkamp_SAH"]] <- t_sah$out

cat("\n====================================\n")
cat("MODEL_D10_03 ‚Äî TEST: temperatur_model\n")
cat("====================================\n")
t_temp <- run_single_test(df_d10_base, extra_var = "temperatur_model", label = "temperatur_model")
print(t_temp$anova)
results_list[["temperatur_model"]] <- t_temp$out

cat("\n====================================\n")
cat("MODEL_D10_04 ‚Äî TEST: vejr_mangler_info\n")
cat("====================================\n")
t_weather_miss <- run_single_test(df_d10_base, extra_var = "vejr_mangler_info", label = "vejr_mangler_info")
print(t_weather_miss$anova)
results_list[["vejr_mangler_info"]] <- t_weather_miss$out



```

D10-nulmodellen er estimeret med s√¶son, runde, kampstartstidspunkt og billetsalg ti dage f√∏r kamp som forklarende variable. Modellen forklarer en meget stor andel af variationen i tilskuertallet med en justeret forklaringsgrad p√• 0,924 og en residual standard error p√• ca. 511 tilskuere. Samlet set er modellen st√¶rkt signifikant, og s√¶rligt billetter_d10 fremst√•r som den klart dominerende forklarende variabel med en h√∏j og meget signifikant effekt.

Kampstartstidspunkt har ligeledes en signifikant positiv effekt, mens runde ikke bidrager signifikant i denne specifikation. Flere s√¶son-dummyer er signifikante, hvilket indikerer strukturelle forskelle i tilskuerniveau mellem s√¶soner, som ikke alene kan forklares af de √∏vrige variable.

P√• baggrund af nulmodellen er der gennemf√∏rt enkeltvariabeltests, hvor hver ekstra variabel er tilf√∏jet √©n ad gangen og evalueret via ANOVA. Resultaterne viser, at er_helligdag, er_h√•ndboldkamp_SAH, temperatur_model og vejr_mangler_info ikke bidrager med en signifikant reduktion i residual sum of squares. For samtlige tests er p-v√¶rdierne h√∏je, og der observeres ingen meningsfuld forbedring af modellens forklaringskraft.

Samlet set indikerer resultaterne, at nulmodellen allerede indfanger de v√¶sentligste systematiske variationer i D10-horisonten, og at de testede ekstra variable ikke tilf√∏rer selvst√¶ndig forklaringsv√¶rdi. P√• denne baggrund frav√¶lges disse variable i den videre modellering.

#### Test af placering f√∏r kamp

Her tilf√∏jes holdets placering f√∏r kampen til D10-nulmodellen. Placeringen joines p√• kamp_id og reduceres til √©n observation pr. kamp, hvorefter modellen sammenlignes med nulmodellen p√• samme datas√¶t. Form√•let er at vurdere, om den sportslige situation f√∏r kickoff bidrager med forklaringskraft ud over billetsalg og kampens rammer.

```{r}
cat("\n====================================\n")
cat("MODEL_D10_05 ‚Äî TEST: placering_f√∏r_kamp\n")
cat("====================================\n")
plac_raw <- safe_dbReadTable(con, "PBA02_Clean", "fact_vff_rundeplaceringer_clean") |>
  dplyr::mutate(kamp_id = as.character(kamp_id))

need_cols <- c("kamp_id","placering_f√∏r_kamp")
miss <- setdiff(need_cols, names(plac_raw))
if (length(miss) > 0) stop("‚ùå Mangler kolonner i placeringstabellen: ", paste(miss, collapse = ", "))

plac_1row <- plac_raw |>
  dplyr::transmute(
    kamp_id = as.character(kamp_id),
    placering_f√∏r_kamp = suppressWarnings(as.integer(placering_f√∏r_kamp))
  ) |>
  dplyr::arrange(kamp_id) |>
  dplyr::group_by(kamp_id) |>
  dplyr::slice(1) |>
  dplyr::ungroup()

df_d10_pos <- df_d10_base |>
  dplyr::left_join(plac_1row, by = "kamp_id")

t_pos <- run_single_test(df_d10_pos, extra_var = "placering_f√∏r_kamp", label = "placering_f√∏r_kamp")
print(t_pos$anova)
results_list[["placering_f√∏r_kamp"]] <- t_pos$out

```

Placering f√∏r kamp er testet som ekstra forklarende variabel i D10-modellen ved at blive tilf√∏jet nulmodellen best√•ende af s√¶son, runde, kampstartstidspunkt og billetsalg ti dage f√∏r kamp.

ANOVA-testen viser, at variablen reducerer residual sum of squares marginalt, men effekten er ikke statistisk signifikant. Den observerede F-statistik p√• 2,18 svarer til en p-v√¶rdi p√• 0,141, hvilket ligger klart over det s√¶dvanlige signifikansniveau.

Resultatet indikerer, at placering f√∏r kamp ikke tilf√∏rer selvst√¶ndig forklaringskraft, n√•r der allerede kontrolleres for s√¶sonstruktur og det observerede billetsalg p√• D10-horisonten. Variablen frav√¶lges derfor i den videre modellering.

#### Test af befolkningstal i D10-modellen (cost‚Äìbenefit)

Befolkningstal testes her som potentiel ekstra forklarende variabel i D10-modellen. Analysen kombinerer en klassisk enkeltvariabeltest med en eksplicit cost‚Äìbenefit-vurdering, hvor b√•de statistisk effekt og tab af observationer indg√•r. Ud over ANOVA-resultatet evalueres variablen ogs√• via out-of-sample performance p√• et f√¶lles datas√¶t for at vurdere, om en eventuel effekt er robust og operationelt relevant.

```{r}

cat("\n====================================\n")
cat("MODEL_D10_06 ‚Äî TEST: befolkningstal (cost vs benefit)\n")
cat("====================================\n")

df_d10_full <- df_d10_base |>
  dplyr::filter(
    !is.na(tilskuere),
    !is.na(s√¶son),
    !is.na(runde),
    !is.na(kamp_time_h),
    !is.na(billetter_d10)
  )

df_d10_common_pop <- df_d10_base |>
  dplyr::filter(
    !is.na(tilskuere),
    !is.na(s√¶son),
    !is.na(runde),
    !is.na(kamp_time_h),
    !is.na(billetter_d10),
    !is.na(befolkningstal)
  )

cat("Data-omkostning:\n")
cat("FULL N=", nrow(df_d10_full), "\n", sep = "")
cat("COMMON N=", nrow(df_d10_common_pop), "\n", sep = "")
cat("Mistede r√¶kker=", nrow(df_d10_full) - nrow(df_d10_common_pop), "\n\n", sep = "")

t_pop <- run_single_test(df_d10_base, extra_var = "befolkningstal", label = "befolkningstal")
print(t_pop$anova)
results_list[["befolkningstal"]] <- t_pop$out

set.seed(42)
split_common <- rsample::initial_split(df_d10_common_pop, prop = 0.80)
train_common <- rsample::training(split_common)
test_common  <- rsample::testing(split_common)

m_no_pop_common <- lm(tilskuere ~ s√¶son + runde + kamp_time_h + billetter_d10, data = train_common)
m_pop_common    <- lm(tilskuere ~ s√¶son + runde + kamp_time_h + billetter_d10 + befolkningstal, data = train_common)

pred_ref <- predict(m_no_pop_common, newdata = test_common)
pred_pop <- predict(m_pop_common,    newdata = test_common)

cat("\nOut-of-sample (COMMON)\n")
cat("Uden befolkning: RMSE=", rmse_vec(test_common$tilskuere, pred_ref),
    " MAE=", mae_vec(test_common$tilskuere, pred_ref),
    " R2=", r2_vec(test_common$tilskuere, pred_ref), "\n", sep = "")
cat("Med  befolkning: RMSE=", rmse_vec(test_common$tilskuere, pred_pop),
    " MAE=", mae_vec(test_common$tilskuere, pred_pop),
    " R2=", r2_vec(test_common$tilskuere, pred_pop), "\n\n", sep = "")

```

Inklusion af befolkningstal i D10-modellen medf√∏rer en betydelig data-omkostning, idet antallet af observationer reduceres fra 254 til 131. Dette svarer til et tab p√• n√¶sten halvdelen af datagrundlaget.

Den statistiske test viser, at befolkningstal ikke har nogen signifikant effekt p√• tilskuertallet. ANOVA-testen giver en meget lav F-v√¶rdi og en h√∏j p-v√¶rdi, hvilket indikerer, at variablen ikke bidrager med selvst√¶ndig forklaringskraft, n√•r der allerede kontrolleres for s√¶son, runde, kampstartstidspunkt og billetsalg ti dage f√∏r kamp.

Out-of-sample evalueringen p√• det f√¶lles datas√¶t underst√∏tter dette resultat. Modellen med befolkningstal pr√¶sterer d√•rligere end reference-modellen uden variablen, med h√∏jere RMSE og MAE samt lavere R¬≤.

Samlet set overstiger omkostningen i tabt data klart den potentielle gevinst, og befolkningstal vurderes derfor ikke at v√¶re en hensigtsm√¶ssig variabel i D10-modellen.

```{r}
variabeltest_oversigt_d10 <- dplyr::bind_rows(results_list) |>
  dplyr::mutate(
    beslutning = dplyr::case_when(
      is.na(p_anova) ~ "Ikke testet",
      p_anova < 0.05 & delta_AIC < 0 ~ "Behold",
      TRUE ~ "Forkast"
    ),
    begrundelse = dplyr::case_when(
      variabel == "befolkningstal" ~ "Ingen robust effekt og stor data-omkostning",
      beslutning == "Behold" ~ "Signifikant forbedring og lavere AIC",
      TRUE ~ "Ingen signifikant forbedring eller AIC bliver d√•rligere"
    )
  ) |>
  dplyr::select(variabel, n_test, p_koefficient, p_anova, delta_AIC, beslutning, begrundelse) |>
  dplyr::arrange(delta_AIC)

cat("====================================\n")
cat("VARIABELTEST-OVERSIGT (D10)\n")
cat("====================================\n")
print(variabeltest_oversigt_d10)
cat("\n")
```

Samtlige testede ekstra variable forkastes i D10-modellen. Ingen af variablerne udviser statistisk signifikant effekt, og ingen bidrager med en konsistent forbedring af modelkvaliteten m√•lt ved AIC.

Flere variable medf√∏rer desuden en forv√¶rring af modellens informationskriterium, og i tilf√¶ldet **befolkningstal** er der samtidig en betydelig data-omkostning i form af et stort tab af observationer, uden tilsvarende gevinst i forklarings- eller pr√¶diktiv styrke.

Resultaterne underst√∏tter, at D10-nulmodellen allerede indfanger de v√¶sentligste forklaringsmekanismer gennem s√¶sonstruktur, kampkarakteristika og observeret billetsalg. Af hensyn til modelrobusthed, generaliserbarhed og operationel anvendelighed fastholdes derfor en **lean D10-model uden de testede ekstra variable**.

```{r}
cat("\n====================================\n")
cat("MODEL_D10_06 ‚Äî TEST: befolkningstal (cost vs benefit)\n")
cat("====================================\n")

df_d10_full <- df_d10_base |>
  dplyr::filter(
    !is.na(tilskuere),
    !is.na(s√¶son),
    !is.na(runde),
    !is.na(kamp_time_h),
    !is.na(billetter_d10)
  )

df_d10_common_pop <- df_d10_base |>
  dplyr::filter(
    !is.na(tilskuere),
    !is.na(s√¶son),
    !is.na(runde),
    !is.na(kamp_time_h),
    !is.na(billetter_d10),
    !is.na(befolkningstal)
  )

cat("Data-omkostning:\n")
cat("FULL N=", nrow(df_d10_full), "\n", sep = "")
cat("COMMON N=", nrow(df_d10_common_pop), "\n", sep = "")
cat("Mistede r√¶kker=", nrow(df_d10_full) - nrow(df_d10_common_pop), "\n\n", sep = "")

```

```{r}

t_pop <- run_single_test(df_d10_base, extra_var = "befolkningstal", label = "befolkningstal")
print(t_pop$anova)
results_list[["befolkningstal"]] <- t_pop$out

set.seed(42)
split_common <- rsample::initial_split(df_d10_common_pop, prop = 0.80)
train_common <- rsample::training(split_common)
test_common  <- rsample::testing(split_common)

m_no_pop_common <- lm(tilskuere ~ s√¶son + runde + kamp_time_h + billetter_d10, data = train_common)
m_pop_common    <- lm(tilskuere ~ s√¶son + runde + kamp_time_h + billetter_d10 + befolkningstal, data = train_common)

pred_ref <- predict(m_no_pop_common, newdata = test_common)
pred_pop <- predict(m_pop_common,    newdata = test_common)

cat("\nOut-of-sample (COMMON)\n")
cat("Uden befolkning: RMSE=", rmse_vec(test_common$tilskuere, pred_ref),
    " MAE=", mae_vec(test_common$tilskuere, pred_ref),
    " R2=", r2_vec(test_common$tilskuere, pred_ref), "\n", sep = "")
cat("Med  befolkning: RMSE=", rmse_vec(test_common$tilskuere, pred_pop),
    " MAE=", mae_vec(test_common$tilskuere, pred_pop),
    " R2=", r2_vec(test_common$tilskuere, pred_pop), "\n\n", sep = "")

variabeltest_oversigt_d10 <- dplyr::bind_rows(results_list) |>
  dplyr::mutate(
    beslutning = dplyr::case_when(
      is.na(p_anova) ~ "Ikke testet",
      p_anova < 0.05 & delta_AIC < 0 ~ "Behold",
      TRUE ~ "Forkast"
    ),
    begrundelse = dplyr::case_when(
      variabel == "befolkningstal" ~ "Ingen robust effekt og stor data-omkostning",
      beslutning == "Behold" ~ "Signifikant forbedring og lavere AIC",
      TRUE ~ "Ingen signifikant forbedring eller AIC bliver d√•rligere"
    )
  ) |>
  dplyr::select(variabel, n_test, p_koefficient, p_anova, delta_AIC, beslutning, begrundelse) |>
  dplyr::arrange(delta_AIC)

cat("====================================\n")
cat("VARIABELTEST-OVERSIGT (D10)\n")
cat("====================================\n")
print(variabeltest_oversigt_d10)
cat("\n")

```

Alle testede ekstra variable i D10-modellen forkastes. Ingen af variablerne opn√•r statistisk signifikans, og samtlige medf√∏rer enten ingen forbedring eller en forv√¶rring af modelkvaliteten m√•lt. For befolkningstal ses desuden en markant data-omkostning, hvor antallet af observationer reduceres fra 254 til 131.

Out-of-sample evalueringen underst√∏tter resultaterne fra ANOVA- testene. Modellen med befolkningstal pr√¶sterer d√•rligere end reference-modellen uden variablen, med h√∏jere RMSE og MAE samt lavere R¬≤.

D10-nulmodellen vurderes at v√¶re tilstr√¶kkelig og robust. Af hensyn til modelkvalitet, datad√¶kning og operationel anvendelighed fastholdes en lean D10-model uden de testede ekstra variable.

## OLS & Ridge & Lasso

Datas√¶ttet klarg√∏res som det endelige analysegrundlag for D10-modellen, hvor relevante variable er udvalgt, datatyper standardiseret og observationer med manglende v√¶rdier fjernet. Resultatet er et konsistent, kronologisk sorteret datas√¶t med √©n r√¶kke pr. kamp, klar til modellering.

```{r}
stopifnot(exists("analysis_df_d10"))

df_d10_final <- analysis_df_d10 |>
  dplyr::transmute(
    kamp_id       = as.character(kamp_id),
    kamp_dato     = as.Date(kamp_dato),
    tilskuere     = as.numeric(tilskuere),
    
    s√¶son_chr     = as.character(s√¶son),
    s√¶son_start   = season_start_year(s√¶son_chr),
    
    runde         = as.integer(runde),
    kamp_time_h   = as.integer(kamp_time_h),
    billetter_d10 = as.numeric(billetter_d10)
  ) |>
  dplyr::filter(
    !is.na(kamp_dato),
    !is.na(tilskuere),
    !is.na(s√¶son_start),
    !is.na(runde),
    !is.na(kamp_time_h),
    !is.na(billetter_d10)
  ) |>
  dplyr::arrange(kamp_dato)

cat(
  "df_d10_final klar ‚úÖ  N=", nrow(df_d10_final),
  "  Periode=", as.character(min(df_d10_final$kamp_dato)), "‚Üí", as.character(max(df_d10_final$kamp_dato)),
  "  S√¶soner=", dplyr::n_distinct(df_d10_final$s√¶son_chr), "\n\n",
  sep = ""
)
```

### Tidsbaseret tr√¶nings- og testsplit (D10)

Datas√¶ttet opdeles i et tidsbaseret tr√¶nings- og tests√¶t, hvor de seneste 20 % af observationerne anvendes som testdata. Opdelingen sikrer, at modellen evalueres p√• fremtidige kampe i forhold til tr√¶ningsperioden og undg√•r informationsl√¶kage, samtidig med at der altid bevares mindst √©n observation i tests√¶ttet.

```{r}
set.seed(42)
test_prop <- 0.20

n_total <- nrow(df_d10_final)
n_test  <- max(1L, as.integer(floor(n_total * test_prop)))
cut_idx <- max(1L, n_total - n_test)

train_d10 <- df_d10_final[seq_len(cut_idx), , drop = FALSE]
test_d10  <- df_d10_final[(cut_idx + 1L):n_total, , drop = FALSE]

if (nrow(test_d10) == 0) {
  n_test  <- 1L
  cut_idx <- n_total - n_test
  train_d10 <- df_d10_final[seq_len(cut_idx), , drop = FALSE]
  test_d10  <- df_d10_final[(cut_idx + 1L):n_total, , drop = FALSE]
}

cat("Tidssplit klar ‚úÖ  Train=", nrow(train_d10), "  Test=", nrow(test_d10),
    "  Test starter=", as.character(min(test_d10$kamp_dato)), "\n\n", sep = "")
```

### Estimering af D10 OLS-baseline

D10-nulmodellen estimeres som en line√¶r regressionsmodel p√• tr√¶ningsdata og evalueres p√• tests√¶ttet ved hj√¶lp af RMSE, MAE og R¬≤. Samme modelspecifikation anvendes til at konstruere designmatricer for tr√¶nings- og testdata, hvilket sikrer konsistens i den efterf√∏lgende modellering og performance-sammenligning.

```{r}

f_d10 <- tilskuere ~ s√¶son_start + runde + kamp_time_h + billetter_d10

m_lm <- lm(f_d10, data = train_d10)
pred_lm <- as.numeric(predict(m_lm, newdata = test_d10))

perf_lm <- tibble::tibble(
  model = "OLS (lm)",
  RMSE  = rmse_vec(test_d10$tilskuere, pred_lm),
  MAE   = mae_vec(test_d10$tilskuere, pred_lm),
  R2    = r2_vec(test_d10$tilskuere, pred_lm)
)

x_train <- stats::model.matrix(f_d10, data = train_d10)[, -1, drop = FALSE]
y_train <- train_d10$tilskuere
x_test  <- stats::model.matrix(f_d10, data = test_d10)[, -1, drop = FALSE]
y_test  <- test_d10$tilskuere

```

### Regulariserede modeller: Ridge og Lasso

Ridge- og Lasso-modeller estimeres ved hj√¶lp af 10-fold krydsvalidering, hvor den optimale regulariseringsparameter v√¶lges automatisk. Modellerne evalueres p√• tests√¶ttet med samme performance-m√•l som OLS, hvilket muligg√∏r en direkte og fair sammenligning af pr√¶diktiv kvalitet p√• D10-horisonten.

```{r}
set.seed(42)
cv_ridge <- glmnet::cv.glmnet(x_train, y_train, alpha = 0, nfolds = 10, standardize = TRUE)
pred_ridge <- as.numeric(predict(cv_ridge, newx = x_test, s = "lambda.min"))

set.seed(42)
cv_lasso <- glmnet::cv.glmnet(x_train, y_train, alpha = 1, nfolds = 10, standardize = TRUE)
pred_lasso <- as.numeric(predict(cv_lasso, newx = x_test, s = "lambda.min"))

perf_glmnet <- tibble::tibble(
  model = c("Ridge (cv.glmnet)", "Lasso (cv.glmnet)"),
  RMSE  = c(rmse_vec(y_test, pred_ridge), rmse_vec(y_test, pred_lasso)),
  MAE   = c(mae_vec(y_test, pred_ridge),  mae_vec(y_test, pred_lasso)),
  R2    = c(r2_vec(y_test, pred_ridge),   r2_vec(y_test, pred_lasso)),
  lambda_min = c(cv_ridge$lambda.min, cv_lasso$lambda.min)
)

perf_d10 <- dplyr::bind_rows(perf_lm, perf_glmnet) |>
  dplyr::arrange(RMSE)
```

```{r}
cat("====================================\n")
cat("D10 ‚Äî SAMLET TEST PERFORMANCE\n")
cat("====================================\n")
print(perf_d10)
cat("\n")

best_model_name <- as.character(perf_d10$model[1])
cat("Best model (lavest RMSE): ", best_model_name, "\n\n", sep = "")

prep_features_d10 <- function(df) {
  req <- c("kamp_id","kamp_dato","s√¶son","runde","kamp_time_h","billetter_d10")
  miss <- setdiff(req, names(df))
  if (length(miss) > 0) stop("‚ùå Forecast input mangler: ", paste(miss, collapse = ", "))
  
  df |>
    dplyr::transmute(
      kamp_id       = as.character(kamp_id),
      kamp_dato     = as.Date(kamp_dato),
      s√¶son_chr     = as.character(s√¶son),
      s√¶son_start   = season_start_year(s√¶son_chr),
      runde         = as.integer(runde),
      kamp_time_h   = as.integer(kamp_time_h),
      billetter_d10 = as.numeric(billetter_d10)
    )
}

predict_d10_best <- function(artifacts, new_df) {
  new_x <- prep_features_d10(new_df)
  keep <- stats::complete.cases(new_x[, c("s√¶son_start","runde","kamp_time_h","billetter_d10")])
  
  out <- tibble::tibble(
    kamp_id   = new_x$kamp_id,
    kamp_dato = new_x$kamp_dato,
    pred      = NA_real_
  )
  
  if (sum(keep) == 0) return(out)
  
  best <- artifacts$best$name
  
  if (best == "OLS (lm)") {
    out$pred[keep] <- clip_nonneg(as.numeric(predict(artifacts$models$lm, newdata = new_x[keep, , drop = FALSE])))
    return(out)
  }
  
  X <- stats::model.matrix(
    ~ s√¶son_start + runde + kamp_time_h + billetter_d10,
    data = new_x
  )[, -1, drop = FALSE]
  
  if (best == "Ridge (cv.glmnet)") {
    out$pred[keep] <- clip_nonneg(as.numeric(predict(artifacts$models$ridge, newx = X[keep, , drop = FALSE], s = "lambda.min")))
    return(out)
  }
  
  if (best == "Lasso (cv.glmnet)") {
    out$pred[keep] <- clip_nonneg(as.numeric(predict(artifacts$models$lasso, newx = X[keep, , drop = FALSE], s = "lambda.min")))
    return(out)
  }
  
  stop("‚ùå Ukendt best model: ", best)
}

d10_artifacts <- list(
  perf = perf_d10,
  models = list(
    lm    = m_lm,
    ridge = cv_ridge,
    lasso = cv_lasso
  ),
  best = list(
    name = best_model_name
  ),
  split_info = list(
    test_prop = test_prop,
    cut_date_test_start = min(test_d10$kamp_dato),
    n_train = nrow(train_d10),
    n_test  = nrow(test_d10),
    date_min = min(df_d10_final$kamp_dato),
    date_max = max(df_d10_final$kamp_dato)
  ),
  predict = list(
    prep_features = prep_features_d10,
    predict_best  = predict_d10_best
  )
)

cat("D10 artifacts klar ‚úÖ  Objekt: d10_artifacts\n\n")
```

#### Modelperformance og valg af bedste D10-model

OLS-, Ridge- og Lasso-modellerne pr√¶sterer meget ens p√• tests√¶ttet. OLS-modellen opn√•r den laveste RMSE og den h√∏jeste R¬≤, mens de regulariserede modeller ikke giver en m√•lbar forbedring i pr√¶diktiv performance. Ridge-modellen udviser en svag forringelse, og Lasso reducerer ikke fejlen trods regularisering.

Lasso fastholder alle forklarende variable ved Œª_min, hvilket indikerer, at der ikke er behov for variabelselektion i denne modelspecifikation. Ridge d√¶mper koefficienterne, men uden gevinst i pr√¶cision.

P√• denne baggrund v√¶lges OLS-modellen som den bedste D10-model. Den er b√•de den mest pr√¶cise og den mest fortolkelige, hvilket g√∏r den velegnet til operationel anvendelse og videre prognoser.

## D10-model Endelig

Denne blok fastl√¶gger den endelige D10-modelpipeline med tidsbaseret datasplit og estimering af OLS-, Ridge- og Lasso-modeller. Samtidig sikres, at det n√∏dvendige datagrundlag og de kr√¶vede variable er til stede, s√• modellen kan estimeres reproducerbart og efterf√∏lgende anvendes til evaluering, visualisering og prognoser.

### Hj√¶lpefunktioner til modelligninger i plots

Denne sektion definerer hj√¶lpefunktioner til automatisk at generere og formatere ligningstekster for OLS-, Ridge- og Lasso-modeller. Funktionerne sikrer ensartet notation og visuel pr√¶sentation af modellernes estimater, som kan inds√¶ttes direkte i plots p√• samme m√•de som i D7 FINAL.

```{r}

wrap_text <- function(s, width = 85) {
  paste(strwrap(as.character(s), width = width), collapse = "\n")
}

build_lm_equation_text <- function(lm_model, yhat_name = "≈∑") {
  cf <- stats::coef(lm_model)
  cf <- cf[!is.na(cf)]
  nm <- names(cf)

  intercept <- unname(cf[1])
  terms <- nm[-1]
  betas <- unname(cf[-1])

  fmt <- function(x) formatC(x, format = "f", digits = 3)

  rhs <- paste0(fmt(intercept))
  if (length(terms) > 0) {
    for (i in seq_along(terms)) {
      b <- betas[i]
      sign_txt <- if (b >= 0) " + " else " ‚àí "
      rhs <- paste0(rhs, sign_txt, fmt(abs(b)), "¬∑", terms[i])
    }
  }

  paste0(yhat_name, " = ", rhs, "    (OLS)")
}

build_glmnet_equation_text <- function(cv_model, x_names, model_label = "GLMNET", yhat_name = "≈∑") {
  cm <- as.matrix(stats::coef(cv_model, s = "lambda.min"))
  b <- as.numeric(cm[, 1])
  names(b) <- rownames(cm)

  intercept <- b["(Intercept)"]
  beta <- b[setdiff(names(b), "(Intercept)")]
  beta <- beta[x_names]

  fmt <- function(x) formatC(x, format = "f", digits = 3)

  rhs <- paste0(fmt(intercept))
  if (length(beta) > 0) {
    for (i in seq_along(beta)) {
      bi <- beta[i]
      sign_txt <- if (bi >= 0) " + " else " ‚àí "
      rhs <- paste0(rhs, sign_txt, fmt(abs(bi)), "¬∑", names(beta)[i])
    }
  }

  paste0(yhat_name, " = ", rhs, "    (", model_label, ", Œª‚Çò·µ¢‚Çô)")
}

add_eq_to_plot <- function(p, eq_text, size = 3) {
  p + ggplot2::annotate(
    "text",
    x = -Inf, y = Inf,
    label = wrap_text(eq_text, width = 85),
    hjust = -0.05, vjust = 1.1,
    size = size
  )
}

```

### Klarg√∏ring af D10-modelleringsdatas√¶t

Datas√¶ttet klarg√∏res til modellering med √©n r√¶kke pr. kamp, hvor relevante variable udv√¶lges, datatyper standardiseres, og observationer med manglende v√¶rdier fjernes. Data sorteres kronologisk, s√• datas√¶ttet er konsistent og klar til tidsbaseret modellering.

```{r}


df_d10_final <- analysis_df_d10 |>
  dplyr::transmute(
    kamp_id       = as.character(kamp_id),
    kamp_dato     = as.Date(kamp_dato),
    tilskuere     = as.numeric(tilskuere),
    s√¶son_chr     = as.character(s√¶son),
    s√¶son_start   = season_start_year(s√¶son_chr),
    runde         = as.integer(runde),
    kamp_time_h   = as.integer(kamp_time_h),
    billetter_d10 = as.numeric(billetter_d10)
  ) |>
  dplyr::filter(dplyr::if_all(dplyr::everything(), ~ !is.na(.))) |>
  dplyr::arrange(kamp_dato)

cat("df_d10_final klar ‚úÖ  R√¶kker:", nrow(df_d10_final),
    "Periode:", as.character(min(df_d10_final$kamp_dato)), "‚Üí", as.character(max(df_d10_final$kamp_dato)), "\n\n")

```

### Tidsbaseret tr√¶nings- og testsplit

Datas√¶ttet opdeles tidsm√¶ssigt, hvor de seneste 20 % af kampene anvendes som testdata. Opdelingen sikrer en realistisk evaluering af modellens pr√¶diktive performance p√• fremtidige kampe og eliminerer risikoen for informationsl√¶kage fra tr√¶ningsperioden.

```{r}

set.seed(42)
test_prop <- 0.20

n_total <- nrow(df_d10_final)
n_test  <- max(1, floor(n_total * test_prop))
cut_idx <- n_total - n_test

train_d10 <- df_d10_final[1:cut_idx, ]
test_d10  <- df_d10_final[(cut_idx + 1):n_total, ]

cat("Tidssplit klar ‚úÖ\n")
cat("Train:", nrow(train_d10), " Test:", nrow(test_d10), "\n")
cat("Test-periode starter:", as.character(min(test_d10$kamp_dato)), "\n\n")

```

### Endelig D10 OLS-model

Den endelige D10-model estimeres som en line√¶r regressionsmodel p√• tr√¶ningsdata og evalueres p√• tests√¶ttet. Modellens pr√¶diktive performance vurderes ved hj√¶lp af RMSE, MAE og R¬≤, som danner referencegrundlag for sammenligning med de regulariserede modeller.

```{r}

m_d10_final_lm <- lm(
  tilskuere ~ s√¶son_start + runde + kamp_time_h + billetter_d10,
  data = train_d10
)

pred_lm <- as.numeric(predict(m_d10_final_lm, newdata = test_d10))

rmse_lm <- rmse_vec(test_d10$tilskuere, pred_lm)
mae_lm  <- mae_vec(test_d10$tilskuere, pred_lm)
r2_lm   <- r2_vec(test_d10$tilskuere, pred_lm)

cat("====================================\n")
cat("D10 FINAL OLS ‚Äî TEST METRICS\n")
cat("====================================\n")
cat("RMSE:", rmse_lm, " MAE:", mae_lm, " R2:", r2_lm, "\n\n")

```

OLS-modellen leverer den bedste samlede performance p√• D10-horisonten med lavest RMSE og MAE samt den h√∏jeste forklaringsgrad blandt de testede modeller. Resultatet viser, at en enkel og fortolkelig line√¶r model er tilstr√¶kkelig til at fange de v√¶sentligste sammenh√¶nge i data. P√• denne baggrund v√¶lges **OLS (lm)** som den endelige D10-model. Men vi tester de andre forneden for at v√¶re sikre.

### Designmatricer til Ridge- og Lasso-modeller

Designmatricer konstrueres for tr√¶nings- og tests√¶ttet med samme modelspecifikation som OLS-modellen. Dette sikrer konsistens i input til Ridge- og Lasso-estimering og muligg√∏r en direkte og retf√¶rdig sammenligning af modellernes performance.

```{r}


x_train <- model.matrix(
  tilskuere ~ s√¶son_start + runde + kamp_time_h + billetter_d10,
  data = train_d10
)[, -1, drop = FALSE]
y_train <- train_d10$tilskuere

x_test <- model.matrix(
  tilskuere ~ s√¶son_start + runde + kamp_time_h + billetter_d10,
  data = test_d10
)[, -1, drop = FALSE]
y_test <- test_d10$tilskuere

x_names <- colnames(x_train)
```

## Ridge-regression (D10)

Ridge-modellen estimeres med 10-fold krydsvalidering, hvor den optimale regulariseringsparameter v√¶lges automatisk. Modellen evalueres p√• tests√¶ttet ved hj√¶lp af RMSE, MAE og R¬≤ for at vurdere, om regularisering forbedrer den pr√¶diktive performance i forhold til OLS-modellen.

```{r}

set.seed(42)
cv_ridge <- glmnet::cv.glmnet(
  x = x_train, y = y_train,
  alpha = 0,
  nfolds = 10,
  standardize = TRUE
)

lambda_ridge <- cv_ridge$lambda.min
pred_ridge <- as.numeric(predict(cv_ridge, newx = x_test, s = "lambda.min"))

rmse_ridge <- rmse_vec(y_test, pred_ridge)
mae_ridge  <- mae_vec(y_test, pred_ridge)
r2_ridge   <- r2_vec(y_test, pred_ridge)

cat("====================================\n")
cat("D10 RIDGE ‚Äî TEST METRICS\n")
cat("====================================\n")
cat("lambda.min:", lambda_ridge, "\n")
cat("RMSE:", rmse_ridge, " MAE:", mae_ridge, " R2:", r2_ridge, "\n\n")
```

Ridge-modellen pr√¶sterer svagere end b√•de OLS- og Lasso-modellerne p√• D10-horisonten med h√∏jere RMSE og MAE samt lavere R¬≤. Selvom regularisering reducerer koefficienternes f√∏lsomhed, medf√∏rer den ingen forbedring i pr√¶diktiv performance. Ridge frav√¶lges derfor som endelig model.

## Lasso-regression (D10)

Lasso-modellen estimeres med 10-fold krydsvalidering, hvor den optimale regulariseringsparameter identificeres automatisk. Modellen evalueres p√• tests√¶ttet ved hj√¶lp af RMSE, MAE og R¬≤ for at vurdere, om variabelselektion og regularisering giver en forbedring i pr√¶diktiv performance sammenlignet med OLS- og Ridge-modellerne.

```{r}

# 6) Lasso (alpha = 1)

set.seed(42)
cv_lasso <- glmnet::cv.glmnet(
  x = x_train, y = y_train,
  alpha = 1,
  nfolds = 10,
  standardize = TRUE
)

lambda_lasso <- cv_lasso$lambda.min
pred_lasso <- as.numeric(predict(cv_lasso, newx = x_test, s = "lambda.min"))

rmse_lasso <- rmse_vec(y_test, pred_lasso)
mae_lasso  <- mae_vec(y_test, pred_lasso)
r2_lasso   <- r2_vec(y_test, pred_lasso)

cat("====================================\n")
cat("D10 LASSO ‚Äî TEST METRICS\n")
cat("====================================\n")
cat("lambda.min:", lambda_lasso, "\n")
cat("RMSE:", rmse_lasso, " MAE:", mae_lasso, " R2:", r2_lasso, "\n\n")
```

Lasso-modellen opn√•r en performance, der ligger meget t√¶t p√• OLS-modellen, men uden at give en forbedring i hverken RMSE, MAE eller R¬≤. Regularisering og potentiel variabelselektion tilf√∏rer s√•ledes ingen ekstra pr√¶diktiv gevinst p√• D10-horisonten. P√• denne baggrund frav√¶lges Lasso som endelig model til fordel for OLS.

## Samlet performance for D10-modeller

Performance for OLS-, Ridge- og Lasso-modellerne sammenfattes i en f√¶lles tabel baseret p√• tests√¶ttet. Sammenligningen g√∏r det muligt at identificere den model, der leverer den bedste pr√¶diktive kvalitet p√• D10-horisonten p√• tv√¶rs af fejlkriterierne RMSE, MAE og R¬≤.

```{r}
# =============================================================================
# 7) Samlet performance-tabel
# =============================================================================
perf_d10 <- tibble::tibble(
  model = c("OLS (lm)", "Ridge (cv.glmnet)", "Lasso (cv.glmnet)"),
  RMSE  = c(rmse_lm, rmse_ridge, rmse_lasso),
  MAE   = c(mae_lm,  mae_ridge,  mae_lasso),
  R2    = c(r2_lm,   r2_ridge,   r2_lasso)
)

cat("====================================\n")
cat("D10 ‚Äî SAMLET TEST PERFORMANCE\n")
cat("====================================\n")
print(perf_d10)
cat("\n")

```

OLS- og Lasso-modellerne pr√¶sterer stort set identisk og leverer den bedste pr√¶diktive kvalitet p√• D10-horisonten. Ridge-modellen klarer sig marginalt d√•rligere p√• alle tre m√•l. Da OLS opn√•r lavest RMSE og h√∏jest R¬≤ samtidig med st√∏rst fortolkelighed, v√¶lges **OLS (lm)** som den endelige D10-model.

## Visualisering og gemning af D10-resultater

Der genereres standardplots for D10-modellerne, herunder *Actual vs. Predicted* og *residualplots* for OLS, Ridge og Lasso. Modelligningerne vises direkte i figurerne for at underst√∏tte fortolkning og transparens. Alle centrale resultater, herunder performance, modeller, plots og ligningstekster, samles og gemmes i √©t f√¶lles objekt til videre brug og prognoser.

```{r}


plot_df <- tibble::tibble(
  kamp_dato  = test_d10$kamp_dato,
  actual     = y_test,
  pred_lm    = pred_lm,
  pred_ridge = pred_ridge,
  pred_lasso = pred_lasso
) |>
  dplyr::mutate(
    resid_lm    = actual - pred_lm,
    resid_ridge = actual - pred_ridge,
    resid_lasso = actual - pred_lasso
  )

eq_ols   <- build_lm_equation_text(m_d10_final_lm, yhat_name = "≈∑")
eq_ridge <- build_glmnet_equation_text(cv_ridge, x_names = x_names, model_label = "Ridge", yhat_name = "≈∑")
eq_lasso <- build_glmnet_equation_text(cv_lasso, x_names = x_names, model_label = "Lasso", yhat_name = "≈∑")

p1 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_lm)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Actual vs Pred (OLS)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p1 <- add_eq_to_plot(p1, eq_ols)

p2 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_ridge)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Actual vs Pred (Ridge)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p2 <- add_eq_to_plot(p2, eq_ridge)

p3 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_lasso)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Actual vs Pred (Lasso)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p3 <- add_eq_to_plot(p3, eq_lasso)

p4 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_lm, y = resid_lm)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Residualer vs Pred (OLS)",
    x = "Forudsagt",
    y = "Residual"
  )
p4 <- add_eq_to_plot(p4, eq_ols)

p5 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_ridge, y = resid_ridge)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Residualer vs Pred (Ridge)",
    x = "Forudsagt",
    y = "Residual"
  )
p5 <- add_eq_to_plot(p5, eq_ridge)

p6 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_lasso, y = resid_lasso)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Residualer vs Pred (Lasso)",
    x = "Forudsagt",
    y = "Residual"
  )
p6 <- add_eq_to_plot(p6, eq_lasso)

print(p1); print(p2); print(p3); print(p4); print(p5); print(p6)

d10_results <- list(
  perf         = perf_d10,
  lm_model     = m_d10_final_lm,
  ridge_lambda = lambda_ridge,
  lasso_lambda = lambda_lasso,
  plot_data    = plot_df,
  equations    = list(ols = eq_ols, ridge = eq_ridge, lasso = eq_lasso)
)

cat("D10 final resultater gemt i objektet: d10_results ‚úÖ\n")

```

```{r}

p1 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_lm)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Actual vs Pred (OLS)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p1 <- add_eq_to_plot(p1, eq_ols)
print(p1)
```

Denne graf viser sammenh√¶ngen mellem faktiske og forudsagte tilskuertal for D10 OLS-modellen p√• tests√¶ttet. Hver prik repr√¶senterer √©n kamp, hvor den horisontale akse angiver det faktiske tilskuertal, og den vertikale akse viser modellens forudsigelse. Den diagonale linje repr√¶senterer perfekt pr√¶diktion.

Punkterne ligger overordnet t√¶t omkring diagonalen, hvilket indikerer en god modeltilpasning og en st√¶rk line√¶r sammenh√¶ng mellem observerede og forudsagte v√¶rdier. Afvigelserne √∏ges en smule ved de h√∏jeste tilskuertal, men der ses ingen systematisk bias. Samlet set bekr√¶fter figuren, at OLS-modellen leverer robuste og operationelt anvendelige forudsigelser p√• D10-horisonten.

```{r}
p2 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_ridge)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Actual vs Pred (Ridge)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p2 <- add_eq_to_plot(p2, eq_ridge)
print(p2)
```

D10 Ridge-modellen sammenligner her faktiske og forudsagte tilskuertal p√• tests√¶ttet. Hver observation repr√¶senterer √©n kamp, hvor den vandrette akse viser det faktiske tilskuertal, og den lodrette akse viser modellens forudsigelse. Den diagonale linje angiver perfekt pr√¶diktion.

Punkterne f√∏lger generelt den diagonale reference, hvilket viser, at modellen opfanger den overordnede line√¶re sammenh√¶ng. Der ses dog st√∏rre spredning end i OLS-modellen, s√¶rligt ved h√∏jere tilskuertal, hvor forudsigelserne i flere tilf√¶lde afviger mere fra de observerede v√¶rdier. Samlet set bekr√¶fter dette, at Ridge ikke giver en forbedring i pr√¶diktiv kvalitet i forhold til OLS p√• D10-horisonten.

```{r}
p3 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = actual, y = pred_lasso)) +
  ggplot2::geom_point() +
  ggplot2::geom_abline(slope = 1, intercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Actual vs Pred (Lasso)",
    x = "Faktiske tilskuere",
    y = "Forudsagte tilskuere"
  )
p3 <- add_eq_to_plot(p3, eq_lasso)
print(p3)

```

D10 Lasso-modellen viser her sammenh√¶ngen mellem faktiske og forudsagte tilskuertal p√• tests√¶ttet. Den vandrette akse angiver det faktiske tilskuertal, mens den lodrette akse viser modellens forudsigelse. Den diagonale linje repr√¶senterer perfekt overensstemmelse.

Observationerne ligger generelt t√¶t omkring diagonalen og viser en pr√¶diktiv kvalitet, der er meget lig OLS-modellen. Der ses ingen tydelig systematisk bias, men heller ingen klar forbedring i forhold til OLS. Resultatet underst√∏tter, at Lasso ikke tilf√∏rer ekstra pr√¶diktiv styrke p√• D10-horisonten, men leverer sammenlignelige ‚Äì dog ikke bedre ‚Äì forudsigelser.

```{r}
p4 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_lm, y = resid_lm)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Residualer vs Pred (OLS)",
    x = "Forudsagt",
    y = "Residual"
  )
p4 <- add_eq_to_plot(p4, eq_ols)
print(p4)
```

D10 OLS-modellen vises her med residualerne plottet mod de forudsagte tilskuertal p√• tests√¶ttet. Den vandrette nul-linje angiver perfekt pr√¶diktion, hvor positive residualer svarer til undervurdering, og negative residualer til overvurdering.

Residualerne er overordnet tilf√¶ldigt fordelt omkring nul uden tydelige systematiske m√∏nstre, hvilket indikerer, at modellens line√¶re antagelse er rimelig p√• D10-horisonten. Der ses dog enkelte st√∏rre afvigelser ved h√∏je forudsagte tilskuertal, som bidrager til den samlede fejl, men uden at pege p√• strukturel bias. Samlet set underst√∏tter plottet, at OLS-modellen er stabil og velegnet som endelig D10-model.

```{r}
p5 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_ridge, y = resid_ridge)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Residualer vs Pred (Ridge)",
    x = "Forudsagt",
    y = "Residual"
  )
p5 <- add_eq_to_plot(p5, eq_ridge)
print(p5)
```

D10 Ridge-modellen vises her med residualer plottet mod de forudsagte tilskuertal p√• tests√¶ttet. Den vandrette nul-linje markerer perfekt pr√¶diktion, hvor positive residualer indikerer undervurdering og negative residualer indikerer overvurdering.

Residualerne er fortsat spredt omkring nul, men udviser st√∏rre variation end i OLS-modellen, s√¶rligt ved h√∏jere forudsagte tilskuertal. Der ses flere markante negative residualer, hvilket tyder p√• en tendens til overvurdering i den √∏vre ende. Plottet underst√∏tter dermed, at Ridge-regularisering ikke forbedrer modellens stabilitet eller pr√¶diktive kvalitet i D10-sammenh√¶ng.

```{r}
p6 <- ggplot2::ggplot(plot_df, ggplot2::aes(x = pred_lasso, y = resid_lasso)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0) +
  ggplot2::labs(
    title = "D10 TEST: Residualer vs Pred (Lasso)",
    x = "Forudsagt",
    y = "Residual"
  )
p6 <- add_eq_to_plot(p6, eq_lasso)
print(p6)
```

D10 Lasso-modellen vises her med residualer plottet mod de forudsagte tilskuertal p√• tests√¶ttet. Den vandrette nul-linje angiver perfekt pr√¶diktion, hvor positive residualer svarer til undervurdering og negative residualer til overvurdering.

Residualerne er overordnet centreret omkring nul og viser et m√∏nster, der minder meget om OLS-modellen. Der ses ingen tydelig systematisk struktur, men enkelte st√∏rre negative residualer ved h√∏je forudsagte tilskuertal indikerer, at modellen i visse tilf√¶lde overvurderer publikumspotentialet. Samlet set bekr√¶fter plottet, at Lasso ikke forbedrer modellens stabilitet eller fejladf√¶rd i forhold til OLS p√• D10-horisonten.

## Produktlag og interaktiv prognose (Shiny)

Produktlaget samler de to bedst pr√¶sterende D10-modeller (OLS og Lasso) i √©n operationel l√∏sning. Den bedste model v√¶lges automatisk som standard, men kan skiftes manuelt i en Shiny-app, hvor brugeren kan indtaste kamp- og billetsituation og f√• en forudsagt tilskuerm√¶ngde, fyldningsgrad af stadion samt forventet billetsalg fra D10 til kampdag. L√∏sningen er designet til praktisk beslutningsst√∏tte og visualiserer resultatet klart i forhold til stadionkapacitet.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


# =============================================================================
# D10 PRODUKTLAG ‚Äî TOP 2 MODELLER (OLS + LASSO) + √âN PLOT + SHINY APP
# =============================================================================

suppressPackageStartupMessages({
  library(dplyr)
  library(tibble)
  library(ggplot2)
  library(shiny)
})

.must_exist <- function(x) exists(x, inherits = TRUE)

stopifnot(.must_exist("perf_d10"), .must_exist("plot_df"), .must_exist("train_d10"), .must_exist("test_d10"))
stopifnot(.must_exist("m_d10_final_lm"), .must_exist("cv_lasso"))
stopifnot(.must_exist("rmse_vec"), .must_exist("clip_nonneg"))
stopifnot(.must_exist("wrap_text"), .must_exist("eq_ols"), .must_exist("eq_lasso"))

STADIUM_CAP_VFF <- 10000
clip_to_cap <- function(x, cap = STADIUM_CAP_VFF) pmin(pmax(as.numeric(x), 0), cap)

perf_top2 <- perf_d10 |>
  dplyr::filter(grepl("^OLS", model, ignore.case = TRUE) | grepl("^Lasso", model, ignore.case = TRUE))

if (nrow(perf_top2) == 0) {
  perf_top2 <- tibble::tibble(
    model = c("OLS (lm)", "Lasso (cv.glmnet)"),
    RMSE  = c(Inf, Inf),
    MAE   = c(NA_real_, NA_real_),
    R2    = c(NA_real_, NA_real_)
  )
}

top2_best_row <- perf_top2 |> arrange(RMSE) |> slice(1)

default_key <- dplyr::case_when(
  grepl("^OLS",  top2_best_row$model[1], ignore.case = TRUE) ~ "lm",
  grepl("^Lasso", top2_best_row$model[1], ignore.case = TRUE) ~ "lasso",
  TRUE ~ "lm"
)

cat("‚úÖ Default model (bedste): ", as.character(top2_best_row$model[1]),
    " => ", default_key, "\n\n", sep = "")

.format_num <- function(x, digits = 1) {
  format(round(as.numeric(x), digits), big.mark = ".", decimal.mark = ",", trim = TRUE)
}

plot_pva_with_eq <- function(df, title, eq_text, rmse_val) {
  ggplot(df, aes(x = y, y = yhat)) +
    geom_point(alpha = 0.7) +
    geom_abline(slope = 1, intercept = 0) +
    labs(
      title = title,
      x = "Faktiske tilskuere",
      y = "Forudsagte tilskuere"
    ) +
    annotate(
      "text",
      x = Inf, y = -Inf,
      hjust = 1.02, vjust = -0.2,
      label = paste0("RMSE = ", .format_num(rmse_val, 1)),
      size = 3.8
    ) +
    annotate(
      "text",
      x = -Inf, y = Inf,
      hjust = -0.02, vjust = 1.15,
      label = wrap_text(eq_text, width = 85),
      size = 3.2
    ) +
    theme_minimal()
}

y <- as.numeric(plot_df$actual)

if (default_key == "lm") {
  yhat <- as.numeric(plot_df$pred_lm)
  eq_best <- eq_ols
  title_best <- "D10 ‚Äî BEDSTE MODEL: OLS (lm) ‚Äî Pred vs Actual"
} else {
  yhat <- as.numeric(plot_df$pred_lasso)
  eq_best <- eq_lasso
  title_best <- "D10 ‚Äî BEDSTE MODEL: Lasso (Œªmin) ‚Äî Pred vs Actual"
}

df_best <- tibble::tibble(y = y, yhat = yhat)
rmse_best <- rmse_vec(df_best$y, df_best$yhat)

print(plot_pva_with_eq(df_best, title_best, eq_best, rmse_best))
cat("\n‚úÖ D10 bedste-model plot f√¶rdig\n\n")

season_label <- function(season_start_int) {
  paste0(as.integer(season_start_int), "/", as.integer(season_start_int) + 1L)
}

parse_season_start <- function(season_text) {
  s <- trimws(as.character(season_text))
  ok <- grepl("^\\d{4}/\\d{4}$", s)
  
  if (!ok) {
    y <- suppressWarnings(as.integer(substr(s, 1, 4)))
    if (!is.finite(y)) return(list(start = NA_integer_, note = "Ugyldigt s√¶sonformat. Brug fx 2025/2026."))
    return(list(start = y, note = "S√¶sonformat er ikke 'YYYY/YYYY'. Jeg bruger f√∏rste √•r som s√¶son_start."))
  }
  
  y1 <- suppressWarnings(as.integer(substr(s, 1, 4)))
  y2 <- suppressWarnings(as.integer(substr(s, 6, 9)))
  if (!is.finite(y1) || !is.finite(y2)) return(list(start = NA_integer_, note = "Ugyldigt s√¶sonformat."))
  if (y2 != y1 + 1L) return(list(start = y1, note = "Andet √•r er ikke f√∏rste+1. Jeg bruger f√∏rste √•r som s√¶son_start."))
  list(start = y1, note = "")
}

.range_or <- function(x, fallback = c(0, 1)) {
  r <- range(as.numeric(x), na.rm = TRUE)
  if (any(!is.finite(r))) fallback else r
}
.med_or <- function(x, fallback = 0) {
  v <- stats::median(as.numeric(x), na.rm = TRUE)
  if (!is.finite(v)) fallback else v
}

.int_or <- function(x, fallback = 0L) {
  v <- suppressWarnings(as.numeric(x))
  v <- v[is.finite(v)]
  if (length(v) == 0) return(as.integer(fallback))
  as.integer(round(stats::median(v, na.rm = TRUE)))
}
.int_range_or <- function(x, fallback = c(0L, 12000L)) {
  v <- suppressWarnings(as.numeric(x))
  v <- v[is.finite(v)]
  if (length(v) == 0) return(as.integer(fallback))
  r <- range(v, na.rm = TRUE)
  as.integer(c(floor(r[1]), ceiling(r[2])))
}

.fill_bucket <- function(pct) {
  if (!is.finite(pct)) return("UKENDT")
  if (pct >= 85) return("H√òJ")
  if (pct >= 60) return("MIDDEL")
  "LAV"
}

.predict_model <- function(model_key, s√¶son_start, runde, kamp_time_h, billetter_d10) {
  billetter_int <- as.integer(round(as.numeric(billetter_d10)))
  
  nd <- data.frame(
    s√¶son_start   = as.integer(s√¶son_start),
    runde         = as.integer(runde),
    kamp_time_h   = as.integer(kamp_time_h),
    billetter_d10 = billetter_int
  )
  
  if (model_key == "lm") {
    yhat <- suppressWarnings(as.numeric(predict(m_d10_final_lm, newdata = nd)))
  } else {
    X <- model.matrix(~ s√¶son_start + runde + kamp_time_h + billetter_d10, data = nd)[, -1, drop = FALSE]
    yhat <- suppressWarnings(as.numeric(predict(cv_lasso, newx = X, s = "lambda.min")))
  }
  
  if (length(yhat) == 0) yhat <- NA_real_
  clip_nonneg(yhat)
}

.eq_for_key <- function(model_key) {
  if (model_key == "lm") eq_ols else eq_lasso
}
.model_name <- function(model_key) {
  if (model_key == "lm") "OLS (lm)" else "Lasso (cv.glmnet)"
}

ui <- fluidPage(
  titlePanel("D10 ‚Äî Prediction (v√¶lg model)"),
  
  sidebarLayout(
    sidebarPanel(
      tags$h4("Model"),
      selectInput(
        "model_choice",
        "V√¶lg model (default = bedste)",
        choices = c("OLS (lm)" = "lm", "Lasso (cv.glmnet)" = "lasso"),
        selected = default_key
      ),
      tags$hr(),
      
      tags$h4("Inputs"),
      textInput("season_txt", "S√¶son (YYYY/YYYY)", value = "2025/2026"),
      
      numericInput(
        "runde", "runde",
        value = .med_or(train_d10$runde, fallback = 1),
        min = .range_or(train_d10$runde, fallback = c(1, 40))[1],
        max = .range_or(train_d10$runde, fallback = c(1, 40))[2],
        step = 1
      ),
      numericInput(
        "kamp_time_h", "kamp_time_h",
        value = .med_or(train_d10$kamp_time_h, fallback = 18),
        min = .range_or(train_d10$kamp_time_h, fallback = c(10, 22))[1],
        max = .range_or(train_d10$kamp_time_h, fallback = c(10, 22))[2],
        step = 1
      ),
      numericInput(
        "billetter_d10", "billetter_d10 (heltal)",
        value = .int_or(train_d10$billetter_d10, fallback = 0L),
        min = .int_range_or(train_d10$billetter_d10, fallback = c(0L, 12000L))[1],
        max = .int_range_or(train_d10$billetter_d10, fallback = c(0L, 12000L))[2],
        step = 1
      ),
      
      tags$hr(),
      numericInput("capacity", "Stadion-kapacitet", value = 10000, min = 1, step = 1),
      actionButton("go", "Predict", class = "btn-primary")
    ),
    
    mainPanel(
      tags$h4("Output"),
      tags$div(style="font-size:20px; margin-bottom:8px;", textOutput("pred_txt")),
      tags$div(style="font-size:20px; margin-bottom:8px;", textOutput("pct_txt")),
      tags$div(style="font-size:20px; margin-bottom:8px;", textOutput("delta_txt")),
      tags$div(style="font-size:14px; margin-bottom:6px; color:#333;", textOutput("season_note_txt")),
      tags$div(style="font-size:14px; margin-bottom:14px; color:#333;", textOutput("eq_txt")),
      plotOutput("cap_plot", height = "520px")
    )
  )
)

server <- function(input, output, session) {
  
  pred_obj <- eventReactive(input$go, {
    
    cap <- as.numeric(input$capacity)
    if (!is.finite(cap) || cap <= 0) cap <- 1
    
    key <- input$model_choice
    
    season_parsed <- parse_season_start(input$season_txt)
    s√¶son_start <- season_parsed$start
    
    if (!is.finite(s√¶son_start)) {
      return(list(
        ok = FALSE,
        msg = "Ugyldig s√¶son. Brug formatet 2025/2026.",
        note = season_parsed$note
      ))
    }
    
    bil_int <- as.integer(round(as.numeric(input$billetter_d10)))
    
    yhat <- .predict_model(
      model_key     = key,
      s√¶son_start   = s√¶son_start,
      runde         = input$runde,
      kamp_time_h   = input$kamp_time_h,
      billetter_d10 = bil_int
    )
    
    yhat_cap <- clip_to_cap(yhat, cap = cap)
    
    pct <- (as.numeric(yhat_cap) / cap) * 100
    pct_clip <- max(min(pct, 100), 0)
    
    delta <- if (is.finite(bil_int)) (as.numeric(yhat_cap) - bil_int) else NA_real_
    
    list(
      ok = TRUE,
      pred = as.numeric(yhat_cap),
      pct  = pct_clip,
      cap  = cap,
      bil_d10 = bil_int,
      delta = delta,
      eq = .eq_for_key(key),
      model_name = .model_name(key),
      season_txt = season_label(s√¶son_start),
      note = season_parsed$note
    )
  })
  
  output$pred_txt <- renderText({
    x <- pred_obj()
    if (is.null(x)) return("Ingen prediction endnu.")
    if (!isTRUE(x$ok)) return(x$msg)
    
    paste0(
      "Model: ", x$model_name, " ‚Äî s√¶son ", x$season_txt, "\n",
      "Forudsagt tilskuertal: ", format(round(x$pred), big.mark = ".", decimal.mark = ",")
    )
  })
  
  output$pct_txt <- renderText({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return("")
    paste0("Stadion fyldt: ", format(round(x$pct, 1), big.mark = ".", decimal.mark = ","), " %")
  })
  
  output$delta_txt <- renderText({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return("")
    if (!is.finite(x$bil_d10)) return("Ekstra billetter (D10 ‚Üí kampdag): kan ikke beregnes (billetter_d10 mangler)")
    paste0(
      "Ekstra billetter (D10 ‚Üí kampdag): ",
      format(round(x$delta), big.mark = ".", decimal.mark = ","),
      "  (≈∑ ‚àí billetter_d10)"
    )
  })
  
  # ‚úÖ FIX HER
  output$season_note_txt <- renderText({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return("")
    if (is.null(x$note) || !nzchar(x$note)) return("")
    paste0("Note: ", x$note)
  })
  
  output$eq_txt <- renderText({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return("")
    paste0("Ligning (kort): ", x$eq)
  })
  
  output$cap_plot <- renderPlot({
    x <- pred_obj()
    if (is.null(x) || !isTRUE(x$ok)) return(NULL)
    
    bucket <- .fill_bucket(x$pct)
    
    df <- data.frame(
      label = "Stadionkapacitet",
      y = x$pred,
      bucket = bucket
    )
    
    ggplot(df, aes(x = label, y = y, fill = bucket)) +
      geom_col(width = 0.6) +
      geom_hline(yintercept = x$cap, linewidth = 0.9, linetype = 2) +
      coord_cartesian(ylim = c(0, x$cap)) +
      scale_fill_manual(
        values = c("LAV" = "#d55e00", "MIDDEL" = "#e69f00", "H√òJ" = "#009e73", "UKENDT" = "grey60"),
        breaks = c("LAV","MIDDEL","H√òJ","UKENDT"),
        name = "Fyldningsniveau"
      ) +
      labs(
        x = NULL,
        y = "Tilskuere (forudsagt)",
        title = "Forudsagt tilskuertal vs stadionkapacitet",
        subtitle = paste0("Kapacitet (stiplet linje): ", format(round(x$cap), big.mark=".", decimal.mark=","))
      ) +
      theme_minimal(base_size = 16) +
      theme(
        legend.position = "top",
        plot.title = element_text(face = "bold"),
        panel.grid.minor = element_blank()
      )
  })
}

shinyApp(ui, server)

```

## Scenarie: Prognose som beslutningsv√¶rkt√∏j f√∏r kampdag

I forbindelse med planl√¶gningen af en kommende Superliga-kamp i s√¶son 2025/2026 st√•r Palle, som har ansvar for den overordnede planl√¶gning og koordinering omkring kampafvikling, over for en konkret beslutning:\
Skal der iv√¶rks√¶ttes ekstra tiltag op mod kampdagen ‚Äì eksempelvis √∏get markedsf√∏ring, ekstra bemanding eller udvidet drift i boder og faciliteter ‚Äì eller er det tilstr√¶kkeligt at fastholde det nuv√¶rende setup?

Palle anvender D10 Prediction App‚Äôen som beslutningsv√¶rkt√∏j. P√• baggrund af allerede solgte billetter 10 dage f√∏r kamp (2.733), kampens tidspunkt (kl. 18), runde og s√¶son estimerer modellen et forventet tilskuertal p√• ca. 6.081, svarende til 60,8 % af stadionkapaciteten.

![](images/2026-01-05_23h34_30.png)

App‚Äôen indikerer samtidig, at der forventes et yderligere billetsalg p√• omkring 3.348 billetter frem mod kampdagen. Denne viden giver Palle et solidt, datadrevet grundlag for at vurdere, om der er behov for at opskalere driften ‚Äì men ogs√• for at argumentere over for ledelsen for, at en fuld kapacitetsudvidelse ikke er n√∏dvendig i dette scenarie.

Dermed fungerer prediction-modellen ikke blot som en prognose, men som et operationelt beslutningsst√∏ttev√¶rkt√∏j, hvor forskellige scenarier hurtigt kan testes ved at justere input som billetstatus, kampstartstid og stadionkapacitet.

# LONG-model uden leakage

Dette afsnit introducerer den samlede LONG-model for prognoser af tilskuertal. Scriptet samler historiske informationer om tilskuere og billetsalg i √©t konsistent workflow, hvor alle tidsafh√¶ngige features er konstrueret uden data leakage. Datagrundlaget hentes fra Azure SQL og kobles til en deduplikeret baseline med √©n r√¶kke pr. kamp. Modellen udvides med s√¶son- og rundeafh√¶ngig historik samt rolling kamp-historik, der udelukkende bygger p√• tidligere kampe. Den f√¶rdige LONG-model evalueres via year-split og danner grundlag for b√•de statistisk modelvalg og en forklarlig, scenariebaseret Shiny-applikation.

## Pakker og globale indstillinger

Denne kodeblok h√•ndterer indl√¶sning og validering af alle pakker, som anvendes i LONG-workflowet. Scriptet stopper eksplicit, hvis en n√∏dvendig pakke mangler, s√• fejl opdages tidligt. Derudover fasts√¶ttes globale indstillinger for output-formattering samt f√¶lles konstanter, som bruges p√• tv√¶rs af resten af analysen.

```{r}
needed_pkgs <- c("DBI","odbc","dplyr","lubridate","stringr","tibble","ggplot2","glmnet","slider")
missing_pkgs <- needed_pkgs[!vapply(needed_pkgs, requireNamespace, logical(1), quietly = TRUE)]
if (length(missing_pkgs) > 0) stop("‚ùå Manglende pakker: ", paste(missing_pkgs, collapse = ", "))

suppressPackageStartupMessages({
  library(DBI); library(odbc); library(dplyr); library(lubridate)
  library(stringr); library(tibble); library(ggplot2); library(glmnet)
  library(slider)
})

options(scipen = 999)
cat("Pakker er klar ‚úÖ\n\n")

N_SHOW <- 20


```

## Hj√¶lpefunktioner

#### Validering af milj√∏variabler

Kontrollerer at alle n√∏dvendige milj√∏variabler til Azure SQL er korrekt defineret i .Renviron og afbryder k√∏rslen, hvis der mangler nogen.

```{r}
ensure_renviron <- function() {
  req <- c("AZURE_SQL_SERVER","AZURE_SQL_DB","AZURE_SQL_UID","AZURE_SQL_PWD")
  vals <- Sys.getenv(req)
  miss <- req[vals == ""]
  if (length(miss) > 0) stop("‚ùå Manglende milj√∏variabler i .Renviron: ", paste(miss, collapse = ", "))
  cat("‚úî .Renviron OK\n\n")
}
```

#### Azure SQL-forbindelse med retry

Etablerer forbindelse til Azure SQL med gentagne fors√∏g og gradvist stigende timeout for at h√•ndtere midlertidige forbindelsesproblemer.

```{r}

connect_azure_retry <- function(
    fors√∏g_max = 6,
    timeouts   = c(60, 180, 240, 360, 600, 900),
    delay_sec  = 10
) {
  for (i in seq_len(fors√∏g_max)) {
    timeout_brug <- timeouts[min(i, length(timeouts))]
    cat("Fors√∏g ", i, " / ", fors√∏g_max, " ‚Äî ConnectionTimeout = ", timeout_brug, " sek\n", sep = "")
    con_try <- try(
      DBI::dbConnect(
        odbc::odbc(),
        driver   = "ODBC Driver 18 for SQL Server",
        server   = Sys.getenv("AZURE_SQL_SERVER"),
        database = Sys.getenv("AZURE_SQL_DB"),
        uid      = Sys.getenv("AZURE_SQL_UID"),
        pwd      = Sys.getenv("AZURE_SQL_PWD"),
        Encrypt  = "yes",
        TrustServerCertificate = "no",
        ConnectionTimeout = timeout_brug
      ),
      silent = TRUE
    )
    if (!inherits(con_try, "try-error")) {
      cat("‚úÖ Forbundet til Azure SQL\n\n")
      return(con_try)
    }
    if (i < fors√∏g_max) Sys.sleep(delay_sec)
  }
  stop("‚ùå Kunne ikke forbinde til Azure SQL efter ", fors√∏g_max, " fors√∏g.")
}

```

#### Sikker indl√¶sning af tabel fra SQL

Fors√∏ger at l√¶se en tabel fra databasen med gentagne fors√∏g og korte pauser imellem, og stopper f√∏rst hvis indl√¶sningen gentagne gange fejler.

```{r}

safe_dbReadTable <- function(con, schema, table, fors√∏g_max = 4, delay_sec = 3) {
  for (i in seq_len(fors√∏g_max)) {
    out <- try(DBI::dbReadTable(con, DBI::Id(schema = schema, table = table)), silent = TRUE)
    if (!inherits(out, "try-error")) return(out)
    msg <- as.character(out)
    cat("‚ö†Ô∏è dbReadTable fejlede (", i, " / ", fors√∏g_max, "): ", schema, ".", table, "\n", sep = "")
    cat(substr(msg, 1, 220), "...\n\n")
    if (i < fors√∏g_max) Sys.sleep(delay_sec)
  }
  stop("‚ùå Kunne ikke l√¶se tabel: ", schema, ".", table)
}

```

Deduplikering til √©n r√¶kke pr. kamp

Reducerer datas√¶ttet til √©n r√¶kke pr. kamp-id ved at v√¶lge den observation med f√¶rrest manglende v√¶rdier.

```{r}
dedup_1row_by_id <- function(df, id_col = "kamp_id") {
  stopifnot(id_col %in% names(df))
  df2 <- df
  df2$.na_count <- rowSums(is.na(df2))
  df2 |>
    arrange(.data[[id_col]], .na_count) |>
    group_by(.data[[id_col]]) |>
    slice(1) |>
    ungroup() |>
    select(-.na_count)
}
```

#### Udtr√¶k af s√¶sonens start√•r

Udleder s√¶sonens start√•r ved at udtr√¶kke det f√∏rste √•rstal fra s√¶sonangivelsen.

```{r}

season_start_year <- function(season_chr) {
  x <- as.character(season_chr)
  suppressWarnings(as.integer(stringr::str_extract(x, "\\d{4}")))
}
```

#### Evalueringsm√•l for modelperformance

Beregner RMSE, MAE og R¬≤ til vurdering af modellens pr√¶diktive n√∏jagtighed.

```{r}

rmse_vec <- function(y, yhat) sqrt(mean((y - yhat) ^ 2, na.rm = TRUE))
mae_vec  <- function(y, yhat) mean(abs(y - yhat), na.rm = TRUE)
r2_vec <- function(y, yhat) {
  sse <- sum((y - yhat) ^ 2, na.rm = TRUE)
  sst <- sum((y - mean(y, na.rm = TRUE)) ^ 2, na.rm = TRUE)
  1 - (sse / sst)
}
```

#### Year-split til tr√¶ning og test

Opdeler datas√¶ttet i tr√¶nings- og testdata baseret p√• hele √•r, s√• de seneste √•r anvendes som testperiode.

```{r}
make_year_split <- function(df, year_col = "√•r", n_test_years = 2) {
  stopifnot(year_col %in% names(df))
  yrs <- sort(unique(df[[year_col]]))
  if (length(yrs) < (n_test_years + 1)) stop("‚ùå For f√• √•r til et stabilt year-split.")
  test_years <- tail(yrs, n_test_years)
  train <- df |> filter(!( .data[[year_col]] %in% test_years ))
  test  <- df |> filter(   .data[[year_col]] %in% test_years )
  list(train = train, test = test, test_years = test_years)
}
```

Estimering af OLS-model

Fitter en line√¶r regressionsmodel p√• tr√¶ningsdata med de angivne forklarende variable.

```{r}
fit_ols <- function(train_df, y, x_vars) {
  x_vars <- x_vars[x_vars %in% names(train_df)]
  f <- as.formula(paste(y, "~", paste(x_vars, collapse = " + ")))
  lm(f, data = train_df)
}
```

#### Opbygning af modelmatrix

Omdanner de valgte forklarende variable til en numerisk modelmatrix egnet til regulariserede modeller.

```{r}
make_model_matrix <- function(df, x_vars) {
  x_vars <- x_vars[x_vars %in% names(df)]
  f <- as.formula(paste("~", paste(x_vars, collapse = " + ")))
  mm <- model.matrix(f, df)
  mm[, -1, drop = FALSE]
}
```

#### Tilpasning af feature-kolonner

Sikrer at modelmatrixen matcher de forventede kolonner ved at tilf√∏je manglende kolonner med nul og fjerne overskydende.

```{r}

align_to_cols <- function(x, target_cols) {
  x_cols <- colnames(x)
  miss <- setdiff(target_cols, x_cols)
  if (length(miss) > 0) {
    add <- matrix(0, nrow = nrow(x), ncol = length(miss))
    colnames(add) <- miss
    x <- cbind(x, add)
  }
  extra <- setdiff(x_cols, target_cols)
  if (length(extra) > 0) {
    x <- x[, setdiff(colnames(x), extra), drop = FALSE]
  }
  x <- x[, target_cols, drop = FALSE]
  x
}
```

#### Evaluering af modeloutput

Beregner RMSE, MAE og R¬≤ for testdata baseret p√• de genererede predictioner.

```{r}
eval_models <- function(test_df, y, pred) {
  yv <- as.numeric(test_df[[y]])
  tibble(
    RMSE = rmse_vec(yv, pred),
    MAE  = mae_vec(yv, pred),
    R2   = r2_vec(yv, pred)
  )
} 
```

#### Robust gennemsnitsberegning

Beregner gennemsnittet og returnerer NA, hvis der ikke findes gyldige numeriske v√¶rdier.

```{r}

safe_mean <- function(x) {
  v <- as.numeric(x)
  v <- v[is.finite(v)]
  if (length(v) == 0) return(NA_real_)
  mean(v)
}  
```

#### Robust medianberegning

Beregner medianen og returnerer NA, hvis der ikke findes gyldige numeriske v√¶rdier.

```{r}
safe_median <- function(x) {
  v <- as.numeric(x)
  v <- v[is.finite(v)]
  if (length(v) == 0) return(NA_real_)
  stats::median(v)
}
```

#### Robust standardafvigelse

Beregner standardafvigelsen og returnerer NA, hvis der er for f√• gyldige observationer.

```{r}
safe_sd <- function(x) {
  v <- as.numeric(x)
  v <- v[is.finite(v)]
  if (length(v) < 2) return(NA_real_)
  stats::sd(v)
}
```

#### Rolling historik uden leakage

Beregner glidende gennemsnit og standardafvigelse udelukkende p√• tidligere observationer ved altid at forskyde data med √©t lag f√∏r beregning.

```{r}
# Rolling (NO LEAKAGE): altid LAG(1) f√∏r vi ruller
roll_mean_prev <- function(x, k) {
  x1 <- dplyr::lag(as.numeric(x), 1)
  slider::slide_dbl(x1, ~ mean(.x, na.rm = TRUE), .before = k - 1, .complete = FALSE)
}
roll_sd_prev <- function(x, k) {
  x1 <- dplyr::lag(as.numeric(x), 1)
  slider::slide_dbl(x1, ~ stats::sd(.x, na.rm = TRUE), .before = k - 1, .complete = FALSE)
}

```

## Initialisering af milj√∏ og databaseforbindelse

Validerer milj√∏variabler, opretter forbindelse til Azure SQL og sikrer, at forbindelsen altid lukkes korrekt ved afslutning af scriptet.

```{r}

# ====================================================================
# 2) .Renviron + connection
# ====================================================================
ensure_renviron()
con <- connect_azure_retry()


```

## Indl√¶sning, validering og klarg√∏ring af baseline

Indl√¶ser baseline-datas√¶ttet fra disk, sikrer korrekte datatyper og kontrollerer, at alle n√∏dvendige variable er til stede. Herefter udf√∏res kvalitetssikring med fokus p√• dubletter, s√• datas√¶ttet reduceres til √©n r√¶kke pr. kamp. Afslutningsvis udledes s√¶sonens start√•r, som anvendes i de efterf√∏lgende historik- og lag-beregninger.

#### Indl√¶sning af baseline-fil

Definerer sti til baseline-datas√¶ttet og sikrer, at filen findes, f√∏r den anvendes i resten af workflowet.

```{r}
baseline_dir  <- "C:/Users/janpe/OneDrive/Skrivebord/PBA Dataanlyse/01_F√∏rste semester/1 Semester projekt/Baseline"

baseline_file <- file.path(baseline_dir, "baseline_azure.rds")
stopifnot(file.exists(baseline_file))

```

#### Klarg√∏ring af baseline-data

Indl√¶ser baseline-datas√¶ttet og sikrer korrekt datatyper for kamp-id og kampdato.

```{r}
baseline <- readRDS(baseline_file) |>
  mutate(
    kamp_id   = as.character(kamp_id),
    kamp_dato = as.Date(kamp_dato)
  )
```

#### Validering af baseline-struktur

Sikrer at alle n√∏dvendige kolonner findes i baseline-datas√¶ttet og logger antal r√¶kker samt unikke kamp-id‚Äôer.

```{r}
stopifnot(all(c("kamp_id","kamp_dato","tilskuere","s√¶son","runde","ugedag") %in% names(baseline)))

cat("Baseline loaded ‚úÖ  R√¶kker: ", nrow(baseline),
    "  Unikke kamp_id: ", n_distinct(baseline$kamp_id), "\n\n", sep = "")

```

#### Tjek for dubletter i baseline

Identificerer kamp-id‚Äôer med flere observationer og rapporterer antallet som led i kvalitetssikring af baseline.

```{r}
dup_ids <- baseline |> count(kamp_id) |> filter(n > 1)
cat("--- BASELINE QA: DUPLIKAT-TJEK ---\n")
cat("Antal kamp_id med dubletter: ", nrow(dup_ids), "\n\n", sep = "")

```

#### H√•ndtering af dubletter i baseline

Fjerner eventuelle dubletter, s√• der kun er √©n r√¶kke pr. kamp-id, og bekr√¶fter resultatet via et konsistenstjek.

```{r}
if (nrow(dup_ids) > 0) {
  baseline <- dedup_1row_by_id(baseline, "kamp_id")
  stopifnot(nrow(baseline) == n_distinct(baseline$kamp_id))
  cat("‚úÖ Baseline deduplikeret (1 r√¶kke pr kamp_id)\n\n")
} else {
  cat("‚úÖ Ingen dubletter fundet\n\n")
}

```

**Udledning af s√¶sonens start√•r**

Tilf√∏jer s√¶sonens start√•r til baseline og logger antallet af manglende v√¶rdier som et simpelt kvalitetstjek.

```{r}
baseline <- baseline |>
  mutate(s√¶son_start√•r = season_start_year(s√¶son))
```

## Feature load & transform

### Helligdage

Tilf√∏jer en bin√¶r indikator for helligdag ved at koble kampdatoer til helligdagsdimensionen og s√¶tte v√¶rdien til 1 p√• helligdage og 0 ellers.

```{r}
# ====================================================================
# 4) FEATURE: Helligdage (1/0)
# ====================================================================
hellig_raw <- safe_dbReadTable(con, "PBA01_Raw", "dim_helligdage_dkk_raw")
stopifnot(all(c("dato","helligdag_navn") %in% names(hellig_raw)))

hellig_min <- hellig_raw |>
  mutate(hellig_dato = as.Date(dato)) |>
  filter(!is.na(hellig_dato)) |>
  distinct(hellig_dato) |>
  transmute(hellig_dato, er_helligdag = 1L)

baseline <- baseline |>
  left_join(hellig_min, by = c("kamp_dato" = "hellig_dato")) |>
  mutate(er_helligdag = if_else(is.na(er_helligdag), 0L, er_helligdag))

cat("Helligdage joinet ‚úÖ\n\n")

```

### SAH-variabler sat til default

Nulstiller SAH-relaterede variable, s√• h√•ndboldkampe ikke indg√•r som forklarende faktor i den videre analyse.

```{r}
# ====================================================================
# 5) SAH droppes (default)
# ====================================================================
baseline <- baseline |>
  mutate(
    er_h√•ndboldkamp_SAH = 0L,
    antal_h√•ndboldkampe = 0L
  )
cat("SAH droppet (default) ‚úÖ\n\n")

```

### Feature: befolkningstal (LOCF)

Tilf√∏jer befolkningstal til hver kamp ved at koble p√• den senest kendte befolkningsobservation f√∏r kampdatoen, s√• tidsm√¶ssig konsistens bevares uden leakage.

### Indl√¶sning af befolkningsdata

Henter befolkningsdata fra databasen og sikrer, at de n√∏dvendige kolonner er til stede.

```{r}
bef_raw <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_Viborg_befolkning_join_ready")
stopifnot(all(c("k√∏n","civilstand","dato","befolkningstal") %in% names(bef_raw)))

```

### Klarg√∏ring og filtrering af befolkningsdata

Standardiserer tekstfelter, sikrer korrekte datatyper og filtrerer til samlede befolkningstal pr. dato, som forberedes til tidsn√¶r join.

```{r}
bef_all <- bef_raw |>
  mutate(
    k√∏n = str_to_lower(str_trim(as.character(k√∏n))),
    civilstand = str_to_lower(str_trim(as.character(civilstand))),
    dato = as.Date(dato),
    befolkningstal = as.numeric(befolkningstal)
  ) |>
  filter(
    !is.na(dato),
    !is.na(befolkningstal),
    k√∏n %in% c("i alt", "alt"),
    civilstand %in% c("i alt", "alt")
  ) |>
  distinct(dato, .keep_all = TRUE) |>
  arrange(dato) |>
  transmute(bef_dato = dato, befolkningstal = befolkningstal)
```

### Kobling af befolkningstal til kampe

Tilf√∏jer befolkningstal til hver kamp ved at bruge den n√¶rmeste tidligere observationsdato og logger antallet af manglende v√¶rdier.

```{r}
baseline_bef <- baseline |>
  transmute(kamp_id, kamp_dato) |>
  left_join(bef_all, join_by(closest(kamp_dato >= bef_dato)))

baseline <- baseline |>
  left_join(baseline_bef |> select(kamp_id, befolkningstal), by = "kamp_id")

cat("Befolkning joinet ‚úÖ  NA: ", sum(is.na(baseline$befolkningstal)), "\n\n", sep = "")

```

### Kalenderbaserede features

Udleder √•r, m√•ned, weekendindikator, s√¶sonperiode og runde-fase samt fastl√¶gger ugedag som faktor med fast **orden** til videre modellering.

```{r}
ugedag_levels <- c("Mandag","Tirsdag","Onsdag","Torsdag","Fredag","L√∏rdag","S√∏ndag")

baseline <- baseline |>
  mutate(
    √•r = year(kamp_dato),
    m√•ned = month(kamp_dato),
    weekend = if_else(as.character(ugedag) %in% c("L√∏rdag","S√∏ndag"), 1L, 0L),
    
    s√¶son_periode = case_when(
      m√•ned %in% c(12,1,2)  ~ "Vinter",
      m√•ned %in% c(3,4,5)   ~ "For√•r",
      m√•ned %in% c(6,7,8)   ~ "Sommer",
      m√•ned %in% c(9,10,11) ~ "Efter√•r",
      TRUE ~ "UKENDT"
    ),
    s√¶son_periode = as.factor(s√¶son_periode),
    
    runde_fase = case_when(
      runde <= 8  ~ "Tidlig",
      runde <= 20 ~ "Midt",
      TRUE        ~ "Sen"
    ),
    runde_fase = as.factor(runde_fase),
    
    ugedag = factor(as.character(ugedag), levels = ugedag_levels)
  )

cat("Kalenderkorrektioner lavet ‚úÖ\n\n")
```

### Tilskuer-historik med lag uden leakage

Konstruerer historiske tilskuerfeatures baseret p√• s√¶son- og rundeniveau ved udelukkende at anvende laggede gennemsnit fra tidligere s√¶soner. Disse historiske estimater joines p√• baseline og sikrer, at aktuelle kampe ikke p√•virker deres egne forklarende variable.

#### S√¶sonbaseret tilskuerhistorik

Beregner gennemsnitligt tilskuertal pr. s√¶son og udleder historiske s√¶sonniveauer ved hj√¶lp af laggede v√¶rdier fra tidligere s√¶soner.

```{r}
season_mean <- baseline |>
  filter(!is.na(s√¶son_start√•r), !is.na(tilskuere)) |>
  group_by(s√¶son, s√¶son_start√•r) |>
  summarise(s√¶son_mean_tilskuere = mean(as.numeric(tilskuere), na.rm = TRUE), .groups = "drop") |>
  arrange(s√¶son_start√•r) |>
  mutate(
    lag1_mean = dplyr::lag(s√¶son_mean_tilskuere, 1),
    lag2_mean = dplyr::lag(s√¶son_mean_tilskuere, 2),
    hist_mean = if_else(!is.na(lag1_mean), lag1_mean, lag2_mean)
  ) |>
  select(s√¶son, s√¶son_start√•r, s√¶son_mean_tilskuere, lag1_mean, lag2_mean, hist_mean)

```

Kobling af s√¶sonhistorik til baseline\
Tilf√∏jer det historiske s√¶sonniveau for tilskuere til hver kamp via s√¶son-join.

```{r}

baseline <- baseline |>
  left_join(season_mean |> select(s√¶son, hist_mean), by = "s√¶son")

```

Beregner gennemsnitligt tilskuertal pr. runde og udleder historiske rundeniveauer via lag fra tidligere s√¶soner.

```{r}

round_mean <- baseline |>
  filter(!is.na(s√¶son_start√•r), !is.na(runde), !is.na(tilskuere)) |>
  group_by(runde, s√¶son_start√•r) |>
  summarise(runde_mean_tilskuere = mean(as.numeric(tilskuere), na.rm = TRUE), .groups = "drop") |>
  arrange(runde, s√¶son_start√•r) |>
  group_by(runde) |>
  mutate(
    lag1_round_mean = dplyr::lag(runde_mean_tilskuere, 1),
    lag2_round_mean = dplyr::lag(runde_mean_tilskuere, 2),
    hist_round_mean = if_else(!is.na(lag1_round_mean), lag1_round_mean, lag2_round_mean)
  ) |>
  ungroup() |>
  select(runde, s√¶son_start√•r, hist_round_mean)

```

Samler s√¶son- og rundebaseret historik i baseline og logger antallet af manglende historiske v√¶rdier som kvalitetstjek.

```{r}
baseline <- baseline |>
  left_join(round_mean, by = c("runde","s√¶son_start√•r"))

cat("Tilskuer-historik joinet ‚úÖ  NA hist_mean: ", sum(is.na(baseline$hist_mean)),
    "  NA hist_round_mean: ", sum(is.na(baseline$hist_round_mean)), "\n\n", sep = "")
```

### Billetdata og s√¶sonbaseret historik uden leakage

Indl√¶ser billetsalgsdata fra Azure SQL, reducerer dem til √©n observation pr. kamp og kobler dem p√• baseline. Herefter konstrueres s√¶sonbaserede aggregater for billetsalg, hvor historiske niveauer udledes via lag fra tidligere s√¶soner, s√• aktuelle kampe ikke p√•virker deres egne forklarende variable.

#### Indl√¶sning af billetsalgsdata

Henter billetsalgsdata fra databasen og klarg√∏r kamp-id og billetrelaterede tal til videre behandling.

```{r}
cat("--- TICKETS: load + s√¶son-aggregater (NO LEAKAGE) ---\n")

tickets_raw <- safe_dbReadTable(con, "PBA03_JoinReady", "fact_VFF_Billetsalg_join_ready") |>
  mutate(
    kamp_id = as.character(kamp_id),
    d10_tilskuere = suppressWarnings(as.numeric(d10_tilskuere))
  )
```

#### Validering af billetsalgsdata

Sikrer at de n√∏dvendige kolonner findes og logger omfanget af billetsalgsdata samt antal unikke kampe.

```{r}

stopifnot(all(c("kamp_id","d10_tilskuere") %in% names(tickets_raw)))

cat("Billetsalg hentet ‚úÖ  R√¶kker: ", nrow(tickets_raw), "\n", sep = "")
cat("Unikke kamp_id i billetsalg: ", n_distinct(tickets_raw$kamp_id), "\n\n", sep = "")

```

#### Aggregering af billetsalg pr. kamp

Reducerer billetsalgsdata til √©n observation pr. kamp ved at v√¶lge det h√∏jeste registrerede billetsalg og h√•ndterer ugyldige v√¶rdier.

```{r}
tickets_1row <- tickets_raw |>
  group_by(kamp_id) |>
  summarise(
    billetter_d10 = suppressWarnings(max(d10_tilskuere, na.rm = TRUE)),
    .groups = "drop"
  ) |>
  mutate(billetter_d10 = if_else(is.infinite(billetter_d10), NA_real_, billetter_d10))

```

#### Kobling af billetsalg til baseline

Tilf√∏jer billetsalgsvariablen til baseline og logger antallet af manglende v√¶rdier som kvalitetstjek.

```{r}
baseline <- baseline |>
  left_join(tickets_1row, by = "kamp_id")

cat("billetter_d10 joinet p√• baseline ‚úÖ  NA billetter_d10: ", sum(is.na(baseline$billetter_d10)), "\n\n", sep = "")

```

#### S√¶sonbaserede billetaggregater

Sammenfatter billetsalget pr. s√¶son ved hj√¶lp af robuste m√•l for niveau, spredning og datad√¶kning. For hver s√¶son konstrueres historiske billetfeatures ved at anvende lag fra tidligere s√¶soner, s√• de afspejler forventet billetsalgsniveau uden at inddrage information fra den aktuelle s√¶son.

```{r}

ticket_season <- baseline |>
  filter(!is.na(s√¶son_start√•r)) |>
  group_by(s√¶son, s√¶son_start√•r) |>
  summarise(
    ticket_mean_d10   = safe_mean(billetter_d10),
    ticket_median_d10 = safe_median(billetter_d10),
    ticket_sd_d10     = safe_sd(billetter_d10),
    ticket_n_d10      = sum(is.finite(as.numeric(billetter_d10))),
    .groups = "drop"
  ) |>
  arrange(s√¶son_start√•r) |>
  mutate(
    lag1_ticket_mean   = dplyr::lag(ticket_mean_d10, 1),
    lag2_ticket_mean   = dplyr::lag(ticket_mean_d10, 2),
    
    lag1_ticket_median = dplyr::lag(ticket_median_d10, 1),
    lag2_ticket_median = dplyr::lag(ticket_median_d10, 2),
    
    lag1_ticket_sd     = dplyr::lag(ticket_sd_d10, 1),
    lag2_ticket_sd     = dplyr::lag(ticket_sd_d10, 2),
    
    lag1_ticket_n      = dplyr::lag(ticket_n_d10, 1),
    lag2_ticket_n      = dplyr::lag(ticket_n_d10, 2),
    
    hist_ticket_mean_d10   = if_else(!is.na(lag1_ticket_mean),   lag1_ticket_mean,   lag2_ticket_mean),
    hist_ticket_median_d10 = if_else(!is.na(lag1_ticket_median), lag1_ticket_median, lag2_ticket_median),
    hist_ticket_sd_d10     = if_else(!is.na(lag1_ticket_sd),     lag1_ticket_sd,     lag2_ticket_sd),
    hist_ticket_n_d10      = if_else(!is.na(lag1_ticket_n),      lag1_ticket_n,      lag2_ticket_n),
    
    hist_ticket_mean2_d10 = case_when(
      !is.na(lag1_ticket_mean) & !is.na(lag2_ticket_mean) ~ (lag1_ticket_mean + lag2_ticket_mean) / 2,
      !is.na(lag1_ticket_mean)                            ~ lag1_ticket_mean,
      !is.na(lag2_ticket_mean)                            ~ lag2_ticket_mean,
      TRUE                                                ~ NA_real_
    )
  ) |>
  transmute(
    s√¶son,
    s√¶son_start√•r,
    ticket_mean_d10,
    ticket_median_d10,
    ticket_sd_d10,
    ticket_n_d10,
    hist_ticket_mean_d10,
    hist_ticket_median_d10,
    hist_ticket_sd_d10,
    hist_ticket_n_d10,
    hist_ticket_mean2_d10
  )
View(ticket_season, "ticket_season_lags")
```

#### Kobling af s√¶sonbaseret billethistorik

Sammenfletter s√¶sonbaserede historiske billetfeatures med baseline og logger omfanget af manglende historiske v√¶rdier som et afsluttende kvalitetstjek.

```{r}

baseline <- baseline |>
  left_join(
    ticket_season |>
      select(
        s√¶son,
        hist_ticket_mean_d10,
        hist_ticket_median_d10,
        hist_ticket_sd_d10,
        hist_ticket_n_d10,
        hist_ticket_mean2_d10
      ),
    by = "s√¶son"
  )
cat("Ticket-historik joinet ‚úÖ  NA hist_ticket_mean_d10: ", sum(is.na(baseline$hist_ticket_mean_d10)),
    "  NA hist_ticket_mean2_d10: ", sum(is.na(baseline$hist_ticket_mean2_d10)), "\n\n", sep = "")

```

#### Rolling kamp-historik uden leakage

Initialiserer beregning af kortsigtede historikfeatures for b√•de billetsalg og tilskuertal baseret udelukkende p√• tidligere kampe.

Logger start p√• rolling-beregninger og tjekker, om kampens tidspunkt findes, s√• sortering kan ske korrekt f√∏r historik beregnes.

```{r}
cat("--- Rolling historik: billetter_d10 + tilskuere (NO LEAKAGE) ---\n")

has_time <- "kamp_time_h" %in% names(baseline)

```

#### Rolling historikfeatures pr. kamp

Beregner glidende gennemsnit, spredning og trends for billetsalg og tilskuertal inden for hver s√¶son, udelukkende baseret p√• tidligere kampe, og logger manglende v√¶rdier som kvalitetstjek.

```{r}
baseline <- baseline |>
  arrange(
    s√¶son_start√•r,
    kamp_dato,
    if (has_time) kamp_time_h else 0
  ) |>
  group_by(s√¶son) |>
  mutate(
    kamp_nr_i_s√¶son = dplyr::row_number(),
    
    ticket_roll_mean_5  = roll_mean_prev(billetter_d10, 5),
    ticket_roll_mean_15 = roll_mean_prev(billetter_d10, 15),
    ticket_roll_sd_5    = roll_sd_prev(billetter_d10, 5),
    ticket_roll_sd_15   = roll_sd_prev(billetter_d10, 15),
    ticket_trend_5_15   = ticket_roll_mean_5 - ticket_roll_mean_15,
    
    tilsk_roll_mean_5   = roll_mean_prev(tilskuere, 5),
    tilsk_roll_mean_15  = roll_mean_prev(tilskuere, 15),
    tilsk_trend_5_15    = tilsk_roll_mean_5 - tilsk_roll_mean_15
  ) |>
  ungroup()

cat("Rolling features lavet ‚úÖ  NA ticket_roll_mean_5: ", sum(is.na(baseline$ticket_roll_mean_5)),
    "  NA tilsk_roll_mean_5: ", sum(is.na(baseline$tilsk_roll_mean_5)), "\n\n", sep = "")

```

#### Filtrering til komplet LONG-datas√¶t

Udv√¶lger observationer med fulde og konsistente v√¶rdier for respons, kalenderfeatures og historiske variable, s√• datas√¶ttet er egnet til modellering uden manglende centrale input.

```{r}
analysis_df_long_full <- baseline |>
  filter(
    !is.na(tilskuere),
    !is.na(runde),
    !is.na(ugedag),
    !is.na(√•r),
    !is.na(m√•ned),
    !is.na(weekend),
    !is.na(s√¶son_periode),
    !is.na(runde_fase),
    !is.na(hist_mean)
  )
```

#### Datas√¶t med og uden befolkningstal

Opretter en udvidet version af LONG-datas√¶ttet med befolkningstal og logger st√∏rrelsen af begge datas√¶t til sammenligning.

```{r}

analysis_df_long_bef <- analysis_df_long_full |>
  filter(!is.na(befolkningstal))

cat("analysis_df_long_full klar ‚úÖ  R√¶kker: ", nrow(analysis_df_long_full), "\n", sep = "")

cat("analysis_df_long_bef  klar ‚úÖ  R√¶kker: ", nrow(analysis_df_long_bef), "\n\n", sep = "")



```

#### Definition af LONG feature-s√¶t

Fastl√¶gger de forklarende variable til LONG-modellen, herunder kalenderfeatures, historiske s√¶son- og rundeniveauer, billetsalgs¬≠historik samt rolling momentum-features, og filtrerer dem til de variable, der faktisk findes i datas√¶ttet.

```{r}
base_long_vars <- c(
  "runde_fase",
  "ugedag",
  "weekend",
  "m√•ned",
  "√•r",
  "er_helligdag",
  "s√¶son_periode",
  "hist_mean",
  "hist_round_mean",
  
  # Ticket-historik (s√¶son-lag)
  "hist_ticket_mean_d10",
  "hist_ticket_mean2_d10",
  "hist_ticket_median_d10",
  "hist_ticket_sd_d10",
  "hist_ticket_n_d10",
  
  # Rolling kamp-historik (momentum)
  "ticket_roll_mean_5",
  "ticket_roll_mean_15",
  "ticket_trend_5_15",
  "ticket_roll_sd_5",
  "tilsk_roll_mean_5",
  "tilsk_roll_mean_15",
  "tilsk_trend_5_15"
)

base_long_vars <- base_long_vars[base_long_vars %in% names(analysis_df_long_full)]

cat("LONG feature-s√¶t:\n")
print(base_long_vars)
cat("\n")

```

### Endelig modelk√∏rsel

Denne del samler hele LONG-setup‚Äôet i en ensartet evalueringsfunktion, hvor datas√¶ttet opdeles i tr√¶ning og test via year-split. F√∏rst etableres simple baselines, som fungerer som referencepunkter, hvorefter OLS, Ridge og Lasso estimeres p√• samme split. Modellerne sammenlignes p√• tv√¶rs af RMSE, MAE og R¬≤, og resultaterne samles i et leaderboard. Afslutningsvis k√∏res processen b√•de uden og med befolkningstal for at vurdere stabilitet og marginal gevinst ved den ekstra feature.

```{r}
# =============================================================================
# 12) FINAL: YEAR SPLIT + Baselines + OLS / Ridge / Lasso
# =============================================================================
run_long_final_yearsplit <- function(df, y = "tilskuere", x_vars, label = "FULL", n_test_years = 2) {
  split <- make_year_split(df, year_col = "√•r", n_test_years = n_test_years)
  tr <- split$train
  te <- split$test
  
  cat("=== LONG FINAL (YEAR SPLIT): ", label, " ===\n", sep = "")
  cat("Test-√•r: ", paste(split$test_years, collapse = ", "), "\n", sep = "")
  cat("Train: ", nrow(tr), "  Test: ", nrow(te), "\n\n", sep = "")
  
  # ---------------------------
  # A) BASELINES
  # ---------------------------
  train_mean <- mean(as.numeric(tr[[y]]), na.rm = TRUE)
  
  pred_mean_train <- rep(train_mean, nrow(te))
  met_mean <- eval_models(te, y, pred_mean_train) |> mutate(model = "BASE_mean_train", dataset = label)
  
  pred_hist_mean <- as.numeric(te$hist_mean)
  met_hist <- eval_models(te, y, pred_hist_mean) |> mutate(model = "BASE_hist_mean", dataset = label)
  
  pred_hist_round <- ifelse(!is.na(te$hist_round_mean), as.numeric(te$hist_round_mean), as.numeric(te$hist_mean))
  met_hist_round <- eval_models(te, y, pred_hist_round) |> mutate(model = "BASE_hist_round_mean", dataset = label)
  
  baselines <- bind_rows(met_mean, met_hist, met_hist_round) |> arrange(RMSE)
  
  cat("--- BASELINES (test) ---\n")
  print(baselines)
  cat("\n")
  
  # ---------------------------
  # B) MODELS
  # ---------------------------
  tr2 <- tr
  te2 <- te
  
  tr2$hist_round_mean <- ifelse(is.na(tr2$hist_round_mean), tr2$hist_mean, tr2$hist_round_mean)
  te2$hist_round_mean <- ifelse(is.na(te2$hist_round_mean), te2$hist_mean, te2$hist_round_mean)
  
  # Imput√©r numeriske features (rolling + ticket-historik) med train-mean
  # (tidlige kampe i s√¶sonen giver typisk NA i rolling)
  for (cc in x_vars) {
    if (!cc %in% names(tr2)) next
    if (is.numeric(tr2[[cc]]) || is.integer(tr2[[cc]])) {
      mu <- mean(as.numeric(tr2[[cc]]), na.rm = TRUE)
      if (is.finite(mu)) {
        tr2[[cc]] <- ifelse(is.na(tr2[[cc]]), mu, tr2[[cc]])
        te2[[cc]] <- ifelse(is.na(te2[[cc]]), mu, te2[[cc]])
      }
    }
  }
  
  # OLS
  m_ols <- fit_ols(tr2, y, x_vars)
  p_ols <- as.numeric(predict(m_ols, newdata = te2))
  met_ols <- eval_models(te2, y, p_ols) |> mutate(model = "OLS", dataset = label)
  
  # Ridge/Lasso
  x_tr <- make_model_matrix(tr2, x_vars)
  x_te <- make_model_matrix(te2, x_vars)
  
  target_cols <- sort(colnames(x_tr))
  x_tr <- x_tr[, target_cols, drop = FALSE]
  x_te <- align_to_cols(x_te, target_cols)
  
  y_tr <- as.numeric(tr2[[y]])
  
  set.seed(42)
  cv_ridge <- cv.glmnet(x_tr, y_tr, alpha = 0, nfolds = 10, standardize = TRUE)
  p_ridge <- as.numeric(predict(cv_ridge, newx = x_te, s = "lambda.min"))
  met_ridge <- eval_models(te2, y, p_ridge) |> mutate(model = "Ridge", dataset = label)
  
  set.seed(42)
  cv_lasso <- cv.glmnet(x_tr, y_tr, alpha = 1, nfolds = 10, standardize = TRUE)
  p_lasso <- as.numeric(predict(cv_lasso, newx = x_te, s = "lambda.min"))
  met_lasso <- eval_models(te2, y, p_lasso) |> mutate(model = "Lasso", dataset = label)
  
  models <- bind_rows(met_ols, met_ridge, met_lasso) |> arrange(RMSE)
  
  cat("--- MODELS (test) ---\n")
  print(models)
  cat("\n")
  
  leaderboard <- bind_rows(baselines, models) |> arrange(RMSE)
  
  cat("--- LEADERBOARD (baselines + models) ---\n")
  print(leaderboard)
  cat("\n")
  
  artifact <- list(
    label = label,
    features = x_vars,
    split_info = list(train_n = nrow(tr2), test_n = nrow(te2), test_years = split$test_years),
    train_mean = train_mean,
    baselines = baselines,
    metrics_models = models,
    leaderboard = leaderboard,
    ols = m_ols,
    ridge = cv_ridge,
    lasso = cv_lasso,
    glmnet_cols = target_cols
  )
  
  list(artifact = artifact, leaderboard = leaderboard)
}

# K√∏r FULL (uden befolkning)
res_full <- run_long_final_yearsplit(
  df = analysis_df_long_full,
  x_vars = base_long_vars,
  label = "FULL_long_plus_ticket_plus_rolling",
  n_test_years = 2
)

# K√∏r BEF (med befolkning) ‚Äî ofte ustabilt pga f√• r√¶kker, men vi tester
vars_bef <- unique(c(base_long_vars, "befolkningstal"))
vars_bef <- vars_bef[vars_bef %in% names(analysis_df_long_bef)]

res_bef <- run_long_final_yearsplit(
  df = analysis_df_long_bef,
  x_vars = vars_bef,
  label = "BEF_long_plus_ticket_plus_rolling",
  n_test_years = 2
)

cat("\n--- LEADERBOARD (FULL) ---\n")
print(res_full$leaderboard)

cat("\n--- LEADERBOARD (BEF) ---\n")
print(res_bef$leaderboard)


```

#### Evaluering

I denne del samles hele LONG-setup‚Äôet i √©n ensartet evalueringsprocedure, der har til form√•l systematisk at sammenligne simple baselines med mere avancerede regressionsmodeller. Datas√¶ttet opdeles konsekvent i tr√¶ning og test ved hj√¶lp af et year-split, hvor de seneste to √•r anvendes som testperiode. Denne tilgang sikrer, at evalueringen af modellerne afspejler en realistisk prognosesituation uden datal√¶kage fra fremtidige observationer.

Som f√∏rste trin etableres en r√¶kke baselines, der fungerer som referencepunkter for modellernes pr√¶station. Disse best√•r af et simpelt gennemsnit beregnet p√• tr√¶ningsdata, et historisk gennemsnit baseret p√• tidligere observationer samt et rundespecifikt historisk gennemsnit, hvor der differentieres mellem runder, n√•r data tillader det. Baselines evalueres p√• testdatas√¶ttet ved hj√¶lp af RMSE, MAE og R¬≤ og giver et klart billede af, hvor stor en del af variationen i tilskuertallene der kan forklares uden brug af egentlige forklarende modeller.

Herefter estimeres tre regressionsbaserede modeller p√• samme datasplit: en klassisk OLS-model samt Ridge- og Lasso-regression. F√∏r estimering h√•ndteres manglende v√¶rdier i numeriske features, s√¶rligt rolling features og ticket-historik, ved imputering med gennemsnittet fra tr√¶ningsdata. Denne l√∏sning er valgt for at bevare observationsgrundlaget, is√¶r tidligt i s√¶sonerne hvor rolling features naturligt indeholder NA-v√¶rdier. Alle modeller tr√¶nes udelukkende p√• tr√¶ningsdata og evalueres derefter p√• testdatas√¶ttet ved hj√¶lp af de samme performance-metrikker som baselines.

Resultaterne fra b√•de baselines og modeller samles i et f√¶lles leaderboard, hvor modellerne rangeres efter RMSE. Dette giver en direkte og gennemsigtig sammenligning af, om de mere komplekse modeller reelt tilf√∏rer pr√¶diktiv v√¶rdi i forhold til simple historiske referencepunkter. Evalueringen viser, at regulariserede modeller som Ridge og Lasso reducerer fejl i forhold til en ureguleret OLS-model, men samtidig at den bedste historiske baseline fortsat pr√¶sterer p√• niveau med eller bedre end de estimerede modeller p√• testperioden.

Afslutningsvis gennemf√∏res hele evalueringsproceduren b√•de uden og med befolkningstal som ekstra feature. Form√•let er ikke prim√¶rt at forbedre den samlede performance, men at vurdere modellernes stabilitet og den marginale informationsv√¶rdi af befolkningstal givet det reducerede datagrundlag. Resultaterne dokumenterer, at tilf√∏jelsen af befolkningstal medf√∏rer f√¶rre observationer og √∏get usikkerhed, uden at der opn√•s en tydelig forbedring i prognosekvaliteten.

Samlet set dokumenterer denne endelige modelk√∏rsel, at historisk information udg√∏r den st√¶rkeste forklaringskomponent i det nuv√¶rende datas√¶t, og at mere avancerede modeller i denne ops√¶tning ikke form√•r entydigt at overg√• en velvalgt historisk baseline. Afsnittet fungerer dermed som empirisk dokumentation for b√•de modellernes pr√¶station og de metodiske valg, der ligger til grund for den endelige evaluering.

#### Robust prediktionsfunktion baseret p√• bedste model

Dette afsnit dokumenterer den endelige prediktionsops√¶tning for LONG-modellen, hvor form√•let er at sikre en stabil og reproducerbar m√•de at generere prognoser p√• baggrund af tidligere estimerede modeller. I stedet for manuelt at v√¶lge modeltype anvendes et f√¶lles artefakt, som indeholder b√•de baselines, regressionsmodeller og tilh√∏rende metadata fra den afsluttende modelk√∏rsel.

Funktionen identificerer automatisk den bedst pr√¶sterende model baseret p√• test-RMSE og anvender denne til efterf√∏lgende prediction. Ops√¶tningen underst√∏tter b√•de simple baselines og mere komplekse modeller (OLS, Ridge og Lasso) og h√•ndterer samtidig praktiske udfordringer som manglende features, faktorniveauer og kolonnejustering i modelmatricer. Dermed fungerer funktionen som et robust bindeled mellem analysefasen og egentlig anvendelse i fx Shiny, scenarieberegninger eller operationelle prognoser.

```{r}
### Graff leaderboard  
res_full$leaderboard |>
  ggplot(aes(x = reorder(model, RMSE), y = RMSE)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Modelperformance ‚Äì LONG",
    subtitle = "Test-√•r: 2024‚Äì2025",
    x = NULL,
    y = "RMSE"
  ) +
  theme_minimal(base_size = 13)
```

Her sammenlignes modelperformance i LONG-setup‚Äôet p√• test√•rene 2024‚Äì2025 m√•lt ved RMSE. Grafen viser tydeligt, at de simple historiske baselines performer markant forskelligt: BASE_hist_mean har den laveste fejl og fungerer som det st√¶rkeste referencepunkt, mens b√•de BASE_mean_train og is√¶r BASE_hist_round_mean har v√¶sentligt h√∏jere RMSE. De estimerede modeller (OLS, Ridge og Lasso) reducerer fejlen i forhold til den naive tr√¶ningsgennemsnits-baseline, men form√•r ikke konsekvent at forbedre sig i forhold til det rene historiske gennemsnit. Det indikerer, at st√∏rstedelen af den forklarende kraft i LONG-horisonten allerede ligger i det historiske niveau, og at de ekstra forklarende variable og regularisering prim√¶rt bidrager med stabilitet og struktur snarere end egentlig pr√¶cisionsgevinst. Grafen underst√∏tter dermed valget af en enkel, historikbaseret model som operationelt udgangspunkt, samtidig med at de mere komplekse modeller anvendes som metodisk benchmark og robusthedstjek.

```{r}

# =============================================================================
# 13) predict_best_long() ‚Äî robust (inkl baselines + stable glmnet align)
# =============================================================================
pick_best <- function(artifact) artifact$leaderboard |> arrange(RMSE) |> slice(1)

predict_best_long <- function(new_df, artifact) {
  best <- pick_best(artifact)
  model_name <- best$model[[1]]
  
  needed <- unique(c(artifact$features, "hist_mean", "hist_round_mean"))
  missing <- setdiff(needed, names(new_df))
  if (length(missing) > 0) {
    return(tibble(status = "MISSING_COLUMNS", missing = paste(missing, collapse = ", "), prediction = NA_real_))
  }
  
  if ("ugedag" %in% names(new_df)) {
    new_df$ugedag <- factor(as.character(new_df$ugedag),
                            levels = c("Mandag","Tirsdag","Onsdag","Torsdag","Fredag","L√∏rdag","S√∏ndag"))
  }
  
  new_df$hist_round_mean <- ifelse(is.na(new_df$hist_round_mean), new_df$hist_mean, new_df$hist_round_mean)
  
  # Imput√©r numeriske features med train-mean fra artifact (for stabil inference)
  # (her bruger vi train_mean for simplicitet; kan udvides til per-feature mean hvis du vil)
  for (cc in artifact$features) {
    if (!cc %in% names(new_df)) next
    if (is.numeric(new_df[[cc]]) || is.integer(new_df[[cc]])) {
      if (any(is.na(new_df[[cc]]))) {
        mu <- suppressWarnings(mean(as.numeric(new_df[[cc]]), na.rm = TRUE))
        if (!is.finite(mu)) mu <- NA_real_
        new_df[[cc]] <- ifelse(is.na(new_df[[cc]]), mu, new_df[[cc]])
      }
    }
  }
  
  # Baselines
  if (model_name == "BASE_mean_train") {
    return(tibble(status = "OK", model = "BASE_mean_train", prediction = rep(artifact$train_mean, nrow(new_df))))
  }
  if (model_name == "BASE_hist_mean") {
    return(tibble(status = "OK", model = "BASE_hist_mean", prediction = as.numeric(new_df$hist_mean)))
  }
  if (model_name == "BASE_hist_round_mean") {
    pred <- ifelse(is.na(new_df$hist_round_mean), new_df$hist_mean, new_df$hist_round_mean)
    return(tibble(status = "OK", model = "BASE_hist_round_mean", prediction = as.numeric(pred)))
  }
  
  # OLS
  if (model_name == "OLS") {
    pred <- as.numeric(predict(artifact$ols, newdata = new_df))
    return(tibble(status = "OK", model = "OLS", prediction = pred))
  }
  
  # Ridge/Lasso
  x <- make_model_matrix(new_df, artifact$features)
  x <- align_to_cols(x, artifact$glmnet_cols)
  
  if (model_name == "Ridge") {
    pred <- as.numeric(predict(artifact$ridge, newx = x, s = "lambda.min"))
    return(tibble(status = "OK", model = "Ridge", prediction = pred))
  }
  if (model_name == "Lasso") {
    pred <- as.numeric(predict(artifact$lasso, newx = x, s = "lambda.min"))
    return(tibble(status = "OK", model = "Lasso", prediction = pred))
  }
  
  tibble(status = "UNKNOWN_MODEL", model = model_name, prediction = NA_real_)
}

cat("\n‚úÖ LONG master script (tickets + s√¶son-lag + rolling uden leakage) f√¶rdig.\n")

```

Den endelige prediktionsfunktion dokumenterer, at den st√¶rkeste prognose i det nuv√¶rende datagrundlag ofte opn√•s via historiske referencepunkter snarere end komplekse regressionsmodeller. P√• trods af et rigt feature-s√¶t med kalenderinformation, billetdata og rolling momentum-features form√•r modellerne ikke systematisk at overg√• den bedste historiske baseline p√• testperioden.

Dette resultat peger p√•, at variationen i tilskuertal i h√∏j grad er struktureret omkring historiske m√∏nstre, og at marginal gevinster fra yderligere modellering er begr√¶nsede givet datam√¶ngde og st√∏jniveau. Den valgte arkitektur sikrer dog, at hvis dette √¶ndrer sig ‚Äì eksempelvis ved flere observationer, nye features eller √¶ndrede strukturer ‚Äì vil den bedste model automatisk blive anvendt uden √¶ndringer i den operationelle kode.

Afsnittet fungerer dermed som empirisk dokumentation for b√•de modelvalg og implementeringsstrategi og danner et solidt grundlag for videre brug af modellen i praksis.

## Introduktion til scenarie-prognose-shiny app (LONG)

Denne Shiny-app er udviklet som et fors√∏g p√• at operationalisere den langsigtede tilskuermodel. Form√•let er at vise, hvordan modelresultater kan oms√¶ttes til et simpelt scenarieestimat, der kan anvendes i en planl√¶gningssammenh√¶ng. Appen bygger p√• den mest stabile model i evalueringen og prioriterer forklarlighed frem for kompleksitet.

### Pakker

Her tjekkes, at de n√∏dvendige pakker til Shiny-appen er installeret, hvorefter de indl√¶ses uden un√∏dige konsolbeskeder.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

needed_pkgs_app <- c("shiny","dplyr","ggplot2","tibble")
missing_pkgs_app <- needed_pkgs_app[!vapply(needed_pkgs_app, requireNamespace, logical(1), quietly = TRUE)]
if (length(missing_pkgs_app) > 0) stop("‚ùå Manglende pakker (app): ", paste(missing_pkgs_app, collapse = ", "))

suppressPackageStartupMessages({
  library(shiny)
  library(dplyr)
  library(ggplot2)
  library(tibble)
})

```

### Afledte hj√¶lpefunktioner til scenarieinput

Denne kode samler de n√∏dvendige hj√¶lpefunktioner, som overs√¶tter brugerens scenarieinput til strukturerede modelvariable. Her udv√¶lges f√∏rst den bedst pr√¶sterende model fra LONG-evalueringen, hvorefter m√•ned, s√¶son, weekend og rundefase oms√¶ttes til konsistente, numeriske og kategoriske st√∏rrelser. Form√•let er at sikre, at input fra Shiny-appen kan kobles direkte til den historiske struktur, som modellen er estimeret p√•, uden at introducere ekstra antagelser eller kompleksitet.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

artifact_long <- res_full$artifact
best_model_name <- artifact_long$leaderboard |> arrange(RMSE) |> slice(1) |> pull(model) |> as.character()

month_labels_da <- c("Januar","Februar","Marts","April","Maj","Juni","Juli","August","September","Oktober","November","December")
month_map <- setNames(1:12, month_labels_da)

season_start_from_year_month <- function(year, month_int) {
  year <- as.integer(year); month_int <- as.integer(month_int)
  if (is.na(year) || is.na(month_int)) return(NA_integer_)
  if (month_int >= 7) year else (year - 1L)
}

season_period_from_month <- function(m) {
  m <- as.integer(m)
  if (m %in% c(12,1,2))  return("Vinter")
  if (m %in% c(3,4,5))   return("For√•r")
  if (m %in% c(6,7,8))   return("Sommer")
  if (m %in% c(9,10,11)) return("Efter√•r")
  "UKENDT"
}

weekend_from_ugedag <- function(ugedag) {
  if (is.na(ugedag)) return(NA_integer_)
  if (ugedag %in% c("L√∏rdag","S√∏ndag")) 1L else 0L
}

runde_from_fase <- function(fase) {
  if (is.na(fase)) return(NA_integer_)
  if (fase == "Tidlig") return(4L)
  if (fase == "Midt")   return(14L)
  if (fase == "Sen")    return(26L)
  NA_integer_
}

```

### Historiske referencev√¶rdier og fallback-logik

Denne kode opstiller de historiske referencev√¶rdier, som bruges til at fastl√¶gge baseline-niveauet i scenarieprognosen. F√∏rst konstrueres opslags¬≠tabeller for s√¶songennemsnit og runde-specifikke gennemsnit baseret p√• den eksisterende pipeline. Herefter defineres en fallback-mekanisme, som sikrer et realistisk niveau, hvis der mangler historik for den valgte s√¶son eller runde. De to hj√¶lpefunktioner returnerer dermed enten et direkte historisk estimat for den relevante s√¶son og runde eller, hvis det ikke findes, det bedst mulige historiske alternativ. Form√•let er at g√∏re prognosen robust over for manglende data uden at introducere nye antagelser.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny

# ---------------------------
# Historik-tabeller fra pipeline:
# ---------------------------
season_hist_map <- season_mean |>
  filter(!is.na(s√¶son_start√•r), is.finite(as.numeric(hist_mean))) |>
  distinct(s√¶son_start√•r, .keep_all = TRUE) |>
  arrange(s√¶son_start√•r) |>
  transmute(s√¶son_start√•r = as.integer(s√¶son_start√•r),
            hist_mean = as.numeric(hist_mean))

round_hist_map <- round_mean |>
  filter(!is.na(s√¶son_start√•r), !is.na(runde), is.finite(as.numeric(hist_round_mean))) |>
  distinct(runde, s√¶son_start√•r, .keep_all = TRUE) |>
  transmute(
    runde = as.integer(runde),
    s√¶son_start√•r = as.integer(s√¶son_start√•r),
    hist_round_mean = as.numeric(hist_round_mean)
  )

fallback_level <- {
  v <- suppressWarnings(as.numeric(analysis_df_long_full$tilskuere))
  v <- v[is.finite(v)]
  if (length(v) == 0) 6500 else mean(v)
}

get_hist_mean_for_target <- function(season_start_year_target) {
  if (is.na(season_start_year_target)) return(NA_real_)
  hit <- season_hist_map |> filter(s√¶son_start√•r == season_start_year_target) |> slice(1)
  if (nrow(hit) == 1) return(as.numeric(hit$hist_mean))
  if (nrow(season_hist_map) > 0) return(as.numeric(tail(season_hist_map$hist_mean, 1)))
  NA_real_
}

get_hist_round_mean_for_target <- function(season_start_year_target, runde_target) {
  if (is.na(season_start_year_target) || is.na(runde_target)) return(NA_real_)
  hit <- round_hist_map |>
    filter(s√¶son_start√•r == season_start_year_target, runde == runde_target) |>
    slice(1)
  if (nrow(hit) == 1) return(as.numeric(hit$hist_round_mean))
  
  hit2 <- round_hist_map |>
    filter(runde == runde_target) |>
    arrange(s√¶son_start√•r) |>
    slice_tail(n = 1)
  if (nrow(hit2) == 1) return(as.numeric(hit2$hist_round_mean))
  
  NA_real_
}
```

### Datadrevet m√•ned- og ugedagskorrektion samt scenarie-app

Denne del udvider LONG-modellen med en enkel, datadrevet korrektion for m√•ned og ugedag baseret udelukkende p√• tr√¶ningsdata. Effekterne beregnes som afvigelser fra det samlede gennemsnit og anvendes i d√¶mpet form for at undg√• overtilpasning. Prognosen tager derfor udgangspunkt i et historisk baseline-niveau fra s√¶son og rundefase og justeres derefter moderat for systematiske kalendereffekter.

Koden samles i en Shiny-app, som operationaliserer modellen i et scenarieformat. Brugeren kan indtaste f√•, centrale antagelser om en fremtidig kamp og f√• et forventet tilskuertal, et kapacitetsforhold og en visuel sammenligning mod stadionkapaciteten. Appen er ikke t√¶nkt som en fuld ML-implementering, men som et transparent og anvendeligt v√¶rkt√∏j, der oms√¶tter den estimerede model til konkret planl√¶gningsst√∏tte.

```{r}
#| eval: false
#| message: false
#| warning: false
#| error: false
# shiny


# =============================================================================
# Datadrevet korrektion for m√•ned + ugedag (baseret p√• TRAIN-data)
#      Vi bruger samme split som din LONG model (artifact split years)
# =============================================================================
test_years_long <- artifact_long$split_info$test_years
train_df_for_effects <- analysis_df_long_full |>
  filter(!(√•r %in% test_years_long)) |>
  mutate(
    m√•ned = as.integer(m√•ned),
    ugedag = factor(as.character(ugedag), levels = c("Mandag","Tirsdag","Onsdag","Torsdag","Fredag","L√∏rdag","S√∏ndag")),
    tilskuere = as.numeric(tilskuere)
  ) |>
  filter(is.finite(tilskuere), is.finite(m√•ned), !is.na(ugedag))

overall_train_mean <- mean(train_df_for_effects$tilskuere, na.rm = TRUE)

month_effect_tbl <- train_df_for_effects |>
  group_by(m√•ned) |>
  summarise(month_mean = mean(tilskuere, na.rm = TRUE), .groups = "drop") |>
  mutate(month_adj = month_mean - overall_train_mean)

wday_effect_tbl <- train_df_for_effects |>
  group_by(ugedag) |>
  summarise(wday_mean = mean(tilskuere, na.rm = TRUE), .groups = "drop") |>
  mutate(wday_adj = wday_mean - overall_train_mean)

get_month_adj <- function(month_int) {
  hit <- month_effect_tbl |> filter(m√•ned == as.integer(month_int)) |> slice(1)
  if (nrow(hit) == 1) return(as.numeric(hit$month_adj))
  0
}
get_wday_adj <- function(wday_chr) {
  hit <- wday_effect_tbl |> filter(as.character(ugedag) == as.character(wday_chr)) |> slice(1)
  if (nrow(hit) == 1) return(as.numeric(hit$wday_adj))
  0
}

# D√¶mpning: vi vil have effekt, men ikke ‚Äúoverfit‚Äù
W_MONTH <- 0.35
W_WDAY  <- 0.25

# Prediction-wrapper:
# - Hvis best er BASE_hist_mean, bruger vi: baseline (runde-justeret) + d√¶mpet m√•ned/ugedag
predict_app_long <- function(new_df, artifact) {
  best <- artifact$leaderboard |> arrange(RMSE) |> slice(1)
  model_name <- as.character(best$model[[1]])
  
  # Baseline-niveau (runde-justeret hvis muligt)
  base_level <- ifelse(is.finite(as.numeric(new_df$hist_round_mean)),
                       as.numeric(new_df$hist_round_mean),
                       as.numeric(new_df$hist_mean))
  
  # M√•ned/ugedag-korrektion (d√¶mpet)
  month_adj <- as.numeric(new_df$month_adj)
  wday_adj  <- as.numeric(new_df$wday_adj)
  corr <- (W_MONTH * month_adj) + (W_WDAY * wday_adj)
  
  if (model_name == "BASE_hist_mean") {
    pred <- base_level + corr
    return(tibble(status = "OK", model = "BASE_hist_mean (runde + m√•ned/ugedag-korr.)", prediction = pred))
  }
  
  # Hvis en ‚Äúrigtig‚Äù model vinder, kan du v√¶lge at bruge den her.
  # Lige nu holder vi os til baseline-logikken for forklaringskraft:
  pred <- base_level + corr
  tibble(status = "OK", model = paste0(model_name, " (app: + m√•ned/ugedag-korr.)"), prediction = pred)
}

ui <- fluidPage(
  titlePanel(paste0("LONG ‚Äî Scenarie-prognose (bedste model: ", best_model_name, ")")),
  sidebarLayout(
    sidebarPanel(
      tags$h4("Indtast scenarie (6 inputs)"),
      
      numericInput("in_year", "√Ör (fx 2026)", value = year(Sys.Date()), min = 2000, max = 2100, step = 1),
      
      selectInput("in_month", "M√•ned", choices = month_labels_da, selected = month_labels_da[month(Sys.Date())]),
      
      selectInput("in_ugedag", "Ugedag", choices = c("Mandag","Tirsdag","Onsdag","Torsdag","Fredag","L√∏rdag","S√∏ndag"),
                  selected = "Mandag"),
      
      selectInput("in_runde_fase", "Runde-fase", choices = c("Tidlig","Midt","Sen"), selected = "Tidlig"),
      
      selectInput("in_hellig", "Helligdag?", choices = c("Nej","Ja"), selected = "Nej"),
      
      numericInput("in_capacity", "Stadionkapacitet", value = 10000, min = 1000, max = 50000, step = 500),
      
      actionButton("btn_pred", "Predict")
    ),
    
    mainPanel(
      tags$h3("Output"),
      uiOutput("txt_out_html"),
      plotOutput("plt_cap", height = 320),
      tags$hr(),
      tags$h4("Kort forklaring"),
      tags$ul(
        tags$li("Baseline-niveau kommer fra historik: hist_mean (s√¶son) og helst hist_round_mean (runde-estimat)."),
        tags$li("M√•ned og ugedag korrigerer niveauet med historiske afvigelser (d√¶mpet)."),
        tags$li("Det er ikke en fuld ML-model ‚Äì men en forklarlig scenarie-korrektion, der g√∏r app‚Äôen brugbar.")
      )
    )
  )
)

server <- function(input, output, session) {
  
  scenarie_df <- eventReactive(input$btn_pred, {
    
    year_in <- as.integer(input$in_year)
    month_int <- as.integer(month_map[[input$in_month]])
    ugedag_in <- as.character(input$in_ugedag)
    runde_fase_in <- as.character(input$in_runde_fase)
    hellig_in <- ifelse(input$in_hellig == "Ja", 1L, 0L)
    cap <- as.numeric(input$in_capacity)
    
    weekend_in <- weekend_from_ugedag(ugedag_in)
    s√¶son_periode_in <- season_period_from_month(month_int)
    
    ssy <- season_start_from_year_month(year_in, month_int)
    
    hist_mean_in <- get_hist_mean_for_target(ssy)
    if (!is.finite(hist_mean_in)) hist_mean_in <- as.numeric(fallback_level)
    
    runde_est <- runde_from_fase(runde_fase_in)
    hist_round_in <- get_hist_round_mean_for_target(ssy, runde_est)
    
    # NYT: hent justeringer
    month_adj_in <- get_month_adj(month_int)
    wday_adj_in  <- get_wday_adj(ugedag_in)
    
    tibble(
      √•r = year_in,
      m√•ned = month_int,
      ugedag = factor(ugedag_in, levels = c("Mandag","Tirsdag","Onsdag","Torsdag","Fredag","L√∏rdag","S√∏ndag")),
      weekend = as.integer(weekend_in),
      er_helligdag = as.integer(hellig_in),
      runde_fase = factor(runde_fase_in, levels = c("Tidlig","Midt","Sen")),
      s√¶son_periode = factor(s√¶son_periode_in, levels = c("Vinter","For√•r","Sommer","Efter√•r","UKENDT")),
      
      hist_mean = as.numeric(hist_mean_in),
      hist_round_mean = as.numeric(hist_round_in),
      
      month_adj = as.numeric(month_adj_in),
      wday_adj  = as.numeric(wday_adj_in),
      
      runde_estimat = as.integer(runde_est),
      kapacitet = cap
    )
  })
  
  pred_tbl <- eventReactive(input$btn_pred, {
    df <- scenarie_df()
    predict_app_long(df, artifact_long)
  })
  
  output$txt_out_html <- renderUI({
    pr <- pred_tbl()
    df <- scenarie_df()
    
    pred <- as.numeric(pr$prediction[[1]])
    cap <- as.numeric(df$kapacitet[[1]])
    fyldt <- (pred / cap) * 100
    
    # Farve-regel (som du bad om)
    col_pred <- ifelse(is.finite(pred) && pred >= 5000, "darkgreen", "orange")
    
    # Tekst: vis ogs√• ‚Äúhvor kommer niveauet fra‚Äù
    base_level <- ifelse(is.finite(as.numeric(df$hist_round_mean[[1]])),
                         as.numeric(df$hist_round_mean[[1]]),
                         as.numeric(df$hist_mean[[1]]))
    
    corr <- (W_MONTH * as.numeric(df$month_adj[[1]])) + (W_WDAY * as.numeric(df$wday_adj[[1]]))
    
    tagList(
      tags$p(tags$b("Model: "), pr$model[[1]]),
      tags$p(
        tags$b("Forudsagt tilskuertal: "),
        tags$span(style = paste0("color:", col_pred, "; font-weight:700;"),
                  ifelse(is.finite(pred), format(round(pred, 0), big.mark=".", decimal.mark=","), "NA"))
      ),
      tags$p(
        tags$b("Stadion fyldt: "),
        tags$span(style = "font-weight:700;",
                  ifelse(is.finite(fyldt),
                         paste0(format(round(fyldt, 1), decimal.mark=","), " %"),
                         "NA")),
        paste0(" (kapacitet = ", format(cap, big.mark=".", decimal.mark=","), ")")
      ),
      tags$hr(),
      tags$p(tags$b("Debug (forklaring af tallet):")),
      tags$ul(
        tags$li(paste0("Baseline-niveau (hist): ",
                       format(round(base_level,0), big.mark=".", decimal.mark=","),
                       ifelse(is.finite(df$hist_round_mean[[1]]), " (runde-justeret)", " (s√¶son-mean)"))),
        tags$li(paste0("M√•ned-justering (d√¶mpet): ",
                       format(round(W_MONTH * as.numeric(df$month_adj[[1]]),0), big.mark=".", decimal.mark=","))),
        tags$li(paste0("Ugedag-justering (d√¶mpet): ",
                       format(round(W_WDAY * as.numeric(df$wday_adj[[1]]),0), big.mark=".", decimal.mark=","))),
        tags$li(paste0("Samlet korrektion: ",
                       format(round(corr,0), big.mark=".", decimal.mark=",")))
      )
    )
  })
  
  output$plt_cap <- renderPlot({
    pr <- pred_tbl()
    df <- scenarie_df()
    
    pred <- as.numeric(pr$prediction[[1]])
    cap <- as.numeric(df$kapacitet[[1]])
    
    if (!is.finite(pred)) {
      ggplot() +
        labs(title = "Forudsagt tilskuertal vs stadionkapacitet", subtitle = "Ingen prediction (NA)") +
        theme_minimal(base_size = 14)
      return(invisible())
    }
    
    # Farve-regel til s√∏jlen
    fill_group <- ifelse(pred >= 5000, "‚â• 5.000", "< 5.000")
    dfp <- tibble(label = "Forudsagt", value = pred, grp = fill_group)
    
    ggplot(dfp, aes(x = label, y = value, fill = grp)) +
      geom_col() +
      geom_hline(yintercept = cap, linetype = 2, linewidth = 0.8) +
      scale_fill_manual(values = c("‚â• 5.000" = "darkgreen", "< 5.000" = "orange"), guide = "none") +
      labs(
        title = "Forudsagt tilskuertal vs stadionkapacitet",
        subtitle = paste0("Kapacitet (stiplet): ", format(cap, big.mark=".", decimal.mark=",")),
        x = NULL, y = "Tilskuere (forudsagt)"
      ) +
      theme_minimal(base_size = 14)
  })
}

cat("\n‚ñ∂ Starter Shiny app...\n")
shinyApp(ui = ui, server = server)


```

## En organisatorisk beslutning baseret p√• scenarie-prognosen

Palle st√•r med en konkret beslutning. Om to m√•neder venter en vigtig Superliga-kamp, og der er internt blevet rejst et forslag om at ops√¶tte midlertidige faciliteter omkring stadion ‚Äì eksempelvis ekstra salgsboder og bemanding ‚Äì for at im√∏dekomme et forventet h√∏jere pres p√• kampdagen.

Inden beslutningen tr√¶ffes, anvender Palle Scenarie-prognose-appen til at vurdere situationen. For en s√∏ndagskamp i april 2026, sent i runde-fasen og uden helligdag, estimerer modellen et tilskuertal p√• cirka 6.134, svarende til en bel√¶gningsgrad p√• omkring 61 % af stadionkapaciteten.

![](images/2026-01-05_09h18_48.png)

Prognosen viser, at kampen forventes at ligge t√¶t p√• et historisk gennemsnitsniveau, og at de samlede korrektioner fra m√•ned og ugedag kun giver et moderat l√∏ft. Det indikerer, at der ikke er tale om et scenarie med markant overbel√¶gning eller ekstraordin√¶rt pres p√• faciliteterne.

P√• den baggrund vurderer Palle, at det ikke er √∏konomisk hensigtsm√¶ssigt at investere i st√∏rre organisatoriske tiltag allerede nu. I stedet besluttes det at afvente og f√∏rst genoverveje initiativet, hvis nye informationer ‚Äì eksempelvis sportslige resultater eller billetsalg t√¶ttere p√• kampdatoen ‚Äì √¶ndrer foruds√¶tningerne.
